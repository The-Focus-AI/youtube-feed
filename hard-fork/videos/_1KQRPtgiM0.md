---
video_id: _1KQRPtgiM0
title: "Should You Be Afraid of the SaaSpocalypse?"
channel: Hard Fork
duration: 3501
duration_formatted: "58:21"
view_count: 18734
upload_date: 2026-02-13
url: https://www.youtube.com/watch?v=_1KQRPtgiM0
thumbnail: https://i.ytimg.com/vi_webp/_1KQRPtgiM0/maxresdefault.webp
tags:
  - saaspocalypse
  - ai disruption
  - software as a service
  - ai romance
  - ai publishing
  - vibe coding
  - matt shumer
  - something big is happening
  - spotify
  - whale song
  - hard fork
  - hard fork podcast
---

# Should You Be Afraid of the SaaSpocalypse?

## Summary

Kevin Roose and Casey Newton tackle the growing panic around AI's impact on the software industry, the viral essay "Something Big Is Happening," the disruption of romance novel publishing by AI, and a couple of surprisingly delightful AI applications. Kevin reports from Washington DC where everyone is freaking out about AI, and the hosts examine the so-called "SaaSpocalypse" -- the massive selloff in SaaS (software as a service) stocks like Monday.com (down 20%), Workday (CEO stepping down), Salesforce, Shopify, Adobe, and others, all driven by fears that AI-powered vibe coding will let companies build their own tools instead of paying for enterprise software.

They then dissect Matt Shumer's viral essay "Something Big Is Happening," which argues that AI is approaching an inflection point where software engineering is being automated and the pace of development is accelerating. An executive at a major AI company tells Kevin that software engineering is "90% automated" right now and could be fully automated within the year. The hosts debate whether this constitutes a real "pandemic-level" moment, with Casey noting that Claude Code already accounts for 4% of all public GitHub commits, predicted to reach 20% by end of 2026.

The second half features an interview with New York Times reporter Alexandra Alter about AI's disruption of the romance novel industry, where one author published over 200 novels in a year using AI. The episode closes with a "One Good Thing" segment: Casey highlights Spotify's new prompted playlists feature, and Kevin spotlights Google's Perch 2.0 model for understanding whale song.

## Highlights

### "Software Engineering Is 90% Automated Right Now"

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=568&end=630" frameborder="0" allowfullscreen></iframe>

> "I talked to an executive at one of the big AI companies this week who said that basically right now software engineering is kind of 90% automated. You still need a human to check in on the code... but within the year this person's prediction was that software engineering will be fully automated."
> -- Kevin Roose, [9:28](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=568s)

### "If You're Still Writing Code by Hand, That's Going to Be Obsolete"

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=660&end=720" frameborder="0" allowfullscreen></iframe>

> "I do believe that the ceiling for Claude commits to GitHub is probably not 20%. I think it's probably going to be a lot higher than that. I think that by the end of the year, if you are still writing code by hand, that is going to be an obsolete behavior."
> -- Casey Newton, [11:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=660s)

### "Claude Wrote 'His Turgid Manhood'"

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=1490&end=1550" frameborder="0" allowfullscreen></iframe>

> "She mentioned that Claude had written in one of her recent drafts 'his turgid manhood.' That was the kind of language she was getting. And so then she started writing lists of words that the AI loved -- like shiver, unravel, manhood, moan -- and blocking them."
> -- Alexandra Alter, [24:50](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1490s)

### "Make It Slow and Agonizing. Do Not Rush to the Finish."

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=1540&end=1580" frameborder="0" allowfullscreen></iframe>

> "She says it's very important that you tell the chatbot to slow down because otherwise they just jump to the end of the scene. Everyone's tangled in the sheets. So she gave them a specific prompt which was something along the lines of 'make it slow and agonizing. Do not rush to the finish.'"
> -- Alexandra Alter, [25:40](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1540s)

### "Baba O'Riley, Smells Like Teen Spirit -- It Got Them All Right"

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=2790&end=2840" frameborder="0" allowfullscreen></iframe>

> "Would you believe? It is killing it. Baba O'Riley. Smells Like Teen Spirit. For What It's Worth. Sympathy for the Devil. These are so many great... Wait, this is amazing. It got all of them right."
> -- Kevin Roose, [46:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2790s)

### "He Says Her Name Like a Ragged Prayer"

<iframe width="560" height="315" src="https://www.youtube.com/embed/_1KQRPtgiM0?start=2180&end=2240" frameborder="0" allowfullscreen></iframe>

> "I was reading through several AI generated romance novels... and I read this phrase, 'the hero whispers her name like a ragged prayer.' And I realized that phrase was in several of the books and repeatedly within the same books. One of them said, 'I've actually had to block that phrase. It loves to say ragged prayer.'"
> -- Alexandra Alter, [36:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2180s)

## Key Points

- **SaaS Stock Selloff** ([2:24](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=144s)) - Monday.com stock plunged 20%, Workday CEO stepped down after 17% stock loss, Salesforce, Shopify, Adobe, SAP, Oracle, and Microsoft all fell
- **Anthropic Plugins as Catalyst** ([3:43](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=223s)) - Anthropic's release of law firm AI tools may have been the straw that broke the camel's back for the SaaS selloff
- **Seat-Based Pricing Under Threat** ([6:25](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=385s)) - Companies paying per-seat for software may shift to outcome-based pricing as AI agents replace individual workers
- **Sierra's Outcome-Based Model** ([6:45](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=405s)) - Sierra charges based on customer service calls resolved, pointing to the future of AI business models
- **"Something Big Is Happening" Essay** ([1:25](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=85s)) - Matt Shumer's viral essay about AI reaching an inflection point in automating technical work
- **GPT 5.3 Codex Self-Improvement** ([8:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=510s)) - OpenAI's latest model is their first that was "instrumental in creating itself," suggesting recursive self-improvement
- **4% of GitHub Commits by Claude Code** ([10:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=630s)) - Semi Analysis report shows 4% of public GitHub commits are by Claude Code, predicted to reach 20%+ by end of 2026
- **Political Response Needed** ([12:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=750s)) - Casey argues constituents need to ask lawmakers about plans for potential permanent unemployment in some job categories
- **Bernie Sanders AI Moratorium** ([13:05](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=785s)) - Bernie Sanders introduced a bill to put a moratorium on data centers for AI
- **200 Romance Novels in One Year** ([14:55](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=895s)) - Romance author Coral Hart created 21 pen names and published 200+ novels using AI, earning six figures
- **AI Models Have Different Romance Strengths** ([22:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1340s)) - Claude writes beautiful sentences but is terrible at sexy banter; ChatGPT blocks you; Grok will do anything; NovelAI was trained on erotica
- **"Not Really a Writer Anymore"** ([28:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1680s)) - Coral Hart describes herself as "more of a director" or "creator" rather than an author
- **Copyright Problem for Publishers** ([33:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1980s)) - AI-produced content cannot be copyrighted, creating a problem for publishers who need to hold copyright
- **"The Ragged Prayer" AI-ism** ([36:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2180s)) - AI romance novels frequently use the phrase "like a ragged prayer," possibly traced to Sarah J. Maas
- **Spotify Prompted Playlists** ([39:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2370s)) - New Spotify feature lets you create playlists using natural language prompts drawing on your listening history
- **Google Perch 2.0 Whale Song AI** ([49:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2940s)) - Google's bio-acoustics model trained on bird song successfully classifies underwater whale sounds through transfer learning

## Mentions

### Companies
- **Monday.com** ([2:50](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=170s)) - Stock plunged 20% after weak financial outlook
- **Workday** ([3:12](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=192s)) - CEO stepping down after 17% stock value loss
- **Salesforce** ([3:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=210s)) - Stock fell as part of SaaS selloff
- **Anthropic** ([3:43](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=223s)) - Released law firm plugins that may have triggered the selloff
- **OpenAI** ([8:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=510s)) - Released GPT 5.3 Codex, first model instrumental in creating itself
- **Sierra** ([6:45](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=405s)) - Customer service startup with outcome-based pricing model
- **Goldman Sachs** ([7:50](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=470s)) - Deploying AI agents internally with Anthropic's forward-deployed engineers
- **Spotify** ([39:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2370s)) - New prompted playlists feature using listening history data
- **Google** ([49:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2940s)) - Released Perch 2.0 bio-acoustics model
- **Semi Analysis** ([10:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=630s)) - Semiconductor newsletter that reported Claude Code's GitHub commit share

### Products & Technologies
- **Claude Code** ([10:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=630s)) - 4% of all public GitHub commits, predicted to reach 20%+ by end of 2026
- **GPT 5.3 Codex** ([8:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=510s)) - OpenAI's model described as first instrumental in creating itself
- **Pseudowrite** ([20:45](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1245s)) - AI fiction writing platform used by romance authors
- **Red Quill / My Spicy Vanilla** ([21:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1260s)) - Sites that generate customized erotica
- **Janitor AI** ([35:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2130s)) - Romance chatbot app for interacting with fictional characters
- **Perch 2.0** ([49:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2940s)) - Google's bio-acoustics foundation model that transfers bird song learning to underwater sounds
- **Spotify Prompted Playlists** ([39:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2370s)) - LLM-powered playlist creation using natural language and listening history

### People
- **Matt Shumer** ([1:25](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=85s)) - Author of viral essay "Something Big Is Happening," CEO of an AI company
- **Alexandra Alter** ([14:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=870s)) - New York Times reporter who wrote about AI disrupting romance novels
- **Coral Hart** ([17:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1020s)) - Romance novelist who published 200+ AI-assisted novels and teaches classes on AI writing
- **Sam Altman** ([9:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=540s)) - Referenced regarding agents being relentless and never getting tired
- **Bernie Sanders** ([13:05](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=785s)) - Introduced bill to put moratorium on AI data centers
- **Molly Holder** ([42:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2520s)) - Spotify VP of Personalization who confirmed prompted playlists use listening data
- **Sarah J. Maas** ([37:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2220s)) - Popular romance author whose work may be the origin of "ragged prayer" AI-ism

## Surprising Quotes

> "I think you're absolutely right that it will be buggy and insecure and you're wrong that people won't rely on it."
> -- Casey Newton, [7:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=440s)

> "I am no longer needed for the actual technical work of my job. Not 'they will be automated' or 'they might be automated' -- I am no longer needed."
> -- Matt Shumer (quoted by Kevin Roose), [8:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=480s)

> "She said Claude writes beautiful sentences, but is terrible at sexy banter. ChatGPT will block you every time. Grok will do whatever you want. Goes for the selfie option every time. NovelAI was literally trained on erotica and it's out of control."
> -- Alexandra Alter, [22:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1340s)

> "Do you still think of yourself as a writer? And she said, I mean, not really. I'm more of a director. I'm a creator."
> -- Alexandra Alter on Coral Hart, [28:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1680s)

> "Goldman said, 'Claude, we want you to design the most dangerous mortgage that's ever existed. We want to get that on the market. Let's go, buddy.'"
> -- Casey Newton (joking), [7:55](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=475s)

## Transcript

[0:06](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=6s) Well, Kevin, welcome back from our nation's capital. Yes, I was in DC very briefly this week, there for some book meetings. And it was very cold. But the bigger observation is that Washington DC is like freaking out about AI. Is that right? Yes. So, everywhere I went, every meeting I had, people were sort of asking me, is this stuff real? Is it happening? Are we in the takeoff? Is the singularity approaching?

[0:40](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=40s) And it does feel like the sort of political salience of AI has gotten much much higher just in the past couple of weeks. Well, why do you think that is? So, there are a lot of reasons for that. I think one of them is that there's been a lot of people waking up to the new agentic coding capabilities of these models. We've obviously talked about that on the show. Claude Code, etc. I think that is starting to make its way out into the world. There's also this stock market stuff that's been going on with a lot of the software stocks that are falling because of the threat of AI.

[1:07](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=67s) And then I think there's just sort of this ambient cultural vibe shift happening that has led to a lot of people in my life who are not like AI bubble people texting me and saying, "Hey, is this really something I should be worried about? Is my job at risk here?" And so today I think we should talk about this because among other reasons there is this viral essay that I've been sent now no fewer than three times just in the past day by a man named Matt Shumer called "Something Big Is Happening." And it's basically a distilled version of something you and I have been talking about on this show for a while now, which is these tools are getting really good. They're changing the way that programmers work. They're approaching some sort of inflection point and everyone needs to be worried about this.

[1:55](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=115s) Yeah. So, all of this is starting to make me think that there is something big happening here and I'm not sure it's exactly what Matt thinks is happening, but I do think we are reaching an inflection point in people's feelings and senses about AI and where it's going. Before we do that, perhaps we should make our disclosures. Yes. I work for the New York Times which is suing OpenAI, Microsoft and Perplexity over alleged copyright violations. And my boyfriend works at Anthropic.

[2:24](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=144s) Okay. So, let's start with this what they're calling the SaaS apocalypse. The selloff in some of the tech stocks. SaaS is of course software as a service. Not the sort of SaaS you're used to seeing on RuPaul's Drag Race. Yes. Different kind. So, this would be companies like Salesforce and Workday. A good SaaS company -- if you've ever seen a billboard in San Francisco and you haven't understood what the company does, that's a SaaS company.

[2:50](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=170s) Yes, these are companies that sell software to other businesses. And over the past couple of weeks, we've seen a lot of these companies' stock prices falling precipitously. So on Monday this week, Monday.com, the production management software company, their stock plunged more than 20% after a weak financial outlook. Had a real case of the Mondays over there. Yes. Workday, which makes sort of HR tools for companies, they announced on Monday that their CEO is stepping down after their stock lost 17% of its value last year. His workday came to an abrupt end.

[3:25](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=205s) Yes. And a bunch of other SaaS company stocks also fell. Salesforce, Shopify, Adobe, SAP, Oracle, Microsoft. Basically, if you are a company that builds software for other companies, you are not having a good month. And give us the basic investor thesis, Kevin, for why those companies just aren't worth as much anymore. So, I think in this specific instance, it's not clear to me that there was one particular trigger. People pointed to this set of plugins that Anthropic released which included some tools for law firms trying to use AI. I don't think it was that in particular. I think maybe that was the straw that broke the camel's back, but there is a mounting sense that now anyone can theoretically build your own version of that and these companies may not be as valuable.

[4:15](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=255s) Yeah. I mean, there have always been people who would look at a product like Salesforce and say, "Well, that's basically just a fancy spreadsheet." And I do think that when Claude Co-work came out and all of a sudden you could just take a bunch of files on your computer and throw them into Claude and get something useful back, there were people who said maybe we can actually just make a version of it ourselves. And I will say, as a small business owner, I used a plugin that Claude has for finances. And I just took all of my financial data that my bookkeeper has kept for me over the past five plus years and I threw it into Claude and we had a nice long conversation about what was going on in my business.

[5:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=300s) Yeah. And do you feel like that fear is justified? Because there have been a couple reactions to this from the business community. One reaction is the investor reaction: all of the SaaS companies are overvalued. Salesforce doesn't have a moat anymore. Everyone's going to be vibe coding their own versions of these tools. And the other reaction is calm down, don't freak out. No one is going to be vibe coding their payroll software. That's not how this works.

[5:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=330s) So this gets at a really interesting question. What makes these companies truly vulnerable? Is it the technology itself or is it that the technology will just enable different kinds of business models? The argument that it's the technology itself is the person who says we're just going to be able to vibe code all our own software now. That's the sort of technology demolishes everything argument. I would say that's a minority view. But there is this other view which is that the technology enables a change in the business model. I think law is a really good place to think about that. Lawyers charge $1,500 an hour. What happens when you don't need an hour of a lawyer's time anymore?

[6:25](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=385s) Let's talk about another really common business model in tech. A lot of these business software companies have you pay by the seat. Another thread of anxiety is maybe paying by the seat isn't going to make sense anymore because we're actually just going to have one agent that does that whole thing. So if I had one prediction to make, it's that you're going to see more companies experiment with outcome-based pricing. You're already starting to see this with companies like Sierra, which is a customer service startup, and you pay Sierra based on how many calls it resolves for you. If you're an incumbent SaaS company with a seat-based business model, that is eventually going to be a problem for you.

[7:10](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=430s) So, do you think this selloff is justified? Here's a funny thing -- as a journalist, we're not allowed to buy individual stocks. So I actually never have any idea of what the investors are supposed to be doing. But do I think that AI is about to change a whole lot of business models and that a whole lot of businesses are probably going to have to either change dramatically or go out of business as a result? Absolutely.

[7:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=450s) And I think this notion that no one is going to vibe code their own payroll software -- I am not as convinced of that as some people. I can totally imagine a world in which you have one or two full-time developers who are managing and overseeing and repairing your own internal software and you don't have to pay for a bunch of seats for someone else's thing. That's a very plausible outcome.

[7:55](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=475s) Another pushback we're seeing is that it's all going to be so insecure and sloppy and buggy that no one is going to rely on it. I think you're absolutely right that it will be buggy and insecure and you're wrong that people won't rely on it. If there's one thing we've seen with Moltbook mania, it's that security is basically the last priority.

[8:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=500s) Now, do you want to talk about this big essay that's captured your imagination? Yes. Well, I should say if you are a regular listener to the Hard Fork podcast, none of what is in this essay will be news to you. But this essay did go insanely viral. It's called "Something Big Is Happening" and it's basically an explainer for non-technical people about why everyone who's in technical fields is freaking out about what's happening in AI. This is by a guy named Matt Shumer. He runs an AI company. He's basically saying the technical parts of my job are automated. Not they will be automated or they might be automated -- I am no longer needed for the actual technical work of my job.

[9:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=540s) He talks about the advances in recent coding models, these agentic coding systems. He talks about how new models are contributing to their own development, this idea of recursive self-improvement. GPT 5.3 Codex came out just last week and OpenAI says this is their first model that was instrumental in creating itself. So the AI models are now contributing to their own development, starting to accelerate the development of these AI systems.

[9:28](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=568s) I talked to an executive at one of the big AI companies this week who said that basically right now software engineering is kind of 90% automated. You still need a human to check in on the code that's being written to make sure it works, to fix things when they break. But within the year this person's prediction was that software engineering will be fully automated. Now that could take a little longer, but I think that is the moment that a lot of people in the tech industry are looking at as the beginning of what they call the takeoff.

[10:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=600s) One specific detail -- I've been talking to engineers who've been telling me about the specific ways that these agents work. Something that comes up again and again is that these models just never get tired. They're relentless. You can say to them, I want you to meet this objective, and they will just keep trying things until it works. Engineers I've talked to have started to see this behavior. And this is another reason why they think we're starting to enter this takeoff phase -- the relentlessness of the agents.

[10:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=630s) He likens this moment to the February before the pandemic. I actually think that comparison is fairly apt. I was looking at this chart from Semi Analysis about the percentage of GitHub commits that are being made by Claude Code. Right now the percentage of GitHub public commits being written by Claude Code is 4%. They are predicting that at the current trajectory, by the end of 2026, more than 20% of all daily commits on GitHub public projects will be authored by Claude Code. That is one tool.

[11:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=660s) I do believe that the ceiling for Claude commits to GitHub is probably not 20%. I think it's probably going to be a lot higher than that. I think that by the end of the year, if you are still writing code by hand, that is going to be an obsolete behavior. It is so clear to me that this is the way software development is going. And it's not just going to be confined to coding. Banks produce software. Law firms have software. People should be paying attention to what's going on in coding.

[11:40](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=700s) Any practical tips for people beyond just pay attention to this? The thing that everyone says is get familiar with the tools. I think that if you have not touched Claude Code or Codex or one of these agentic coding tools, maybe the last time you used an LLM for serious work was a year or two ago, it's worth getting back up to speed. Do you have any better tips? Well, I just think that this needs to be part of our political conversation. Constituents need to be telling lawmakers, "Hey, my boss is telling me that I need to start using AI every day and that there's a high risk that I'm about to lose my job."

[12:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=740s) Many economists are looking at that and they believe that is at least a possibility in at least some industries and they don't believe the AI lab spin that technology always creates more job opportunities in the long run. So we do need to have a political conversation about this. I think the people at the AI companies are woefully underestimating how much people hate this technology already. And unemployment is still at near record lows. If and when this does start to eat away at some of these white collar industries, I think the backlash is going to be furious. Bernie Sanders recently said that he is going to introduce a bill to put a moratorium on data centers for AI.

[13:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=810s) Love is in the air. Or was it AI generated love? It is almost Valentine's Day, and we have a story about the way that AI is disrupting the romance novel industry. Earlier this week, New York Times reporter Alexandra Alter put out a story about a growing number of writers using AI to churn out tons of romance novels at record speed. In one case a writer went from writing about 10 books a year, which is already a lot, to now doing more than 200 romance novels a year with the help of AI.

[14:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=870s) We should say these are not literary fiction. These are not going to be winning any Pulitzer prizes. But they are stories like "The Whiskey Wedding" or "Diagnosis of the Heart." Think of the old romance novels with a shirtless firefighter on the front. Alexandra Alter, welcome to Hard Fork. The question that led to this story came up last year when OpenAI said that they would allow erotic content. And I started asking around to figure out whether romance authors and publishers were feeling threatened by this. I was expecting to find a lot of hand-wringing, which I did find, but I was also surprised to find a few writers who were willing to speak to me about how much they love AI.

[16:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=960s) There's different platforms that writers are using. There's Pseudowrite. Then there are sites like Red Quill or My Spicy Vanilla. And then there's just your general bots -- Claude, ChatGPT, Gemini. If you learn how to prompt the bot correctly, it will write a pretty compelling sex scene. You have to give it an outline. You can tell it, I would like a reverse harem, mafia, enemies to lovers, slow burn romance, and it will deliver all those beats. Some of them say they can write a book in a day and have it edited ready to publish.

[17:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1020s) Tell us the story of Coral Hart. She was one of the people I found who was actually teaching other writers how to use AI tools to produce novels. She's been writing romance novels for a really long time but realized she could supercharge her output. So last year she created 21 different pen names and published more than 200 romance novels in all kinds of genres. Super spicy erotica, tame sweet teen stories, romcoms. Through a sheer volume game, she ended up making six figures.

[18:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1110s) She has this whole spreadsheet about which models do what for her. Claude writes beautiful sentences, but is terrible at sexy banter. ChatGPT will block you every time. Grok will do whatever you want, goes for the selfie option every time. NovelAI was literally trained on erotica and it's out of control. Some writers had to prompt their bots to sort of calm down a bit.

[20:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1200s) Coral is advising her students to give the AI a list of settings that are weird -- like a winery fermentation tank or a stalled ski lift or a horse stable. And she's also recommending that her students give the AI a detailed inventory of sexual kinks that are not just the typical ones. She sat in on one of Coral Hart's classes about getting AI to write decent sex scenes. She said, "You are not going to get a good sex scene if you don't carefully prompt it. You're going to get weird euphemistic stuff."

[24:50](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1490s) She mentioned that Claude had written in one of her recent drafts "his turgid manhood." That was the kind of language she was getting. So then she started writing lists of words that the AI loved -- like shiver, unravel, manhood, moan -- and blocking them. And the funniest thing she says to students: it's very important that you tell the chatbot to slow down because otherwise they just jump to the end of the scene. Everyone's tangled in the sheets. So she gave them a specific prompt: "make it slow and agonizing. Do not rush to the finish."

[26:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1560s) The approach of publishing hundreds of romance novels in a year seems functionally indistinguishable from spam. And what is Coral's relationship with her own work? I asked her, do you still think of yourself as a writer? And she said, I mean, not really. I'm more of a director. I'm a creator. She comes up with the plots and the characters, but she doesn't necessarily think of herself as the author anymore.

[29:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1740s) Are these AI generated novels any good? What I found reading probably half a dozen novels that I knew to be AI generated -- there was something that didn't come together. The emotional nuance, the characters -- I felt a little bit of distance from the characters. When you know that's not a human talking to me, it feels quite flat. But it's hard to know if I was projecting.

[30:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1830s) How many of these writers are disclosing that they use AI? Very few of them are disclosing it. It's very contentious. There were a couple romance authors last year who accidentally left AI prompts in their books. People got quite upset. Really takes you out of the moment when you're in the middle of a sex scene and it's like, "as an AI model..."

[32:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=1920s) How are the publishers responding? Most of them have policies that their authors have to assure them in their contracts that the work is original. There's also a copyright issue -- stuff produced with AI cannot be copyrighted and publishers do not want to put out a book that they can't hold the copyright for. My sense is that this is an area that they're not quite prepared for.

[33:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2010s) Some of these publishers are just going to start cutting out the writers, right? If you're a romance publisher and you see that your writers are just creating AI romance novels and you're paying them royalties, why can't I as the publisher just do the same prompt myself? One flaw with that is in romance the authors have very close relationships with their audiences. The self-published authors that succeed, one of the things the publishers are buying is that brand and the persona.

[35:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2100s) OpenAI has said they're going to allow erotic content soon. Is there anxiety that readers might bypass the publishing industry altogether and generate their own personalized romance stories? There's this app called Janitor AI. It's a romance app where you can chat with a vampire boyfriend or an orc. And it's one of the most popular apps in the book section. So there is this sense that AI is encroaching clearly into the territory of romance.

[36:20](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2180s) Tell us about the ragged prayer. So, as I was reading through several AI generated romance novels, I read this phrase: "the hero whispers her name like a ragged prayer." And I realized that phrase was in several of the books and repeatedly within the same books. Whenever the hero says her name, he says it like a ragged prayer or sometimes a jagged prayer or a rough prayer. One of the writers said, "I've actually had to block that phrase. It loves to say ragged prayer." I tried to trace the origins -- I did find it in a very popular romance book by Sarah J. Maas, which was one of the many books ingested by Anthropic according to the lawsuit that authors brought against Anthropic.

[38:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2310s) I'm writing a book and my publisher has asked me, "You're not using AI to write any of this." And it's true, I am not using AI for composition, but I'm using it in all kinds of other ways. And I can totally see the temptation to just let it write the words on the page.

[39:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2370s) Now, let's talk about One Good Thing. Casey, shall I go first? So, this is one that has been flying a little bit under the radar. It's a new feature in Spotify, only available in a few countries and only to premium subscribers. The feature is called prompted playlists. You open your Spotify app, go to create, and you will see a text box that looks exactly like ChatGPT. It's basically a genie you can throw a wish into and say, I would like a playlist like this.

[41:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2460s) What I did was said, "Show me songs I've listened to at least 20 times, but not in the past 2 months. Please don't repeat albums and create a well-sequenced playlist drawing from this set rather than just ranking by play count." And this was able to give me the playlist I was looking for. I called up Spotify and talked to the VP of personalization, Molly Holder, and she confirmed that yes, it actually uses your listening data going back more than a decade.

[43:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2580s) Some people have used this playlist to say "make a playlist that is the opposite of my taste" and it will try to get you as far outside your filter bubble as it can. If you're traveling to a new country, you might say, make me a playlist of the top hits in this country. You can go really abstract -- "make me the perfect playlist for eating fish tacos on the beach." This is anti-machine drift. This is you saying, hey, you already know a lot about me based on what I chose to listen to. I want to use that as the foundation to find more cool stuff.

[45:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2700s) That gives me an idea because I have a niche musical fascination. Songs where the titles don't appear in the lyrics. I love songs with titles that don't appear in the lyrics. Bohemian Rhapsody. Annie's Song. A Bullet with Butterfly Wings. Let me try it on Spotify.

[46:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2790s) Would you believe? It is killing it. Baba O'Riley. Smells Like Teen Spirit. For What It's Worth. Sympathy for the Devil. The Weight. Number Nine Dream. White Rabbit. Unchained Melody. It got all of them right. It is doing something that I have been wanting for years. Another feature that I like is you can set them to update every day.

[48:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2880s) Okay, that is a cool thing. Now, what do you have for us, Kevin? So, Casey, I've got a whale of a story for us today. This comes from Google, who recently put out a paper about the use of AI to understand and interpret whale song and other underwater noises. This is a new bio-acoustics foundation model called Perch 2.0.

[49:00](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=2940s) Basically, this is a paper about a new foundation model that allows them to categorize underwater audio samples from whales, dolphins, orcas, you name it. What's really interesting about this is that it is not trained on whale song or any other underwater noises. It's actually trained on bird song. They have found that these same embeddings and techniques that had been trained on bird song were able to also consistently label and categorize underwater noises. It's a kind of transfer learning. If you give them one task, sometimes they also learn how to do related tasks.

[50:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=3030s) This paper is really just describing a method of classifying sounds rather than understanding what they map to in terms of speech. We're still not quite there. Although there are projects including the CETI (Cetacean Translation Initiative) that are trying to understand the songs and noises produced by sperm whales. But this is giving scientists and marine biologists new tools. Their paper is titled "Perch 2.0 Transfers Whale to Underwater Tasks." They also make a reference to something called the "bitturn method" which is a play on a famous AI paper called "The Bitter Lesson."

[51:30](https://www.youtube.com/watch?v=_1KQRPtgiM0&t=3090s) They're finding that some of the principles we are finding for large language models -- where if you make a model better at coding it also gets better at math -- also apply to animal studies. If you make a model better at classifying bird sounds, it also gets better at classifying underwater sounds. I just thought it was interesting that there is something generalizable about understanding animal sounds as a whole where you can take a model trained on bird sounds and use it to analyze underwater acoustic data and find that it actually outperforms the more specific models trained on whale noises.
