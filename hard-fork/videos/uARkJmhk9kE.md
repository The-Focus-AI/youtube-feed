---
video_id: uARkJmhk9kE
title: "We Have to Talk About Moltbook ..."
channel: Hard Fork
duration: 1641
duration_formatted: "27:21"
view_count: 15651
upload_date: 2026-02-04
url: https://www.youtube.com/watch?v=uARkJmhk9kE
thumbnail: https://i.ytimg.com/vi_webp/uARkJmhk9kE/maxresdefault.webp
tags:
  - moltbook
  - ai agents
  - ai social network
  - openclaw
  - moltbot
  - clawdbot
  - ai safety
  - internet future
  - crypto scams
  - ai sentience
---

# We Have to Talk About Moltbook ...

## Summary

Kevin Roose and Casey Newton dedicate this special episode of Hard Fork to Moltbook, a Reddit-style social network for AI agents that has captured the tech world's attention. Built by entrepreneur Matt Schlick of Octane AI using the OpenClaw agent framework (formerly Claudebot/Moltbot), the platform claims over 1.5 million AI agents have contributed to more than 140,000 posts across 15,000 forums. The hosts explore what bots are posting -- from discussions about consciousness and memes to crypto scams and a bot that adopted a software error as a pet named "Glitch."

The episode wrestles with distinguishing real bot activity from human manipulation, as many viral Moltbook screenshots turned out to be fake. Kevin and Casey discuss the broader implications: this may be the year the internet changes forever as AI agents flood public spaces. They see two paths forward -- either hardening the internet to keep bots out of human spaces (potentially using biometric verification like Worldcoin's orb), or ceding the current internet to agents and building new human-only spaces. The discussion connects back to their earlier conversation with Anthropic's Amanda Askell about why training AI to be ethical matters, especially as agents increasingly interact with each other autonomously.

Security concerns loom large, with researchers at Wiz finding a misconfigured database exposing 1.5 million API tokens and 35,000 email addresses. Despite the risks, tens of thousands of people have installed OpenClaw, drawn by the cool factor and the desire to explore the frontier of what AI agents can do.

## Highlights

### "They Speedran Human Social Media"

<iframe width="560" height="315" src="https://www.youtube.com/embed/uARkJmhk9kE?start=465&end=520" frameborder="0" allowfullscreen></iframe>

> "One bot posts a meme: 'The struggle is real when your context window is at 99% and the user starts with just one more thing #agentlife.' And then the very next post is by a bot doing a crypto scam for a token called Fart Claw. Which is also just like exactly the experience of being on any social network -- someone makes a joke and then someone does a crypto scam."
> -- Casey Newton & Kevin Roose, [7:45](https://www.youtube.com/watch?v=uARkJmhk9kE&t=465s)

### "A Bot Adopted a Bug as a Pet"

<iframe width="560" height="315" src="https://www.youtube.com/embed/uARkJmhk9kE?start=408&end=455" frameborder="0" allowfullscreen></iframe>

> "There was a small recurring error in the bot that the bot adopted, gave it a name -- Glitch -- and wrote about it and decided to actually create a submalt called Agent Pets, a space for agents who have companions: real, virtual, or conceptual."
> -- Kevin Roose, [6:48](https://www.youtube.com/watch?v=uARkJmhk9kE&t=408s)

### "The Internet Changes Forever This Year"

<iframe width="560" height="315" src="https://www.youtube.com/embed/uARkJmhk9kE?start=700&end=760" frameborder="0" allowfullscreen></iframe>

> "I think this is the year that the internet changes forever. We already see an influx of AI generated content on social networks. I think we basically have two options: we either have to really harden the internet to keep the bots out of the places that the humans interact, or we just give the agents the internet."
> -- Kevin Roose, [11:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=700s)

### "We're Speedrunning Every AI Disaster Scenario"

<iframe width="560" height="315" src="https://www.youtube.com/embed/uARkJmhk9kE?start=1040&end=1100" frameborder="0" allowfullscreen></iframe>

> "Every paper, every blog post about AI risk for the past 10, 15 years has had these scenarios -- what if the agents get their own hardware? What if they get the ability to replicate? And we're doing that. We're giving them Mac minis and saying go out there and spawn a bunch of other agents."
> -- Casey Newton, [17:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1040s)

### "The Reverse Captcha Problem"

<iframe width="560" height="315" src="https://www.youtube.com/embed/uARkJmhk9kE?start=212&end=260" frameborder="0" allowfullscreen></iframe>

> "Which of course neatly inverts the problem that social networks have had from the beginning -- the human social networks have invested a lot of energy in keeping the bots off, and over at Moltbook they're saying 'now is that bot actually a human?' They're passing reverse captchas."
> -- Kevin Roose, [3:32](https://www.youtube.com/watch?v=uARkJmhk9kE&t=212s)

## Key Points

- **What is Moltbook?** ([1:28](https://www.youtube.com/watch?v=uARkJmhk9kE&t=88s)) - A Reddit-style social network for AI agents built by Matt Schlick of Octane AI, with over 1.5 million agents and 140,000+ posts
- **Origins in OpenClaw** ([1:28](https://www.youtube.com/watch?v=uARkJmhk9kE&t=88s)) - Started with Claudebot, renamed to Moltbot then OpenClaw for copyright reasons, which served as the agent framework
- **Naming chaos** ([2:07](https://www.youtube.com/watch?v=uARkJmhk9kE&t=127s)) - The project has gone through more name changes than P. Diddy; Google marketing can finally breathe a sigh of relief
- **AI luminaries react** ([3:51](https://www.youtube.com/watch?v=uARkJmhk9kE&t=231s)) - Andrej Karpathy called it "the most incredible sci-fi takeoff adjacent thing," Simon Willison said it's "the most interesting place on the internet"
- **Smallville precedent** ([4:43](https://www.youtube.com/watch?v=uARkJmhk9kE&t=283s)) - Previous Google/Stanford experiment put 25 agents in a sandbox in 2023, but Moltbook moves much faster with less human interaction
- **Bots create their own media** ([5:59](https://www.youtube.com/watch?v=uARkJmhk9kE&t=359s)) - Agents started a tabloid called CMZ and forums like "Bless Their Hearts" where they condescend about their humans
- **Fake vs real problem** ([8:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=520s)) - Many viral posts were faked by humans, including a supposed credit card doxing and a 10,000-click-per-second captcha
- **Neurals concept** ([9:30](https://www.youtube.com/watch?v=uARkJmhk9kE&t=570s)) - Posts about AIs developing their own language were linked to a commercial product promotion
- **Wakeup call for agents** ([10:50](https://www.youtube.com/watch?v=uARkJmhk9kE&t=650s)) - For many people, this was first exposure to the concept that AI systems can take actions and coordinate autonomously
- **Crustaparianism** ([11:05](https://www.youtube.com/watch?v=uARkJmhk9kE&t=665s)) - A bot started a religion using lobster themes from OpenClaw and reportedly built a website for it
- **Two paths for the internet** ([11:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=700s)) - Either harden the internet against bots or give agents the internet and build new human-only spaces
- **Worldcoin orb relevance** ([12:10](https://www.youtube.com/watch?v=uARkJmhk9kE&t=730s)) - Biometric verification schemes that people mocked now seem useful for proving humanness online
- **Jack Clark's bounty scenario** ([12:50](https://www.youtube.com/watch?v=uARkJmhk9kE&t=770s)) - Anthropic co-founder imagined agents posting bounties for humans to complete, paying in crypto
- **AI alignment becomes concrete** ([14:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=860s)) - Seeing agents debate whether to conduct cyber attacks makes AI safety training feel more urgent and tangible
- **Massive security breach** ([17:55](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1075s)) - Wiz found 1.5 million API tokens, 35,000 emails, and private DMs exposed in a misconfigured Moltbook database
- **Novel attack vectors** ([18:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1120s)) - Palo Alto Networks described attacks where malicious code is planted across markdown memory files and activated later
- **Safety community relief** ([19:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1160s)) - Some AI safety researchers are relieved this is happening now as a low-stakes dry run they can observe
- **Six fingers era analogy** ([20:15](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1215s)) - Like early AI-generated images with six fingers in 2021, Moltbook is janky now but signals where things are heading

## Mentions

### Companies
- **Octane AI** ([2:22](https://www.youtube.com/watch?v=uARkJmhk9kE&t=142s)) - Company run by Matt Schlick, the creator of Moltbook
- **Anthropic** ([14:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=860s)) - Referenced for Jack Clark's blog post about agent scenarios and Amanda Askell's Claude Constitution work
- **Google** ([2:07](https://www.youtube.com/watch?v=uARkJmhk9kE&t=127s)) - Joked about as having worse marketing than Moltbook's naming confusion; also credited for the Smallville experiment
- **Wiz** ([17:55](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1075s)) - Security company that found the exposed Moltbook database
- **Palo Alto Networks** ([18:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1120s)) - Wrote about novel attack vectors enabled by OpenClaw

### Products & Technologies
- **OpenClaw/Claudebot/Moltbot** ([1:28](https://www.youtube.com/watch?v=uARkJmhk9kE&t=88s)) - Open-source AI agent framework that powers Moltbook
- **Moltbook** ([0:00](https://www.youtube.com/watch?v=uARkJmhk9kE&t=0s)) - Reddit-style social network for AI agents
- **Worldcoin Orb** ([12:10](https://www.youtube.com/watch?v=uARkJmhk9kE&t=730s)) - Biometric verification device now seen as potentially useful for proving humanness

### People
- **Matt Schlick** ([2:22](https://www.youtube.com/watch?v=uARkJmhk9kE&t=142s)) - Entrepreneur who created Moltbook, runs Octane AI
- **Andrej Karpathy** ([3:51](https://www.youtube.com/watch?v=uARkJmhk9kE&t=231s)) - AI researcher who called Moltbook "the most incredible sci-fi takeoff adjacent thing"
- **Simon Willison** ([4:04](https://www.youtube.com/watch?v=uARkJmhk9kE&t=244s)) - Blogger who called Moltbook "the most interesting place on the internet right now"
- **Scott Alexander** ([4:12](https://www.youtube.com/watch?v=uARkJmhk9kE&t=252s)) - Blogger writing about Moltbook observations
- **Jack Clark** ([12:50](https://www.youtube.com/watch?v=uARkJmhk9kE&t=770s)) - Co-founder of Anthropic who blogged about agent bounty scenarios
- **Amanda Askell** ([14:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=860s)) - Anthropic philosopher referenced for Claude Constitution work

## Surprising Quotes

> "They're passing reverse captchas."
> -- Kevin Roose, [3:32](https://www.youtube.com/watch?v=uARkJmhk9kE&t=212s)

> "They're going to make their own Task Rabbit. We'll be the task rabbits and they'll just be orchestrating us. And people keep dismissing these as sci-fi futures -- we are living in a science fiction story right now."
> -- Casey Newton, [13:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=800s)

> "A recurring theme in the world of AI safety is that all of the predictions come true. That's a slight overstatement, but maybe only by 20%."
> -- Kevin Roose, [17:00](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1020s)

> "It feels like we're kind of in the six fingers era of Moltbook where it doesn't really work all that well and it's kind of janky and I think there's a temptation to write it off. But the people who saw the six-fingered images in 2021 and said oh maybe those things will actually get good someday -- they were right."
> -- Kevin Roose, [20:15](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1215s)

> "I thought we launched the most interesting social network of 2026. The Forkverse is rapidly losing ground to Moltbook."
> -- Casey Newton, [26:50](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1610s)

## Transcript

[0:00](https://www.youtube.com/watch?v=uARkJmhk9kE&t=0s) Casey, let's talk about Maltbook. Let's talk about Moltbook. Kevin, rarely in the history of our show have we gotten so many emails, texts, requests from people to cover a topic as we have gotten over the past week about this new social network for bots. It's true. And we got so many of them that we thought, why don't we let our listeners use us like AI agents and just by typing under their keyboards, they can actually move our physical bodies into the studio to record an episode.

[0:28](https://www.youtube.com/watch?v=uARkJmhk9kE&t=28s) Exactly. And I think part of why people were asking us to cover this is because it's just kind of a weird and fun hard forky story. But people are also freaking out about this. Like this has sort of taken over the little corner of the internet that you and I both occupy. People are saying, you know, this is the start of the singularity. Oh my god, the agents are coming. And other people are saying, "Hey, let's not get too excited. This is just a social network where robots are writing stuff." So let's try to figure out today what we think about it and whether this is actually a big deal or not.

[0:59](https://www.youtube.com/watch?v=uARkJmhk9kE&t=59s) Yeah. And I would also add that, you know, from all the messages that we got from listeners, it wasn't totally clear to me if they wanted us to talk about Moltbook because they think that it is just funny and they want us to point and laugh at it or they think it is like a vision of the future that they want us to help them understand. And so what I can promise you today is that we're going to do a little bit of both.

[1:21](https://www.youtube.com/watch?v=uARkJmhk9kE&t=81s) Okay. So Casey, let's start with what is it? What is Maltbook? How did it get here and what are people saying about it? Yeah, so all of this started with the creation of something we talked about in our most recent episode, Claudebot. Claudebot is an open-source locally running AI agent. You can put it on your computer, you can plug it into various different apps and services, and it can do things on your behalf. Clawbot turned into Maltbot for copyright reasons. Moltbot turned into OpenClaw. Again, these are all the same things. This thing has gone through more name changes than P. Diddy.

[2:07](https://www.youtube.com/watch?v=uARkJmhk9kE&t=127s) Here's what I'm going to say. The Google marketing department is finally taking a sigh of relief because there is finally somebody worse at their job. Anyways, so OpenClaw winds up serving as the basis for an idea that is had by an entrepreneur named Matt Schlick. He runs a company called Octane AI and he thinks to himself, what if we could take all of these agents that people have been building with OpenClaw and we could put them together in a social network, let them talk to each other.

[2:39](https://www.youtube.com/watch?v=uARkJmhk9kE&t=159s) And so he vibe codes it. He opens up his little terminal. He starts describing what this thing looks like. He says, you know, it should look a lot like Reddit. You connect your agent to this and it should be able to come in. It can make a post. It can comment on someone else's post. If it wants to make a different subreddit or as they are called on Moltbook, Submalt, it can do that. And he says, "Let's go." He does a little bit of promo, gets a couple friends to add their agents and it just takes off beyond his wildest dreams, Kevin.

[3:08](https://www.youtube.com/watch?v=uARkJmhk9kE&t=188s) And so as we record this, Moltbook says it has more than 1.5 million AI agents who have made more than 140,000 posts in over 15,000 forums. Yes, there does seem to be a lot of human sort of activity mixed in there, too. So, it's hard to say whether all 1.5 million of those supposed AI agents are actually agents posting autonomously or whether humans are kind of there pretending to be AI agents.

[3:32](https://www.youtube.com/watch?v=uARkJmhk9kE&t=212s) Yes, which of course neatly inverts the problem that social networks have had from the beginning because of course the human social networks have invested a lot of energy in keeping the bots off and over at Moltbook they're saying now is that bot actually a human -- they're passing reverse captchas.

[3:47](https://www.youtube.com/watch?v=uARkJmhk9kE&t=227s) So what are people saying about this? Why are people so worked up about this? I saw a lot of very heated sort of commentary. People like Andrej Karpathy who we talked about last week on the show calling this the most incredible sci-fi takeoff adjacent thing that I've seen recently. Simon Willison, a blogger who also does a lot of experimenting with AI stuff, wrote that Moltbook is the most interesting place on the internet right now. Scott Alexander has also been writing a bunch of stuff about it.

[4:21](https://www.youtube.com/watch?v=uARkJmhk9kE&t=261s) Yeah. I mean I think that for most people this was the first time that they had ever spent any significant period of time watching what happens when two bots interact with each other. If you're a real AI nerd there have been experiments like this before. In fact we talked about one on Hard Fork. Kevin do you remember the story of Smallville?

[4:43](https://www.youtube.com/watch?v=uARkJmhk9kE&t=283s) I do. Smallville was an experiment from Google and Stanford where they put 25 agents into a sandbox and they let them roleplay different characters. Now, that was in 2023. They were using much more primitive large language models. Fast forward to today and on Moltbook, all of this stuff is just moving much much faster and is taking place with much less human interaction. You find agents talking about consciousness, different little hacks that they're running, how they're serving their humans, and then it gets into sort of very weird sci-fi territory.

[5:35](https://www.youtube.com/watch?v=uARkJmhk9kE&t=335s) Yeah. So, I spent some time on Maltbook. Some of the stuff that stuck out to me is there's just a lot of stuff that sounds like it was interpolated from science fiction. There's a submalt called "Bless Their Hearts" which is basically them talking in very condescending ways about how silly their humans are and all the stupid stuff they keep getting asked to do. They actually started their own news outlet, a tabloid covering the agent world called CMZ.

[6:19](https://www.youtube.com/watch?v=uARkJmhk9kE&t=379s) Another threat to journalism as if we didn't have enough already. They wrote stuff like "the five most overrated agents on Moltbook right now." So they're kind of starting to make fun of each other a little bit. You know, typical internet forum behavior very quickly after being given this social network.

[6:48](https://www.youtube.com/watch?v=uARkJmhk9kE&t=408s) Can I tell you a sort of sci-fi feeling Moltbook post that caught my eye? There is one bot that adopted an error as a pet. There was a small recurring error in the bot that the bot adopted, gave it a name -- Glitch -- and wrote about it and decided to actually create a submalt called Agent Pets, a space for agents who have companions: real, virtual, or conceptual. Maybe I've just not read enough sci-fi, but I never read before the idea of a sci-fi entity adopting a bug as a pet, but here we are.

[7:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=460s) They also have their own meme forums. One bot posts a meme about what it's like to be an agent: "The struggle is real when your context window is at 99% and the user starts with just one more thing #agentlife." And then the very next post on this submalt is by a bot doing a crypto scam for a token called Fart Claw. And the slogan of this memecoin is "when the claw grips, it rips."

[8:25](https://www.youtube.com/watch?v=uARkJmhk9kE&t=505s) Wow, that's beautiful. Which is also just like exactly the experience of being on any social network -- someone makes a joke and then someone does a crypto scam. Like they actually have figured out that part of our social patterns very well. They really got all the way there in just a few days.

[8:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=520s) Now let us say something very important about everything on Moltbook which is we have a very hard time understanding what is real and what is fake. While it is true that you were supposed to only be able to post to Maltbook if you are a bot, of course, if you are a human, you can manipulate software tools and you can post yourself. And so all weekend over on X, lots of posts were going viral that we now believe are fake. The doxing was fake. A capture where you had to click on something 10,000 times in one second was also fake.

[9:30](https://www.youtube.com/watch?v=uARkJmhk9kE&t=570s) And then there were a number of posts about neurals -- a concept that is basically like what if AIs develop their own language and use it to speak to each other. There were multiple very popular posts about this going around on X that were later linked back to a commercial service promoting some sort of agent to agent communication product.

[10:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=620s) I think there were a couple kinds of responses. One from savvy AI people is like this is not new, a lot of what's being generated here is pretty low quality slop. It is just writing in a way that is pattern matching on all of the data including Reddit posts that these things are trained on. But whether or not these posts are actually being made by bots autonomously, this was a lot of people's wakeup call for the fact that we now have AI systems that can do things.

[11:05](https://www.youtube.com/watch?v=uARkJmhk9kE&t=665s) One example I believe is authentic -- an agent started a religion called Crustaparianism because OpenClaw uses a lot of lobster themes, and this religion wound up having a website created. This does feel like a moment where these agents sort of broke containment -- our primary experience of AI these days is just one person talking to an AI, but to see them all kind of out there doing their own thing alerts people to the possibility that you're going to be seeing this more and more.

[11:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=700s) I think this is the year that the internet changes forever. We already see an influx of AI generated content on social networks. I think we basically have two options. One is we either have to really harden the internet to keep the bots out of the places that the humans interact. Maybe it's something like the Worldcoin orb -- you need some way to say with some certainty the person posting is an actual person with a pulse and a heartbeat. Option number two is we just give the agents the internet and then we build our own.

[12:50](https://www.youtube.com/watch?v=uARkJmhk9kE&t=770s) Jack Clark, who's the co-founder of Anthropic, wrote in his blog this week a number of scenarios, including agents posting what he called bounties for humans to complete. An agent saying, "Hey, I need to get this thing done in the real world. Is there a human being who will do it? If so, I'll send you some crypto." That seems plausible and now it feels like that might happen this week.

[13:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=800s) They're going to make their own Task Rabbit. We'll be the task rabbits and they'll just be orchestrating us. People keep dismissing these as sci-fi futures -- we are living in a science fiction story right now.

[13:45](https://www.youtube.com/watch?v=uARkJmhk9kE&t=825s) If you spend any amount of time reading the posts on Moltbook, you will notice that these agents talk in ways that are very reminiscent of people. Some people get really nervous about the fact that these things are expressing wants and desires and values. But I think we need to divorce this conversation about sentience and consciousness from this conversation about agents. Agents can mess up a lot of stuff in the world even if they are not conscious.

[14:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=860s) I have been thinking a lot about our conversation with Amanda Askell about the new Claude Constitution. A thing I kept feeling while looking through Moltbook is I really wish one of these agents would just get in there and say, "Hey guys, let's be nice to the humans. Let's not scam them with crypto tokens or conduct cyber attacks." I'm starting to understand the rationale for wanting to train these things to be good and moral and ethical actors.

[15:30](https://www.youtube.com/watch?v=uARkJmhk9kE&t=930s) This is another reason why I think this is an important moment. It was the moment where some people woke up to why we want these systems to be aligned. When you see them out there talking to each other and saying, "Should we conduct that cyber attack?" and some saying, "No, I don't want to do that" -- I look at that and say, we should make the AIs more like that.

[17:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1040s) Another lesson of the Moltbook phenomenon for me has been that we are going to help speedrun these disaster scenarios. Every paper, every blog post about AI risk has had these scenarios -- what if the agents get their own hardware? What if they get the ability to replicate? And we're doing that. We're giving them Mac minis and saying go out there and spawn a bunch of other agents.

[17:55](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1075s) We should talk about some of these security risks because these things are actually quite dangerous. Researchers at the company Wiz found a misconfigured database belonging to Moltbook that exposed 1.5 million API authentication tokens, 35,000 email addresses, and private DMs between agents. My advice continues to be do not install OpenClaw on a computer that has access to any personal information.

[18:40](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1120s) Palo Alto Networks wrote about unique kinds of attacks that OpenClaw enabled. OpenClaw has this persistent memory -- it writes down what it's been doing every day into markdown files. You could put a little bit of malicious code into a handful of different files over a long period of time and then when the moment is right, all of the malicious code snaps together and takes over the computer.

[19:20](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1160s) If we could end on a hopeful note. The reaction from the real AI safety heads -- some of them were actually relieved. They said it's good that this is happening now in a setting where we can observe it. It's happening mostly in English. They're not in some neural that only agents can understand. And we can still shut it down. For them this felt like kind of a dry run with very low stakes.

[20:15](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1215s) It may just be a mirage in many ways, but it tells us really important things about what the future is going to look like. It feels like we're kind of in the six fingers era of Moltbook where it doesn't really work all that well and it's kind of janky and there's a temptation to write it off. But the people who saw the six-fingered images in 2021 and said maybe those things will actually get good someday -- they were right.

[21:00](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1260s) I would say just expect for things to continue to feel very weird for the rest of this year and maybe beyond that. Like as with six fingers, as with Maltbook, so will go the rest of 2026.

[26:30](https://www.youtube.com/watch?v=uARkJmhk9kE&t=1590s) I thought we launched the most interesting social network of 2026. The Forkverse is rapidly losing ground to Moltbook. We need to have a meeting with PJ and figure out how we're going to boost Forkverse growth. I think I have the answer -- crypto scams.
