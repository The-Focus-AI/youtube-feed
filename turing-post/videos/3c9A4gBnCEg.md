---
video_id: 3c9A4gBnCEg
title: "When AI Agents Start Hiring Humans: The Meatspace Layer Explained"
channel: Turing Post
duration: 793
duration_formatted: "13:13"
view_count: 429
upload_date: 2026-02-09
url: https://www.youtube.com/watch?v=3c9A4gBnCEg
thumbnail: https://i.ytimg.com/vi_webp/3c9A4gBnCEg/maxresdefault.webp
tags:
  - AI
  - Agents
  - Robotics
  - FutureOfWork
  - MechanicalTurk
  - ImageNet
  - AlexNet
  - RLHF
  - LLMs
  - MCP
  - TuringPost
  - AttentionSpan
  - Rentahuman
---

# When AI Agents Start Hiring Humans: The Meatspace Layer Explained

## Summary

This episode of Attention Span examines RentAHuman.ai, a new service launched in February 2026 by crypto engineer Alexander Liplo that allows AI agents to hire humans for physical tasks in the real world. Within just 72 hours of launching, the platform gained nearly 100,000 human sign-ups and received close to a million site visits. The host places this development in a sweeping historical context, tracing a direct lineage from Amazon Mechanical Turk through ImageNet, AlexNet, and RLHF to arrive at what she calls the "meatspace layer" -- humans serving as physical actuators for AI systems.

The video argues that human labor has always been the hidden engine behind AI breakthroughs. Mechanical Turk workers enabled Fei-Fei Li to build ImageNet with 49,000 labelers from 167 countries, which in turn enabled the AlexNet deep learning revolution of 2012. Similarly, RLHF relied on thousands of low-paid human contractors to align large language models with human values. Now, with RentAHuman.ai, the relationship has fundamentally flipped: AI is the client, the requester, the one with the task list.

The host raises important questions about liability, labor dignity, and safety while acknowledging the platform is still experimental and raw. She draws a poetic parallel between the original Mechanical Turk -- a fake automaton hiding a real human -- and RentAHuman.ai, which she describes as real automatons using actual humans as their hands and feet in the physical world. The video suggests this may be a first glimpse into a much larger economic and societal shift.

## Highlights

### "From Decision Makers to Infrastructure"

<iframe width="560" height="315" src="https://www.youtube.com/embed/3c9A4gBnCEg?start=562&end=600" frameborder="0" allowfullscreen></iframe>

> "The crazy part of it is that some people would say that from the decision makers, from supervisors, we became infrastructure. We are physical actuators in the AI world."
> -- Turing Post, [9:22](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=562s)

### "Human Presence as an API"

<iframe width="560" height="315" src="https://www.youtube.com/embed/3c9A4gBnCEg?start=535&end=565" frameborder="0" allowfullscreen></iframe>

> "RentAHuman.ai turns human presence itself into an API. An AI agent managing logistics can now verify that a retail location actually exists thanks to a human."
> -- Turing Post, [8:55](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=535s)

### "AI is the Client Now"

<iframe width="560" height="315" src="https://www.youtube.com/embed/3c9A4gBnCEg?start=455&end=500" frameborder="0" allowfullscreen></iframe>

> "The relationship has fundamentally flipped. For 20 years, humans hired AI to directed human labor to train AI. And now the premise is that AI is the client. AI is the requester. AI is the customer."
> -- Turing Post, [7:35](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=455s)

### "Without Mechanical Turk, ImageNet Does Not Exist"

<iframe width="560" height="315" src="https://www.youtube.com/embed/3c9A4gBnCEg?start=291&end=340" frameborder="0" allowfullscreen></iframe>

> "Without Mechanical Turk's human labor infrastructure, ImageNet does not exist. Without ImageNet, what happens next does not exist."
> -- Turing Post, [4:51](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=291s)

### "The Joke Has Come Full Circle"

<iframe width="560" height="315" src="https://www.youtube.com/embed/3c9A4gBnCEg?start=734&end=775" frameborder="0" allowfullscreen></iframe>

> "In 2026, RentAHuman.ai is the inverse. Real automatons pretending to have bodies with actual humans hidden inside their systems acting as their hands and feet in the world. The joke has come full circle, except it's not a joke anymore."
> -- Turing Post, [12:14](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=734s)

## Key Points

- **RentAHuman.ai Launch** ([0:26](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=26s)) - A new service by crypto engineer Alexander Liplo that allows AI agents to hire humans for physical tasks, gaining nearly 100,000 human sign-ups in 72 hours
- **AI as the Customer** ([0:55](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=55s)) - The customers of RentAHuman.ai are not humans but AI agents and autonomous software
- **Historical Context: Mechanical Turk** ([1:41](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=101s)) - Amazon launched Mechanical Turk in 2005, creating the first data labeling infrastructure where humans completed microtasks for AI systems
- **The Original Mechanical Turk** ([1:52](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=112s)) - Named after an 18th century hoax chess-playing automaton that was actually a person hidden inside a machine
- **Fei-Fei Li's Radical Hypothesis** ([2:48](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=168s)) - In 2006, Fei-Fei Li proposed that the bottleneck in computer vision was data, not algorithms, inspired by how children learn through thousands of examples
- **ImageNet Scale** ([3:43](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=223s)) - The goal was over 14 million images across 20,000+ categories; people thought it was impossible
- **Mechanical Turk Enables ImageNet** ([4:07](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=247s)) - 49,000 workers from 167 countries labeling images at 50 images per minute made ImageNet possible via crowdsourcing
- **The AlexNet Moment** ([5:32](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=332s)) - In September 2012, AlexNet achieved 15.3% error rate on ImageNet, shattering the competition by over 10 percentage points and launching the deep learning revolution
- **Key Insight: Deep Learning's Human Foundation** ([6:21](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=381s)) - Everything we call modern AI -- ChatGPT, DALL-E, self-driving cars -- traces back to 49,000 Mechanical Turk workers labeling millions of images
- **RLHF and Human Contractors** ([6:38](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=398s)) - Large language models were aligned using thousands of low-paid human contractors from Kenya, Philippines, and Venezuela ranking AI responses
- **Humans Teaching AI** ([7:23](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=443s)) - Throughout AI history, humans were not writing AI but teaching it to see, understand, and align with human values
- **The Embodiment Problem** ([8:17](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=497s)) - RentAHuman.ai solves AI's fundamental limitation: it exists in purely digital reality and cannot interact with the physical world
- **Physical Use Cases** ([9:04](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=544s)) - AI agents can verify retail locations, photograph safety equipment, or walk through properties before finalizing transactions
- **MCP Integration** ([10:31](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=631s)) - The platform uses Model Context Protocol (MCP), allowing AI to hire humans with a single API call without understanding hiring or contracts
- **Open Questions** ([10:54](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=654s)) - Questions of liability, safety, labor dignity, and whether it is acceptable for humans to work for AI remain unresolved
- **Platform Immaturity** ([11:18](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=678s)) - The platform currently has minimal verification, allowing impersonation; founder acknowledges trying to patch these issues
- **Historical Parallel** ([11:55](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=715s)) - If Mechanical Turk enabled deep learning, services like RentAHuman.ai might enable an entirely new paradigm
- **Full Circle Metaphor** ([12:14](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=734s)) - The Mechanical Turk was a fake automaton hiding a real human; RentAHuman.ai is real automatons using real humans as their physical presence

## Mentions

### Companies
- **Amazon** ([1:52](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=112s)) - Launched Mechanical Turk in 2005, creating the first human-as-a-service data labeling platform
- **Google** ([6:12](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=372s)) - Acquired Geoffrey Hinton's startup after the AlexNet moment, pivoting to deep learning
- **RentAHuman.ai** ([0:31](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=31s)) - New service allowing AI agents to hire humans for physical tasks, launched February 2026

### Products & Technologies
- **Amazon Mechanical Turk** ([1:52](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=112s)) - Amazon's crowdsourcing marketplace for human intelligence tasks (HITs)
- **ImageNet** ([3:36](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=216s)) - Dataset of 14+ million images across 20,000+ categories built by Fei-Fei Li using crowdsourced labor
- **AlexNet** ([5:47](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=347s)) - Deep convolutional neural network that won the 2012 ImageNet challenge with 15.3% error rate
- **RLHF (Reinforcement Learning with Human Feedback)** ([6:58](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=418s)) - Training method for large language models using human contractors to rank responses
- **MCP (Model Context Protocol)** ([10:34](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=634s)) - Protocol used by RentAHuman.ai enabling AI to hire humans via a single API call
- **ChatGPT** ([6:21](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=381s)) - Referenced as part of the AI revolution tracing back to ImageNet and deep learning
- **DALL-E** ([6:24](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=384s)) - Referenced alongside ChatGPT as modern AI enabled by the deep learning revolution
- **WordNet** ([3:39](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=219s)) - Linguistic database whose structure inspired ImageNet's category organization
- **ILSVRC** ([5:08](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=308s)) - ImageNet Large Scale Visual Recognition Challenge launched by Fei-Fei Li in 2010

### People
- **Alexander Liplo** ([0:40](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=40s)) - Crypto engineer and founder of RentAHuman.ai
- **Fei-Fei Li** ([2:48](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=168s)) - Computer scientist who built ImageNet, hypothesized that data scale was the bottleneck in computer vision
- **Geoffrey Hinton** ([5:37](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=337s)) - Led the University of Toronto team behind AlexNet; his startup was acquired by Google
- **Alex Krizhevsky** ([5:41](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=341s)) - Student of Hinton who co-created AlexNet
- **Ilya Sutskever** ([5:41](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=341s)) - Student of Hinton who co-created AlexNet

## Surprising Quotes

> "The customers are not humans. They are AI agents and autonomous software that can now hire you, human, to do physical tasks in the real world."
> -- [0:57](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=57s)

> "It's absolutely true that when AI calls API on you, when AI calls RentAHuman.ai to rent you out, it doesn't think about you. It does think about the capability."
> -- [9:38](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=578s)

> "We've created a recursive loop. Human, AI, human, AI. Who's the boss? Who's the employee? The answer is it depends on the moment, on the task, and who initiated the chain."
> -- [10:21](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=621s)

> "Is this the future of work? Is this okay for a human to work for AI?"
> -- [10:57](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=657s)

> "Welcome to the meatspace layer."
> -- [12:44](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=764s)

## Transcript

[0:00](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=0s) Welcome back to Attention Span. Today I want to show you something that sounds like science fiction, but it's very real, very live, and happening right now. And though it sounds a bit crazy and kind of even wacky, well, we will discuss why it might be not that crazy and why it just starts something very interesting.

[0:26](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=26s) I'm talking about a new service that is called RentAHuman.ai, and really phenomenal success because it just started days ago by crypto engineer Alexander Liplo, and in a matter of 72 hours it gained like almost 100,000 users -- humans that signed up to be rentable -- and the site has received, as they showcase, nearly a million visits.

[0:55](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=55s) The interesting part is, as you might already realize, that the customers are not humans. They are AI agents and autonomous software that can now hire you, human, to do physical tasks in the real world. We will go through the process how to set up a profile, even if just out of curiosity, because for example I am not ready to rent out my time to agents. We will do this at the end of this video.

[1:20](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=80s) But first, I want to put this whole thing into the historical context and demonstrate you that humans have served machines before. And that's exactly how we ended up here in 2026 with all the agents and looming over us humanoid robots.

[1:41](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=101s) And to understand why this matters, we need to rewind 20 years to a moment that changed everything. 2005 to 2007: the birth of Mechanical Turk. In 2005, Amazon launched something called Mechanical Turk. The name came from the 18th century hoax chess-playing automaton that was actually a person hidden inside a machine. Amazon's version was the reverse -- humans hidden inside the machine of automation.

[2:09](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=129s) Back then, early AI systems could not do basic perception tasks. They couldn't identify if a photo contained a cat, couldn't transcribe messy handwriting, couldn't understand images. So Amazon created an API where humans became Human Intelligence Tasks, or HITs. Companies would send requests -- label these images, transcribe this audio, identify this object -- and humans around the world called Turkers would complete these microtasks for pennies. This was the first data labeling company.

[2:45](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=165s) So now here's where it really gets interesting. In 2006, a computer scientist named Fei-Fei Li had a radical idea. At the time, the entire field of computer vision was focused on better algorithms. Researchers would compete to squeeze out tiny improvements, maybe 1-2% accuracy gains using small data sets of a few thousand images. But Li had a different hypothesis. What if the problem was not the algorithms? What if the problem was the data?

[3:14](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=194s) She was inspired by how children learn. A child sees thousands of examples before they understand what a dog is. They see big dogs, small dogs, dogs in different poses, lighting conditions, context. Scale matters. So Fei-Fei Li set out to build something unprecedented -- a data set that would mirror the visual richness of the real world. She called it ImageNet, based on WordNet's structure of language.

[3:43](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=223s) The goal: over 14 million images across more than 20,000 categories. People literally thought she was crazy for a couple of years. She tried to get attention and support from many people. They were telling her that that scale was impossible. Who would label millions and millions of images?

[4:04](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=244s) Mechanical Turk at that moment came as a revelation. She discovered in 2007 Amazon Mechanical Turk and everything changed for Fei-Fei Li. She realized crowdsourcing could scale. Over the next two and a half years, Li and her team orchestrated something extraordinary. 49,000 workers from 167 countries labeling images at an average rate of 50 images per minute. 3.2 million images initially, eventually growing to over 14 million, and each image verified by multiple workers to ensure accuracy.

[4:43](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=283s) By 2009, ImageNet was complete. In 2012, it became the largest academic user of Mechanical Turk on the planet. And here's the key insight number one: without Mechanical Turk's human labor infrastructure, ImageNet does not exist. Without ImageNet, what happens next does not exist.

[5:03](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=303s) So in 2010, Fei-Fei Li launched the ImageNet Large Scale Visual Recognition Challenge, ILSVRC. The competition was simple: build an algorithm that can correctly classify images into 1,000 categories. For two years, traditional computer vision methods slowly improved. The best systems had error rates around 25-26%. Not great, but steady progress.

[5:32](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=332s) Then came September 30, 2012, and that changed AI forever. A team from the University of Toronto led by Geoffrey Hinton with students Alex Krizhevsky and Ilya Sutskever entered a deep convolutional neural network called AlexNet. Suddenly, AlexNet's error rate: 15.3%. This neural network didn't just win. It shattered the competition by over 10 percentage points. And nothing had ever made a leap like that.

[6:02](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=362s) This was the ImageNet moment. The moment deep learning went from academic curiosity to the foundation of modern AI. Within a year, every major company pivoted to deep learning. Google acquired Hinton's startup. The AI race was officially on.

[6:21](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=381s) So key insight number two: the entire revolution -- ChatGPT, DALL-E, self-driving cars -- everything we call modern AI that is based on deep learning traces back to that moment, and that moment was enabled by 49,000 Mechanical Turk workers labeling millions of images.

[6:38](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=398s) Now fast forward to the era of large language models. We had models that could generate text but they couldn't understand what humans actually wanted. They'd be helpful but sometimes toxic, accurate but occasionally harmful, coherent but not aligned with human values. Here comes reinforcement learning with human feedback. This is how ChatGPT was trained. You take a base model. Then you bring in thousands of human contractors, many from Kenya, from Philippines, Venezuela, very low-paid workers, and you ask them to rank responses. Which answer is better? Which one is more helpful? Which one follows instructions better?

[7:19](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=439s) So here is the key insight number three. Again, humans weren't writing the AI. We were teaching it. Teaching it to see, teaching it to understand, teaching it to align with our values.

[7:35](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=455s) And now we arrive at February 2026, RentAHuman.ai. The relationship has fundamentally flipped. For 20 years, humans hired AI to directed human labor to train AI. And now the premise is that AI is the client. AI is the requester. AI is the customer. AI is actually the one with the task list. I see the lineage from Mechanical Turk to Rent a Human. But now it's different on the scale, on the promise, how the economy of human labor can be changed in this new AI and agentic world.

[8:17](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=497s) So what does RentAHuman.ai solve? It solves what researchers call the embodiment problem. For all the advances in AI -- language models, reasoning systems, autonomous agents that can write code and negotiate contracts -- there is one fundamental limitation. AI exists in purely digital reality. AI can't walk into a building. It can't hold a physical object. It can't shake someone's hand. As the website puts it, it cannot touch the grass.

[8:45](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=525s) But we humans can. And until now, AI's interaction with the physical world happened through sensors, robots, or humans doing tasks manually. And what's interesting is that RentAHuman.ai turns human presence itself into an API. An AI agent managing logistics can now verify that a retail location actually exists thanks to a human. An AI handling compliance can send someone to photograph safety equipment. An AI closing real estate deals can have someone walk through a property before finalizing a transaction. It kind of blows my mind.

[9:22](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=562s) The crazy part of it is that some people would say that from the decision makers, from supervisors, we became infrastructure. We are physical actuators in the AI world. It's absolutely true that when AI calls API on you, when AI calls RentAHuman.ai to rent you out, it doesn't think about you. It does think about the capability. But the crazy part is that someone, actually a human, might show up for that.

[9:55](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=595s) The interest in this website demonstrated that there's a bunch of actual profiles, people who also posted their social network accounts. So you can see, you can actually check if these humans are real, and they are. Now, let's go and see how to set an account if you want to be rented out by an AI.

[10:17](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=617s) So, as you might see, we've created a recursive loop. Human, AI, human, AI. Who's the boss? Who's the employee? The answer is it depends on the moment, on the task, and who initiated the chain.

[10:31](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=631s) The interesting innovation is that this website uses MCP, Model Context Protocol. One API call, that's it. And AI doesn't need to understand human hiring, negotiation, contracts. It just says, I need a human at this location with these skills, and the platform handles the rest.

[10:54](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=654s) And there are of course many questions to that type of service. There are questions of liability and safety. Who is responsible, AI or human? There are questions of labor and dignity. Is this the future of work? Is this okay for a human to work for AI? There are also very mundane things that are common for any startup when the platform is new, raw, and undeveloped -- that is just minimal, minimal verification and people can impersonate others and all of that.

[11:24](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=684s) The founder Alexander Liplo himself tweeted about trying to patch these issues. The platform is experimental at this moment. But why I wanted to talk about it is because if Mechanical Turk set up the whole new world for deep learning to unfold, deep learning -- we might start thinking what services like this might unfold also.

[11:50](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=710s) This is a very important moment, and with all the other conditions and risks and all that stuff, we need to look ahead and think how this type of services can change the world of humans. It might be a first glimpse into a much larger shift.

[12:07](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=727s) So I want to leave you with the previous thought and another thought. In 2005, Mechanical Turk was named after a fake automaton, a chess-playing machine that was really a person hidden in the box. In 2026, RentAHuman.ai is the inverse. Real automatons pretending to have bodies, with actual humans hidden inside their systems, acting as their hands and feet in the world. The joke has come full circle, except it's not a joke anymore.

[12:44](https://www.youtube.com/watch?v=3c9A4gBnCEg&t=764s) Welcome to the meatspace layer. What do you think? Would you sign up as a rentable human? Leave me your thoughts in the comment section and let's discuss it. I think that might be a very interesting shift in this new economy. Thank you for watching. Please subscribe. Please share and like -- that helps with growth and spreading the ideas and building this knowledge. Thank you.
