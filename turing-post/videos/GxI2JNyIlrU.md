---
video_id: GxI2JNyIlrU
title: "What Really Blocks AI Progress? Ulrik Hansen from Encord thinks it's..."
channel: Turing Post
duration: 1686
duration_formatted: "28:06"
view_count: 4744
upload_date: 2025-09-20
url: https://www.youtube.com/watch?v=GxI2JNyIlrU
thumbnail: https://i.ytimg.com/vi/GxI2JNyIlrU/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Neural Networks
  - AI Breakthroughs
  - Technology and Society
  - AI in Real Life
  - Turing Post
  - AI Revolution
  - AI Trends
  - Thought Provoking AI
  - Innovators in AI
  - AI Interviews
  - AI Pioneers
  - GPT and LLMs
  - AI Explained
  - Human vs Machine
  - AI for Good
  - AI Startups
  - Robotics
  - Waymo
  - Tesla
  - SelfDriving
  - DataBottleneck
  - Encord
  - Ulrik Hansen
  - AGI
  - AI Progress
---

# What Really Blocks AI Progress? Ulrik Hansen from Encord thinks it's...

## Summary

In this episode of the Inference podcast by Turing Post, Ulrik Hansen, president and co-founder of Encord, argues that the true bottleneck in AI progress is not compute or model architecture, but data. Working with over 200 of the world's top AI teams, Hansen explains that while models have become largely interchangeable and good enough for most applications, the challenge lies in orchestrating and enriching data to provide enough context for AI systems to make accurate decisions. He draws a compelling analogy to human decision-making: just as humans cannot make sound judgments with incomplete information, AI systems are fundamentally constrained by the quality and completeness of their data.

Hansen discusses the evolution of AI challenges since ChatGPT's launch, noting that the field has moved from basic data quantity problems (like bounding box annotation) to more sophisticated data quality issues, including post-training alignment and finding long-tail edge cases. He uses self-driving as a prime example, contrasting Tesla's approach of collecting live human feedback data through their fleet of supervised vehicles with Waymo's more cautious expansion strategy. Tesla's compounding data advantage, where driver interventions are sent back as training signals, gives them what Hansen considers a significant edge over competitors who must collect data through their own fleets.

The conversation also explores the future of human-AI collaboration, with Hansen introducing the concept of a "connection economy" replacing the current "intelligence economy." He distinguishes between "cheap" intelligence (facts, pattern recognition, boilerplate tasks) that AI handles well, and "expensive" intelligence (creativity, taste, original insight, human agency) that will remain distinctly human. Hansen believes the next 10 years will bring more technological change than the last 50, with AI enabling new drug discoveries, household robots, and new professions we cannot yet conceive.

## Highlights

### "What Really Is Blocking Progress Is the Data"

[![Clip](https://img.youtube.com/vi/GxI2JNyIlrU/hqdefault.jpg)](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=45s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*0:45-1:50" "https://www.youtube.com/watch?v=GxI2JNyIlrU" --force-keyframes-at-cuts --merge-output-format mp4 -o "GxI2JNyIlrU-0m45s.mp4"
```
</details>

> "But what really is blocking progress is the data."
> — Ulrik Hansen, [0:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=45s)

### "Tesla Has a Thumbs Up Button Embedded in the Cars"

[![Clip](https://img.youtube.com/vi/GxI2JNyIlrU/hqdefault.jpg)](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=364s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*6:04-7:00" "https://www.youtube.com/watch?v=GxI2JNyIlrU" --force-keyframes-at-cuts --merge-output-format mp4 -o "GxI2JNyIlrU-6m04s.mp4"
```
</details>

> "They have like the equivalent of like a thumbs up and a thumbs down button that you're used to in chat right embedded in the cars because they have people driving the cars."
> — Ulrik Hansen, [6:17](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=377s)

### "Synthetic Data Is Like the Snake Eating Its Own Tail"

[![Clip](https://img.youtube.com/vi/GxI2JNyIlrU/hqdefault.jpg)](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1072s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*17:52-18:50" "https://www.youtube.com/watch?v=GxI2JNyIlrU" --force-keyframes-at-cuts --merge-output-format mp4 -o "GxI2JNyIlrU-17m52s.mp4"
```
</details>

> "It's kind of like the snake eating its own tail."
> — Ulrik Hansen, [18:30](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1110s)

### "More Change in 10 Years Than the Last 50"

[![Clip](https://img.youtube.com/vi/GxI2JNyIlrU/hqdefault.jpg)](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1470s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*24:30-25:30" "https://www.youtube.com/watch?v=GxI2JNyIlrU" --force-keyframes-at-cuts --merge-output-format mp4 -o "GxI2JNyIlrU-24m30s.mp4"
```
</details>

> "We're likely to see more change from technology in like the next 10 years than we've seen in the last like 50 years."
> — Ulrik Hansen, [24:38](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1478s)

### "Excellence Is Not an Act But a Habit"

[![Clip](https://img.youtube.com/vi/GxI2JNyIlrU/hqdefault.jpg)](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1632s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*27:12-28:00" "https://www.youtube.com/watch?v=GxI2JNyIlrU" --force-keyframes-at-cuts --merge-output-format mp4 -o "GxI2JNyIlrU-27m12s.mp4"
```
</details>

> "We are what we repeatedly do. Excellence then is not an act but a habit."
> — Ulrik Hansen quoting Aristotle, [27:28](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1648s)

## Key Points

- **Data is the bottleneck** ([0:31](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=31s)) - From Encord's vantage point working with 200+ top AI teams, data orchestration and enrichment is what constrains AI progress, not models which are largely interchangeable.

- **Evolution from quantity to quality** ([1:57](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=117s)) - Since ChatGPT, the AI challenge has shifted from bounding box annotation to hiring PhDs for frontier work, post-training alignment, and finding edge cases.

- **Tesla's data advantage** ([4:04](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=244s)) - Tesla collects live human feedback data through driver interventions, creating a compounding advantage that Waymo cannot match with its own fleet approach.

- **Waymo's geographic limitations** ([4:11](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=251s)) - Even successful in downtown SF, Waymo hasn't expanded to the airport due to dynamic real-world environments and edge cases.

- **Robotics follows language model trajectory** ([7:20](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=440s)) - Robotics is now where language models were in 2017-2018, with additional constraints of edge deployment and slower feedback loops.

- **Feedback loop speed determines progress** ([8:20](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=500s)) - Digital AI (chat, coding) progresses faster because feedback loops are instant; physical AI faces latency and connectivity challenges.

- **AI infrastructure parallels software development** ([9:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=589s)) - AI toolchains will develop similar to software development over 5-10 years, but with additional complexity because AI systems are dynamic.

- **Humans provide preference and uncertainty feedback** ([10:38](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=638s)) - In both consumer and enterprise contexts, humans will provide preference data and handle edge cases that models flag as uncertain.

- **Task-centric machine learning** ([13:08](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=788s)) - The field is moving from model-centric to data-centric to task-centric/context-specific ML, where AI proposes and humans verify or escalate.

- **Services vs software companies** ([14:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=856s)) - Data labeling market splits into services companies (serving hyperscalers with human experts) and software companies (serving Fortune 500 with tooling).

- **Scale AI serves different market** ([15:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=949s)) - Scale has built a fantastic business selling services to hyperscalers; Encord focuses on software for enterprise applied AI use cases.

- **Market consolidation coming** ([16:44](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1004s)) - More acquisitions expected in AI data space as data becomes recognized as the only irreplaceable ingredient for building defensible AI systems.

- **Synthetic data works for physics simulation** ([17:34](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1054s)) - Synthetic data succeeds in physics-based simulation (self-driving edge cases) but fails when models train on their own outputs, causing model collapse.

- **Hybrid human-synthetic approach wins** ([18:41](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1121s)) - Most successful companies use real-world/human data in conjunction with synthetic data.

- **Enterprise challenge: matching frontier lab resources** ([18:48](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1128s)) - Companies lack access to frontier lab resources; Encord bridges this gap with tools previously available only to labs.

- **Cheap vs expensive intelligence** ([20:37](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1237s)) - Intelligence bifurcates into cheap (facts, patterns, boilerplate) that AI handles, and expensive (agency, creativity, taste, vision) requiring humans.

- **Brand value increases with AI** ([23:24](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1404s)) - With AI misinformation risks, trusted brands become more valuable as they provide accountability and verified information.

- **Connection economy replacing intelligence economy** ([24:57](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1497s)) - Value shifts from intelligence to human connections; new unimaginable professions will emerge, like software engineering was unthinkable 150 years ago.

- **Daily Rituals book recommendation** ([25:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1545s)) - Hansen recommends "Daily Rituals: How Artists Work" by Mason Curry, emphasizing that breakthroughs come from years of consistent effort, not single insights.

## Mentions

### Companies

- **Encord** ([0:28](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=28s)) - Ulrik Hansen's company, providing data infrastructure and tools for AI teams
- **Tesla** ([5:06](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=306s)) - Example of compounding data advantage through supervised self-driving feedback loops
- **Waymo** ([4:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=256s)) - Example of cautious self-driving rollout, collecting data through own fleet
- **Scale AI** ([15:47](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=947s)) - Services-first company selling human experts to hyperscalers
- **Meta** ([15:46](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=946s)) - Mentioned in context of deal with Scale for human expert services
- **Databricks** ([16:17](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=977s)) - Analogy for enterprise software focus
- **Snowflake** ([16:18](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=978s)) - Analogy for enterprise software focus
- **Financial Times** ([24:03](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1443s)) - Example of trusted brand for objective information
- **The Economist** ([24:05](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1445s)) - Example of trusted brand for objective information

### Products & Technologies

- **ChatGPT** ([1:59](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=119s)) - Marker for when AI problem space changed
- **RGB sensors** ([6:47](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=407s)) - Tesla's computer vision approach vs Waymo's additional sensors
- **LiDAR/additional sensors** ([6:43](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=403s)) - Waymo's approach to planning and trajectory
- **Foundation models** ([7:44](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=464s)) - Base models that enterprises fine-tune for their use cases
- **Multimodal models** ([20:10](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1210s)) - Evolution from unimodal models opening new support requirements

### People

- **Ulrik Hansen** ([0:28](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=28s)) - President and co-founder of Encord, guest on the podcast
- **Mason Curry** ([26:00](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1560s)) - Author of "Daily Rituals: How Artists Work"
- **Mark Twain** ([26:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1605s)) - Featured in Daily Rituals book
- **Isaac Newton** ([26:47](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1607s)) - Featured in Daily Rituals book
- **Ayn Rand** ([26:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1609s)) - Featured in Daily Rituals book
- **Aristotle** ([27:26](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1646s)) - Quoted: "We are what we repeatedly do. Excellence then is not an act but a habit"

## Surprising Quotes

> "But what really is blocking progress is the data."
> — [0:00](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=0s)

> "They have like the equivalent of like a thumbs up and a thumbs down button that you're used to in chat right embedded in the cars because they have people driving the cars."
> — [6:17](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=377s)

> "It's kind of like the snake eating its own tail."
> — [18:30](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1110s)

> "We're likely to see more change from technology in like the next 10 years than we've seen in the last like 50 years."
> — [24:38](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1478s)

> "We are what we repeatedly do. Excellence then is not an act but a habit."
> — [27:28](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1648s)

## Transcript

[0:00](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=0s) But what really is blocking progress is the data. What I like to call like a connection economy. Excellence then is not an act but a habit. And that's like how you create the breakthrough. So yeah, I think it's like a very exciting time.

[0:19](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=19s) Hello everyone and welcome to Inference podcast by Turing Post. I'm very happy to welcome Ulrik Hansen, president and co-founder of Encord. Welcome. Thank you. Thanks for having me.

[0:33](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=33s) Let's start with a big question. If intelligence is solving tasks under uncertainty, what is still holding us back? And some people would say it's models, some people say it's inference. What's your take?

[0:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=45s) Yeah, it's a great question and something that we spend quite a lot of time thinking about. And from our vantage point, we work with more than 200 of the world's top AI teams. It really comes down to the data. So that was the original founding insight for starting Encord that the thing that wins in AI and the thing that is actually constraining progress is principally down to the data and orchestrating the data to get the models working in production.

[1:09](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=69s) Because if you think about the different ways that AI is being deployed now, the models themselves are mostly swappable and interchangeable. And I think in the vast majority of cases that we see, at least the models are for the most part good enough to add tremendous value to whatever it is that you're trying to solve. But what really is blocking progress even further is the data.

[1:31](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=91s) And so I think what's hard is getting the data orchestrated and enriched to provide enough context to the model or the system you're building via training, inference, or otherwise. And getting it to make the right decisions based on data is really the harder part. And it's almost like if you think about being a human being, right? You can't really make sound decisions and judgments with incomplete data. So you might be slightly smarter as a person, you might have a slightly better model, but if you don't have the right data, you're not going to get very far.

[1:59](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=119s) Well, you started Encord in very different times in 2021. What changed when ChatGPT went public for you as a company?

[2:07](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=127s) Yeah, it's interesting because we started the company principally focused on automating the annotation process. So at the time the problems that people had were principally around solving the data quantity problems, just like getting enough labeled training data to be able to train these base models.

[2:24](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=144s) And of course with the collaboration and the massive improvement we've seen in language models over the past year and also in AI more broadly, we've seen the problem space change from doing bounding box annotation to now all the frontier labs are hiring PhDs to do very frontier type work to continuously improve the models.

[2:44](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=164s) I think that generally comes with just us moving further up the scaling law curve, right? So we've gone from data quality to data quality is getting the right data, which is now the sort of post-training and alignment types problems for the most advanced areas of AI. And as the models generally have gotten smarter, each incremental unit of progress has become harder.

[3:05](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=185s) And I think language models and self-driving, I think the two most mature areas of AI, we see that right front and center. And so the space has evolved from again the bounding box annotation into hiring the PhDs. And I think for self-driving it's like finding all the long-tail edge cases, and that is really what is necessary to push the next frontiers of AI.

[3:24](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=204s) And we're seeing that also in other areas. Now we're seeing it in robotics where robotics probably is now where language models were in 2017-2018, where we're seeing massive improvements to the baseline which I think we're likely to see over the next couple years. But at some point the curve asymptotes and then we start moving into these more esoteric types of problems and tasks, and that's where most of the future work will be directed.

[3:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=229s) And I think we see scaling also in many different parts of AI, right? And we've sort of followed that journey since ChatGPT launched to now working with some of the world's top AI teams in how they've evolved that as well. So yeah, it's super exciting to be on the sidelines to witness how this stuff is evolving.

[4:06](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=246s) Well, give me some example of what was the most challenging things recently.

[4:11](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=251s) So taking an example for self-driving. I think one of the main challenges that they have - if you take Waymo as an example, they are now live in San Francisco but they haven't yet expanded to cover the geography all the way to San Francisco airport. So now the question is why is that, right? Why don't you have fully unsupervised self-driving given that it works so well in downtown SF?

[4:32](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=272s) And it is really down to real environments being dynamic and they change. And to eliminate all the different types of edge cases that the car might encounter in the real world is extremely difficult. So you need to basically factor that into the way that you build your data orchestration pipeline so that when the car encounters a new type of unseen scenario, you have either a heuristic to have the car solve that problem itself or you have some way of relaying the feedback back into the model.

[5:06](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=306s) And I think that's something that Tesla is doing really well, right? Because they have now supervised self-driving. And I have a Tesla myself. When I'm driving the car, sometimes I have to intervene and that data is sent directly back to Tesla. So they built this iterative feedback loop between okay actually solving the long tail as it happens. Whereas of course these robo-taxis and unsupervised types of use cases are much more difficult because they're relying on using their own drivers to go and collect that data.

[5:33](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=333s) Those are two very different strategies if we talk about Waymo and Tesla because Tesla relies basically solely on computer vision and machine learning. So what's your bet? Because I just published a little video about self-driving and I was recording video while Tesla was driving me around. So yeah, what's your take? Do you think Tesla's strategy with more data with more learning will win or Waymo's more step-by-step careful approach from a data perspective?

[6:04](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=364s) Yeah, I think the one thing that Tesla really has going for them is they just have a huge and compounding data advantage over basically every single other player in the market. They are collecting live human feedback data. They have the equivalent of a thumbs up and a thumbs down button that you're used to in chat, embedded in the cars because they have people driving the cars.

[6:26](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=386s) And so this data advantage compounds massively over time, whereas Waymo has to rely on collecting their own data. They don't have the distribution advantage that Tesla has. So inevitably I think that's a much slower rollout and a much slower build. That being said, of course they've sort of decided to add additional sensors on top of - as you pointed out, Tesla's relying on RGB. Additional sensors help inform the planning and trajectories of how the car drives and operates, which I think should be a safer option but of course is way more expensive and takes longer to build.

[6:57](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=417s) I am very bullish on Tesla actually getting ahead on this. And now they're starting to roll out their own robo-taxi fleet which they can probably do very quickly. Now the question is they probably don't have the same advantage or the same lead with working with the regulators that Waymo has. So I think that'll be an interesting dynamic to observe over the next 3 to 5 years as these systems actually go live in the different cities around the US.

[7:20](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=440s) Do robotics have the same bottlenecks as autonomous systems like self-driving or is it different?

[7:27](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=447s) Yeah, I think they have a lot of the same constraints. So I think ultimately the difficulty in deploying these robotic systems is you have the additional constraints that you have to deploy the model on specific hardware devices on edge. So you have GPU-constrained environments that you don't have if you're leveraging a foundation model like a chat interface.

[7:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=465s) You have to first and foremost make sure that your systems can actually work on these embodied AI devices, which is I think no small feat of engineering. And then creating the iterative feedback loop between the actual product usage and the model itself is also much, much harder because you might have a robot folding laundry in your house and it might fail.

[8:07](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=487s) So now how do you relay that back into the system and how it's trained? It becomes - there's of course latency for uploading the data, you might be in an area without Wi-Fi so you don't necessarily have internet connectivity. Whereas where we have seen the fastest progress in AI has been in the pure digital workflows - for language models like ChatGPT and otherwise, or coding - where the feedback loop between the actual user and the model itself is instant. That's not a luxury that you have in physical and embodied AI.

[8:36](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=516s) So the companies that are building in those domains, they have to really think carefully about how they collect that feedback. And we see it being solved in a number of different ways - some companies adding tele-operations to help steer the robot if they kind of go off the rails. But ultimately if you want them to work on a fully autonomous basis, you don't necessarily be able to rely on that. So being clever about how you build those feedback loops is going to be what determines a lot of the future compounding advantage.

[8:59](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=539s) Feedback loops - we will see more and more of that in AI agentic systems, right? How does infrastructure evolve to address that?

[9:09](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=549s) Yeah, it's a great question and something we've thought a lot about because we are building a key part of that infrastructure that makes the human feedback possible. I think what we've seen generally over the last couple years is the companies have evolved from building out the core foundations of the models that they've been building. And as they go live in production, then building the human feedback infrastructure becomes much more important.

[9:31](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=571s) And per use case, right? You have to have a lot of custom tooling. So if you're building a model that can work with LIDAR, 3D data, or video data, you need good tools. And the whole AI toolchain is just very much in development. A lot of this stuff hasn't really been built yet. So we'll see that happening over the next 5 to 10 years.

[9:51](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=591s) If you think about how the internet economy has built over the last 30 years, the development lifecycle has gotten to where we are now. I think AI is likely to happen on a much more compressed timeline. And yeah, of course we're one of the companies building in that space alongside others. What that toolchain will look like exactly - I think it will probably look like a lot of the functionality that we have in software development: version control systems, good networking protocols and all these things.

[10:20](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=620s) We will have to build out similar things for AI specifically. But the interesting quirk about AI systems is it becomes a little bit more difficult to do because they are dynamic, right? And they're sort of working in a real environment and not constrained to the same environments that software is working in, which are inevitably much more programmatic.

[10:38](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=638s) Yeah, a lot of uncertainty to deal with. 100%.

[10:41](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=641s) You were talking about involving more PhD students for annotation, working with data. So if expert feedback is the new gold, what is the role of humans in this? Is it like coexisting tasks with agents? Are humans just callable functions in this system? Who are humans here?

[11:02](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=662s) Yeah, I think ultimately the humans will be providing human preference and feedback to the AI systems, and I think that will happen in many different ways. So let's maybe take two examples.

[11:14](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=674s) One example would be you with your personal AI digital assistant. You will provide feedback to that digital system of how you like to - I don't know - when do you like to wake up in the morning, what do you like to have for breakfast. And that will continuously learn based on the human preference data that you give it. So that's on the more consumer side.

[11:31](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=691s) And I think that's already happening in ChatGPT where it's kind of getting personalized based on how much context that you've fed it. And I think that's some of the things that the frontier labs are working on - giving the models as much context as you can from your personal human preference data to be able to offer more and more customized advice and be more of an assistant to you.

[11:52](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=712s) I think in the enterprise, more on the commercial side, all human experts now are really people that are doing their day-to-day jobs. So if you're like an investment banking analyst at a big investment bank, you are doing the work. AI will be observing what you're doing. So you are quote-unquote human experts that are providing feedback to the model - how certain workflow processes and all these things should operate.

[12:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=736s) And I think as AI is getting pushed into the enterprise, that's something that is likely to become more and more prevalent. As you will be at work constantly providing feedback and work with AI to do your job essentially. So it's happening both in the rollout of AI but also happening of course at the pure training layer for pushing the frontiers of the models where we're starting to see the asymptote.

[12:43](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=763s) And that is what the frontier labs are doing behind the PhDs and the human experts - making the base foundation models better so that you have to do less customization in the future. And really the human role will be just providing feedback on the areas of uncertainty of the model, or it will be for giving human preference on how you like to get things done. Because the model naturally will not necessarily understand what you like to do or how you like to do things. And that's something that will also become way more important.

[13:08](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=788s) From what you're saying, it feels like we're moving from model-centric machine learning that was data-centric and now it's task-centric or even context-specific machine learning. Do you agree with this evolution?

[13:24](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=804s) Yeah, 100%. And I think at the end of the day the model that we will see going forward is that the AI will propose something where the human can verify or escalate certain things. The machines will handle the baseline grunt work, or the 80% of the work. But then the expert, which would be the human - let's say the investment banking analyst - will be owning the edge cases or providing their preference or providing calls on what the policy of the model should be.

[13:52](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=832s) And so I think the way that the system should be designed is for allowing complementarity between humans and AIs. The AI will allow for edits, ask for rationale, they will surface the uncertainty where it's not sure about certain things. And you kind of incentivize the model to find mistakes in how it's operating. And of course we need all the tools and the systems to be able to measure the systems - all the throughput, the cost, and the risk of this stuff as the feedback starts to compound.

[14:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=856s) There is a bunch of competitors in this field in terms of data labeling. How do you see this area evolving? What would be the role of companies like Encord?

[14:29](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=869s) Yeah, great question. So I think you can broadly think about the market that we are in in two different buckets. There are the services-first companies and then there are the tooling/software-first companies.

[14:42](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=882s) So the services-first companies principally work on supplying and finding human experts to do the expert work. That typically most often works with the frontier labs because those are the companies that actually work on those things. And then for the software companies, they principally sell all the tooling and the infrastructure to enable the first part.

[15:00](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=900s) And I think for us, we principally work with applied AI, Fortune 500, and other types of enterprises on actually enabling that thing. They are unlikely in most scenarios to be building their own foundation models. They typically take the stuff that is off the shelf and then they fine-tune it based on their own preference data.

[15:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=916s) So whereas the services companies principally go after the hyperscalers, the software companies typically go after the companies that are bringing the models from the hyperscalers and putting them into production or taking an open source model. And so we are focused principally on software working with enterprise, Fortune 500, and applied AI companies. Whereas the services companies generally tend to focus on the hyperscalers and the frontier labs with a different USP, which is finding the people to do the work - whereas we provide the software to do the work.

[15:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=945s) So the deal between Meta and Scale falls into the category of...

[15:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=949s) Yeah, I would probably put them into the category of - they - I think Scale has built a fantastic business selling into the hyperscalers principally. It's hard to say exactly what's going to happen after the acquisition. I think there's been a lot of chatter around what will happen exactly. I don't know, but I think Scale has supplied human experts to Meta for a long period of time. I probably see that continuing going forward.

[16:14](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=974s) But it is a different market that they're serving to what the software-first companies are serving. So you can think about the analogy of Databricks or Snowflake. They rarely sell into the hyperscalers. They have more of a core enterprise focus on selling to enterprise companies. They don't necessarily sell to the digital natives, the big FAANG companies, because they tend to build their own stuff in-house. It's just a question of what market are you going after? And some companies are going after the services market and providing the human experts, and some companies like ours are going after the actual enterprise use cases.

[16:44](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1004s) Do you think there will be more acquisitions in the upcoming year of data labeling companies?

[16:51](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1011s) Yeah, I mean I think obviously AI is very new and the market is consolidating. And data is a very crucial ingredient for AI development. If you think about the three ingredients for AI development - models, compute, and data - data is where all of the IP and all the proprietary information comes from.

[17:08](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1028s) Going back to the initial point, you cannot really do anything or build a custom AI system without actually having context on whatever it is that you're solving. And so I think the market now has kind of coalesced around the idea that data is extremely important. It is ultimately the only thing that the models cannot replicate. And so yeah, it is vital that the companies that do want to build defensible AI systems that they have good data infrastructure, access to data, and all the rest of it.

[17:34](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1054s) So context is coming from people. And what about synthetic data? It seems to be everywhere now for edge cases, rare classes, bootstrapping new domains. Do you think it helps to bridge the gap or where does it work and where does it fall short?

[17:52](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1072s) Yeah, good question. So I think the areas where we generally see synthetic data working really well is where you can do physics-based simulation. So environments where you can build some sort of model of the world and you can build some stochasticity into the model and you kind of simulate these real-world environments.

[18:08](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1088s) I think that's worked really well in self-driving where you can simulate some of these long-tail edge cases that would be very, very hard to capture in the real world. I think where it's falling short is generally when you are using a model to generate synthetic data and then maybe generating synthetic data and then having another model train on that data that is already seen. So that can sometimes lead to model collapse because it's kind of like the snake eating its own tail.

[18:33](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1113s) But you can also use a bigger model to train a smaller model. So there are different ways of doing it. I think the most successful companies are the ones that use the human or real-world data in conjunction with synthetic data. And I see that being the winning formula going forward.

[18:48](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1128s) The hybrid method. That's right.

[18:50](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1130s) From what I understand, you work with high-stakes domains like medical AI and robotics, autonomous systems, right? What are the biggest mistakes that these companies make from prototype to production in terms of dealing with data?

[19:04](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1144s) I think most of the very savvy companies that we work with broadly understand what their shortcomings are and what their shortfalls on the infrastructure side would be. And of course they are working very hard to eliminate those. I think at the end of the day the challenge that companies always have is they don't necessarily have access to the same resources as the frontier labs and the hyperscalers.

[19:26](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1166s) So of course we're plugging that gap with building the tools and the infrastructure that has really only been available to the labs and making that available to the enterprise so that they can move as fast as the frontier labs on building performant AI systems.

[19:40](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1180s) So you are their guide basically in this scenario.

[19:42](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1182s) Yeah, we're the guide and of course we can build a product that helps them bring the models from prototype into production - doing that faster than they would have if they had tried to build a lot of the stuff in-house. And a lot of times it's also just not feasible because the complexity of AI systems being developed I think is only really going one way.

[20:02](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1202s) You want to solve increasingly complex types of tasks and problems, and so there's a never-ending and evolving need to continue to push the frontiers of your own AI models and systems. So one thing we've seen for example is all the models have gone from being unimodal to being multimodal. That opens up a whole new set of things that you need to be able to support. It's just not attainable for a Fortune 500 enterprise.

[20:22](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1222s) Similar to how the move to the cloud - all the companies that had previously built in-house data centers and infrastructure, now they can rely on a cloud platform which means that they can move a lot faster on building in-house apps and all these other things. I think the same thing will happen in AI development.

[20:37](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1237s) That's very interesting. Everything that we were talking about is on a very practical level. Are there any conversations about AGI with the companies you work with? Or what's your personal take on it?

[20:50](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1250s) There are of course companies working on AGI. My general sense is we principally work on more applied AI use cases where they try to actually bring that intelligence into production. At the end of the day, treating intelligence as a single construct is difficult because there are different levels of intelligence.

[21:07](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1267s) There's the cheap types of intelligence which is just raw knowledge and facts where the models can spit out infinite versions of something at near-zero cost. There's pattern recognition or common things like writing boilerplate code, summarizing documents, and generating standard designs. All that stuff is quite easy to do. It's been a lot of time in development.

[21:29](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1289s) But I think there will be a kind of bifurcation of expensive and cheap intelligence. So the expensive types of intelligence are things like human agency, creativity, original insight, taste, and vision - the stuff that feels like it's genius or original because it can't be reverse-engineered from the data.

[21:51](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1311s) And so I think going back to the analogy around having AI systems that evolve in doing both of those things - the ones where we can do it for cheap, there'll be less need for a human in the loop. And factoring in the things that will be more difficult or require more expensive types of intelligence - that's really where human agency, taste, and all these things that you can't really explain necessarily in data will become more important.

[22:15](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1335s) Yeah, for me applied AI seems much more exciting than the conversations about AGI.

[22:18](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1338s) At the end of the day, I think a lot of the models themselves are good enough. So the main constraint now really is to embed those models and wrap them into products that can solve real problems. So I think that's where the main constraint is because the form factor matters a lot.

[22:34](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1354s) ChatGPT can help you write emails and all these other things, but you can't necessarily have it do your whole job for you. Of course these things are getting better, but there'll be a long tail of different types of human tasks and work that at least for a substantial amount of time will be outside the remit of what the existing form factors that AI is delivered in can support.

[22:57](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1377s) In this world where you work with data on all the stages - you know how it works in pre-training, you know how it works in post-training or what it makes for the context - working with high-stakes companies when it's super important to really manage your data well and be safe about it. What concerns you the most in this world that you help building and what excites you the most?

[23:21](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1401s) Yeah, that's a good question. The concerns that people have around AI and making sure that AI is deployed safely and all those things - a lot of those concerns are born because there are real risks with AI systems. We're seeing that kind of come out in a few different ways.

[23:37](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1417s) There's the mass-produced misinformation and all those other things, which I think we will just need a good way of verifying whether something is AI-generated or has been created by a human. But that's also why I think the value of brands will be even more important in the future because you know that if a specific brand is a trusted source - like you go and read the Financial Times or The Economist - I trust that they are as objective as they can be and their assessment of the truth.

[24:05](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1445s) But they have responsibility. Exactly. And so I think that will happen across every single part of the economy - the value of brands will go up a lot because of the general kind of trust and safety issues of AI. So that is just one thing that I don't think there's a good solution to other than it makes sense for the existing companies that are doing these things to continue investing in the brand, make sure that they know that they can be the trusted source of things.

[24:30](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1470s) I think the excitement is also on the flip side, right? The opportunity that we have and living in this time of history - we're likely to see more change from technology in the next 10 years than we've seen in the last 50 years. And so seeing what comes out of that I think is going to be very exciting.

[24:47](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1487s) I think the models will start to work in conjunction with humans to come up with new drugs that can treat disease and new different ways that we had never encountered before. A lot of the chores from our daily life will be easier because we will have robots in our house, right? Doing a lot of the stuff that you don't necessarily want to do.

[25:05](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1505s) Humans will sort of - it's an interesting point because we will kind of go back to doing the things that we find to be most valuable as humans. So it'll be things like spending time with our family and friends and whatnot.

[25:16](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1516s) So we're moving from an intelligence economy where value has accrued to intelligence over the last 30 years into more of what I like to call a connection economy, where the value that would be delivered - and there will be new jobs, new kind of professions created. In the agrarian economy 150 years ago it was unthinkable that there would be such a profession as a software engineer. And I think we'll see a similar proliferation of new types of work and new types of jobs that humans will be doing in the future that we can't even conceive of at this point. So yeah, I think it's a very exciting time to be alive.

[25:45](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1545s) I'm ready for all of that. And my last question will be about books. I always ask this question. I believe that books shape people. And what is a book or idea that shaped your thinking? And it can be related or completely unrelated to AI and machine learning.

[26:01](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1561s) Yeah, I've read so many good books over the years - how to pinpoint exactly which one has shaped my thinking the most. I think a more recent book that I've read that has definitely made me think a lot about my own life and how I have developed in my career is a book called "Daily Rituals: How Artists Work" by Mason Curry.

[26:20](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1580s) And so he - I think was writing a column in a newspaper and then he started writing about the daily routines of people. And so he kind of took that to the extreme and looked at what would be some of the foremost artists and thinkers in history. So there's I think maybe 150 different people in the book. I definitely encourage people reading it - it would include the likes of Mark Twain, Isaac Newton, Ayn Rand.

[26:49](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1609s) And it's super interesting reading about the daily rituals of these people because you realize that the insight or the art or the breakthrough, whatever it might be - or the new law of physics or whatever that they discovered - were created not from a single insight but really from many years of grinding away and iterating on things before they found that insight or before things actually started working.

[27:12](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1632s) And there is just a lot of analogy to building a company. It's also - people always think that these things are overnight successes but the reality is these things are many, many years in the making. I think it kind of correlates nicely with this quote from Aristotle which is: "We are what we repeatedly do. Excellence then is not an act but a habit."

[27:32](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1652s) And I think that is definitely true for most things, right? So doing the same thing over and over again every day and that's how you create the breakthroughs. I think that's how the AI breakthroughs were created, how every single breakthrough in the past was created. And I think that's just something that is very pertinent to company building and research and the new discoveries in artificial intelligence and beyond.

[27:53](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1673s) Thank you. Yeah, that's a great lesson to learn. Thank you so much for this interview. It was fun.

[27:57](https://www.youtube.com/watch?v=GxI2JNyIlrU&t=1677s) Yeah, no, thank you. Thanks for having me.
