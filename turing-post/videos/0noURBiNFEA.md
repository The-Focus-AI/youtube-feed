---
video_id: "0noURBiNFEA"
title: "When Will We Fully Trust AI to Lead? A conversation with Eric Boyd, CVP of AI Platform"
channel: Turing Post
duration: 1149
duration_formatted: "19:09"
view_count: 437
upload_date: 2025-06-28
url: https://www.youtube.com/watch?v=0noURBiNFEA
thumbnail: https://i.ytimg.com/vi/0noURBiNFEA/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Technology and Society
  - AI in Real Life
  - Turing Post
  - AI Revolution
  - Eric Boyd
  - CVP AI platform
  - Microsoft
  - Agentic Web
---

# When Will We Fully Trust AI to Lead? A conversation with Eric Boyd, CVP of AI Platform

## Summary

Eric Boyd, Corporate Vice President of Microsoft's AI Platform, discusses the evolving relationship between human trust and AI autonomy in enterprise settings. The conversation, recorded at Microsoft Build, explores when businesses will trust AI to run operations independently and the spectrum of risk tolerance that determines where AI can act autonomously versus where human oversight remains essential.

Boyd shares compelling examples of AI agents in production, including a demo where an agent upgraded a Java 8 codebase to Java 17 autonomously, working through dependencies and complications the same way a human developer would. He also highlights Nuance DAX, which creates medical records while doctors focus on patient conversations. The discussion emphasizes that AI is best positioned to handle tedious, unfun tasks that humans don't want to do, freeing people to focus on more meaningful work.

The interview covers Microsoft's "co-pilot" metaphor as a trust-building framework, the emerging "agentic web" concept announced at Build, parenting strategies for children growing up with AI, and Boyd's pragmatic view on AGI debates. He notes that even without new model releases, we have five years of adoption work ahead to fully utilize current tools. Boyd predicts 2-5 years until agents are routinely used across professional life, while emphasizing the importance of guardrails, identity management, and enterprise governance for safe deployment.

## Highlights

### "The agent did exactly what a person would do"

[![Clip](https://img.youtube.com/vi/0noURBiNFEA/hqdefault.jpg)](https://www.youtube.com/watch?v=0noURBiNFEA&t=157s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*2:37-3:15" "https://www.youtube.com/watch?v=0noURBiNFEA" --force-keyframes-at-cuts --merge-output-format mp4 -o "0noURBiNFEA-2m37s.mp4"
```
</details>

> "We just watched the agent upgrade a codebase from Java 8 to Java 17. It did exactly what a person would do. I changed all these APIs. Oh, I compiled it, but now I forgot I need this dependency. So I went and installed some stuff. That pulled these other dependencies and just kept working through the problem the same way a person would do."
> — Eric Boyd, [2:37](https://www.youtube.com/watch?v=0noURBiNFEA&t=157s)

### "People also hallucinate"

[![Clip](https://img.youtube.com/vi/0noURBiNFEA/hqdefault.jpg)](https://www.youtube.com/watch?v=0noURBiNFEA&t=293s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*4:53-5:10" "https://www.youtube.com/watch?v=0noURBiNFEA" --force-keyframes-at-cuts --merge-output-format mp4 -o "0noURBiNFEA-4m53s.mp4"
```
</details>

> "If the AI performs and makes mistakes at the same level of humans, is that okay? It feels like the answer today is no. We have a higher bar. People make mistakes. People are fallible. People also hallucinate. How do you live with AI that has some of those same characteristics? That's a pretty big societal question."
> — Eric Boyd, [4:53](https://www.youtube.com/watch?v=0noURBiNFEA&t=293s)

### "Websites without AI agents will seem silly"

[![Clip](https://img.youtube.com/vi/0noURBiNFEA/hqdefault.jpg)](https://www.youtube.com/watch?v=0noURBiNFEA&t=480s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*8:00-8:15" "https://www.youtube.com/watch?v=0noURBiNFEA" --force-keyframes-at-cuts --merge-output-format mp4 -o "0noURBiNFEA-8m00s.mp4"
```
</details>

> "It'll be the change of like, what do you mean this website doesn't have an AI agent that can help me answer my question immediately? That'll seem silly - like they just haven't caught up and updated."
> — Eric Boyd, [8:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=480s)

### "Is it AGI? I don't know. I don't think so."

[![Clip](https://img.youtube.com/vi/0noURBiNFEA/hqdefault.jpg)](https://www.youtube.com/watch?v=0noURBiNFEA&t=585s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*9:45-10:20" "https://www.youtube.com/watch?v=0noURBiNFEA" --force-keyframes-at-cuts --merge-output-format mp4 -o "0noURBiNFEA-9m45s.mp4"
```
</details>

> "Is it AGI? I don't know. I don't think so. It's pretty helpful though. It's a very useful tool. I really like being able to use it. The things that people worry about with AGI in terms of jobs changing and disruption - those are real concerns, but they're real concerns with the tools we have today."
> — Eric Boyd, [9:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=585s)

### "Character and judgment are the dominant things"

[![Clip](https://img.youtube.com/vi/0noURBiNFEA/hqdefault.jpg)](https://www.youtube.com/watch?v=0noURBiNFEA&t=560s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*9:20-9:45" "https://www.youtube.com/watch?v=0noURBiNFEA" --force-keyframes-at-cuts --merge-output-format mp4 -o "0noURBiNFEA-9m20s.mp4"
```
</details>

> "As a parent, I still think the important things of your character and your judgment are the dominant things that we need as a society to work on. But the tools that they have access to, they're going to need to learn how to use."
> — Eric Boyd, [9:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=560s)

## Key Points

- **Trust depends on risk** ([1:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=65s)) - Low-risk scenarios already allow AI autonomy; high-risk areas like medical procedures will always need human oversight
- **Developer lens on progress** ([1:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=115s)) - From code completion suggestions to agents resolving GitHub issues autonomously in just two years
- **Java upgrade demo** ([2:37](https://www.youtube.com/watch?v=0noURBiNFEA&t=157s)) - Agent upgraded Java 8 to Java 17 codebase, working through dependencies like a human would
- **Nuance DAX for doctors** ([3:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=200s)) - Technology produces medical records while doctors focus on patient conversations
- **Tedium removal trend** ([3:40](https://www.youtube.com/watch?v=0noURBiNFEA&t=220s)) - AI excels at menial, thankless tasks that people don't want to do
- **Building vs convincing trust** ([4:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=245s)) - Both sides must work together; trust starts from data, training, and safety systems
- **Higher bar for AI** ([4:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=290s)) - We hold AI to higher standards than humans even though people also make mistakes and hallucinate
- **Co-pilot metaphor** ([5:15](https://www.youtube.com/watch?v=0noURBiNFEA&t=315s)) - Important framework for building trust; agent phase will require different muscles
- **Dispute resolution agents** ([6:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=365s)) - Two-sided marketplace uses agents with thresholds to resolve customer disputes
- **Agentic web** ([6:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=410s)) - Shift from searching web pages to asking AI to do research and produce reports
- **NLweb for integration** ([7:35](https://www.youtube.com/watch?v=0noURBiNFEA&t=455s)) - Microsoft making it simpler for websites to incorporate AI agents
- **Calculator analogy** ([9:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=545s)) - Schools worried about calculators; now we use them naturally - AI tools will be similar
- **Pragmatic AGI view** ([9:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=585s)) - Focuses on practical utility rather than philosophical debates about AGI definitions
- **5 years of adoption ahead** ([10:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=645s)) - Even without new models, we have years of work to fully utilize current tools
- **2-5 year timeline** ([12:33](https://www.youtube.com/watch?v=0noURBiNFEA&t=753s)) - Prediction for agents being routinely used across professional life
- **Research automation** ([13:33](https://www.youtube.com/watch?v=0noURBiNFEA&t=813s)) - AI agents can do hours of travel research in 5 minutes
- **Guardrails balance** ([14:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=870s)) - Must constrain for safety while preserving the "wow" factor
- **Enterprise governance** ([15:57](https://www.youtube.com/watch?v=0noURBiNFEA&t=957s)) - Entra ID integration allows giving identities to agents for centralized control

## Mentions

### Companies
- **Microsoft** ([0:23](https://www.youtube.com/watch?v=0noURBiNFEA&t=23s)) - Eric Boyd's employer, AI platform leader
- **GitHub** ([2:04](https://www.youtube.com/watch?v=0noURBiNFEA&t=124s)) - Agent resolves issues from GitHub backlog
- **Nuance** ([3:22](https://www.youtube.com/watch?v=0noURBiNFEA&t=202s)) - Provides DAX technology for medical records

### Products & Technologies
- **GitHub Copilot** ([11:35](https://www.youtube.com/watch?v=0noURBiNFEA&t=695s)) - Used extensively by Microsoft's team
- **Microsoft 365 Copilot** ([5:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=330s)) - Understands email, contacts, documents
- **Azure Content Safety** ([4:25](https://www.youtube.com/watch?v=0noURBiNFEA&t=265s)) - Safety system giving developers control
- **Nuance DAX** ([3:22](https://www.youtube.com/watch?v=0noURBiNFEA&t=202s)) - Produces medical records from conversations
- **NLweb** ([7:35](https://www.youtube.com/watch?v=0noURBiNFEA&t=455s)) - Microsoft tool for integrating AI into websites
- **Entra ID** ([16:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=960s)) - Identity management for agents in enterprise

### People
- **Kevin Scott** ([8:15](https://www.youtube.com/watch?v=0noURBiNFEA&t=495s)) - Microsoft executive who discussed children and AI on stage

### Books
- **Crucial Conversations** ([16:48](https://www.youtube.com/watch?v=0noURBiNFEA&t=1008s)) - Book about having difficult emotionally charged conversations
- **Brave New World** ([17:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=1040s)) - Dystopian sci-fi Eric's son just read
- **Silo series** ([17:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=1070s)) - Recent dystopian fiction Eric read

## Surprising Quotes

> "My son was like 'This has blown up on TikTok faster than anything in my whole life.' And I'm just like - on TikTok in your entire life."
> — [8:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=525s)

> "If we didn't produce another model, nothing else ever came out - we have at least 5 years of adoption of the existing tools to sort of fully figure out how we can use them in their best ways."
> — [10:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=645s)

> "There's a company that uses agents to resolve disputes. It's got thresholds - it can offer refunds up to a certain dollar amount. Sometimes it's just like 'look it's better to have two happy customers' and an agent can make that happen."
> — [6:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=365s)

> "The GitHub agent can solve issues from your backlog and understand the issue and test them out and write code and run it. It can't check it in and deploy it - we've given it guardrails."
> — [14:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=890s)

## Transcript

[0:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=0s) And so we just watched the agent do it and it did exactly what a person would do. Do really interesting work for us and remove tedium from our lives. I just think that's really exciting that the world is really changing. Is it AGI? I don't know. I don't think so. Dystopian societies are always fun.

[0:23](https://www.youtube.com/watch?v=0noURBiNFEA&t=23s) Thank you very much for joining me for the interview. It's an Inference podcast for Turing Post. Let me just start with a big question right away. When will we trust AI enough to run our businesses, to run our companies?

[0:35](https://www.youtube.com/watch?v=0noURBiNFEA&t=35s) So already we see just tremendous impact from AI across so many of our customers. There are lots of places where people are using AI everywhere from customer support systems to developers using it to write code. And in all of those scenarios, people are using it generally to make a person more productive. Here's a suggestion. Here's how you should do your job. Here's some help for you.

[1:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=60s) I take your question to mean at what point are we at the place where I don't need that human sort of looking over the shoulder? I think it will depend entirely on the particular scenario. Already there are some low-risk scenarios where you'll let the AI go and try something and if it does a poor job, you kind of don't care that much. And there are high-risk scenarios that I think we'll never want to give over to AI.

[1:28](https://www.youtube.com/watch?v=0noURBiNFEA&t=88s) Where do you think this level of trust will never be achieved? You can think about the highest level like medical procedures or places you could think about - people always go to "we're not going to let nuclear missiles be launched by AI or anything like that." So there are some places that I think we will just never go to. But there are so many more that we're starting to see where AI is actually doing a better job.

[1:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=110s) I think it's instructive to look through the developer lens. We've in just the past couple years gone from having AI suggest a completion to you to now we're asking it to go and resolve some issues from my GitHub backlog with the agent we announced this morning. You're still going to review that code and make sure it works, but you've given a lot more responsibility and tools to the agent to go do those things.

[2:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=140s) What is your favorite example from the internal work with agents and from the client side? The internal "dog fooding" - learning how to use the product for the GitHub software agent has been really pretty amazing for a lot of people.

[2:37](https://www.youtube.com/watch?v=0noURBiNFEA&t=157s) One of the early demos we did to see if it was even possible was upgrading a codebase from Java 8 to Java 17. For those who aren't deep in the guts of developing, it's just a mindless, thankless, not fun, and really pretty difficult job. You just keep running into another corner and another dead end.

[2:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=175s) And so we just watched the agent do it. It did exactly what a person would do. "I changed all these APIs. Oh, I compiled it, but now I forgot I need this dependency. So I went and installed some stuff. That pulled these other dependencies" - and just kept working through the problem the same way a person would do. It completed this pretty thankless, unfun task that's still pretty important to do.

[3:18](https://www.youtube.com/watch?v=0noURBiNFEA&t=198s) I think that's a trend we'll actually see a lot of. When I go to the doctors in the area, they're all using Nuance DAX. It's a technology that lets a doctor have a conversation with a patient and Nuance DAX sits unobtrusively and listens and then produces the medical record. So the doctor's gone from having to type away everything to having a medical record produced while they have a conversation focused on you.

[3:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=225s) I think that trend of menial work that people don't want to do - upgrading Java 8 to Java 17, producing the medical record - are going to be done by AI. We're pretty much at that world today. That's a great improvement.

[3:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=235s) AI is very powerful but trust is still a bottleneck. In your view, is it harder to build trustworthy AI or to convince the stakeholders to trust it? That's a really hard question. You need both sides to work together.

[4:10](https://www.youtube.com/watch?v=0noURBiNFEA&t=250s) We focus a lot on building trustworthy AI starting all the way from the data we use to train the models, the way we post-train the models to follow instructions and answer questions a particular way. Then the Azure Content Safety system we put on top that helps give developers control to make sure they're going to be able to use it in the right way.

[4:35](https://www.youtube.com/watch?v=0noURBiNFEA&t=275s) But then there's the other side - as you start to give agency to these models, this question comes up in a lot of AI research areas: if AI performs and makes mistakes at the same level of humans, is that okay? It feels like the answer today in many cases is no. We have a higher bar.

[4:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=295s) But that'll be something we have to work to. It's just sort of hard to accept. People make mistakes. People are fallible. People also hallucinate. I've never ever possibly said something incorrect, right? So how do you live with AI that has some of those same characteristics? That's a pretty big societal question to work through.

[5:10](https://www.youtube.com/watch?v=0noURBiNFEA&t=310s) What lessons has Microsoft learned from early enterprise agent deployments? What breaks the trust? What builds it? We settled on this metaphor of "co-pilot." And I think that's been a pretty important metaphor. The system - this model that is helping a person perform better - is looking over the shoulder, looking at the code that you write.

[5:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=330s) Microsoft 365 Copilot understands your email and your contacts and your documents and the relationships you have and is able to answer questions in a better way because of that. I think that's been a really important metaphor at this first phase.

[5:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=350s) This next phase as we move into agents is going to start to build different muscles. It's going to work differently where you're actually giving more control to an agent to perform certain actions and tasks. People will work carefully to set guardrails on it.

[6:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=365s) There's a company I spoke to - a two-sided marketplace - they use agents to resolve disputes. "I say I purchased something, you say I didn't" - and they have an agent. It's got thresholds - it can offer refunds up to a certain dollar amount. It's using its judgment to decide how to balance the two.

[6:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=390s) They've given some guardrails and restrictions, but they're also starting to open up. "How much do we let the agent make these decisions?" In their case, sometimes it's just "look, it's better to have two happy customers" and an agent can make that happen.

[6:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=410s) If we're talking about the new metaphor about the agentic web - this is the new story Microsoft announced at Build. How would you describe it? The agentic web is this recognition that the world is really changing.

[7:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=425s) We're moving from a place where most of the time I would go to a search engine, look for a web page, consume information that way - to a world where I'm asking AI to do a lot more. Some of the researcher capabilities we've announced through M365 Copilot - go and perform some research, look at stuff in my documents, look at stuff on the web, and produce me a report.

[7:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=450s) It changes the interactions quite a lot and changes the way we think about what it means to be using the web. People who produce content on the web are going to think about that too - what are the ways they should incorporate agents into their websites? And you saw NLweb and how we've made that simpler to integrate.

[7:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=470s) Everyone is going to need to grapple with "hey, we have new technology and things are going to work different." In some ways, it's not that different from the emergence of the web. I remember in the mid-90s when every commercial on TV said ".com" and we laughed about that. Now you don't think it's weird at all. Of course I want to go to a website for more information.

[8:10](https://www.youtube.com/watch?v=0noURBiNFEA&t=490s) Everything is "with AI" now. It'll be the change of "what do you mean this website doesn't have an AI agent that can help me answer my question immediately?" That'll seem silly - like they just haven't caught up and updated.

[8:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=500s) Do you have children? I do. There were a lot of conversations about how children use AI from Kevin Scott and from the stage today. What's your strategy with your kids? How do you talk with them about AI?

[8:40](https://www.youtube.com/watch?v=0noURBiNFEA&t=520s) I have five children. I don't know that I have all the answers. I'm definitely not the world's perfect parent, but I think we've done a pretty good job. We have an 18-year-old and a 14-year-old, two boys. They've been comfortable online and comfortable with AI.

[8:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=535s) My favorite line when ChatGPT first launched - my son was like "This has blown up on TikTok faster than anything in my whole life." And I'm just like - on TikTok in your entire life. It's the first thing you've seen explode like that. But it was suddenly something they got that they interacted with.

[9:15](https://www.youtube.com/watch?v=0noURBiNFEA&t=555s) There are a lot of concerns about how this impacts education, whether people will still know how to write. I think the important question is these are new tools. When I was in high school, they were very worried about using calculators. Now I don't carry a calculator - I carry a phone - but anything hard I don't write the long division, I just pull out the calculator. It'll be the same with AI tools.

[9:41](https://www.youtube.com/watch?v=0noURBiNFEA&t=581s) We have powerful tools and you can use them in powerful and productive ways. You can probably use them in some harmful ways. You need to understand those things. As a parent, I still think the important things of your character and your judgment are the dominant things we need as a society to work on. But the tools they have access to, they're going to need to learn how to use.

[10:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=600s) Everything we talk about now is very practical. What is AGI in your opinion? AGI is a great science fiction topic. And ASI for superintelligence and all those things - it becomes almost a philosophical conversation of "how do we know we've actually reached it?"

[10:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=620s) Maybe over a nice glass of wine you can indulge in that conversation. I tend to be much more pragmatically focused. We have this AI - is it AGI? I don't know. I don't think so. It's pretty helpful though. It's a very useful tool. I really like being able to use it.

[10:40](https://www.youtube.com/watch?v=0noURBiNFEA&t=640s) The things people worry about with AGI in terms of jobs changing and potential disruption - those are very real concerns, but they're real concerns with the tools we have today. And they've been very real concerns going back to the industrial revolution, with the invention of the PC, and like the number of jobs that have changed. They change. And that's hard for societies to work through, but they do work through them.

[11:10](https://www.youtube.com/watch?v=0noURBiNFEA&t=670s) Are we close to understanding that or just more questions? There are certainly areas where we've seen - I think it's interesting how developers, programmers are going to be one of the first places to grapple with this that the role is going to change.

[11:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=690s) The ability to remember some arcane API or quickly search for it is less important. The ability to use the AI tool is suddenly much more important. It's funny - the calculator analogy - there are some companies interviewing for developers trying to prevent them from using AI in the interviews.

[11:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=710s) I was talking to another company - they said "that's a totally wrong approach. They should be using the tool. I want them using the most advanced tools and showing they're comfortable and fluent in it because that's where the developer world is moving."

[12:10](https://www.youtube.com/watch?v=0noURBiNFEA&t=730s) In the last year, how did it change for your team? We use GitHub Copilot extensively. The place we're at now is developers largely have the same job, but they're faster at a lot of the menial tasks. As we start moving into the agent space, we're just starting to see that shift.

[12:33](https://www.youtube.com/watch?v=0noURBiNFEA&t=753s) Increasingly it'll start to look like I now have even a fleet of agents at my disposal to get my tasks done. Being effective at getting them to do that work will be an important role. The main change has been you have to learn how to use Copilot to prompt it to complete this particular function.

[12:55](https://www.youtube.com/watch?v=0noURBiNFEA&t=775s) How long will it take for everyone to be more productive, more knowledgeable about agents, and for agents to work properly? That's a hard question. The space has moved really quickly - that's been one of the defining characteristics of AI over the last couple years. It'll probably be quick, but is quick 6 months or 5 years? Both feel pretty quick.

[13:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=800s) I think it's probably going to be on the order of a couple of years to fully take effect. If we didn't produce another model - nothing else ever came out - we have at least 5 years of adoption of the existing tools to fully figure out how we can use them in their best ways. We keep releasing new models so there's going to be so much more development and applicability.

[13:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=825s) So you think 2 to 5 years for infrastructure to get to a place where people are very frequently using agents in a large portion of their professional life? I think that's probably the right timeline.

[14:00](https://www.youtube.com/watch?v=0noURBiNFEA&t=840s) When you think ahead to 5 years, what excites you the most and what are your concerns? It's pretty exciting being able to get these tools to do what we want. My son wanted to go backcountry skiing and I wanted a guide so we didn't die in an avalanche. What are the guide services? Where can I look them up? Where should we go? What are the different costs?

[14:25](https://www.youtube.com/watch?v=0noURBiNFEA&t=865s) That's just hours of research. I was able to ask an AI agent to go fill this out and come back with a report. In 5 minutes I had something - a nice synthesized answer. Taking that tedium out of so many aspects of life is really quite exciting.

[14:45](https://www.youtube.com/watch?v=0noURBiNFEA&t=885s) We see that expanding into so many professional fields. I talked about doctors with medical records. My wife's a lawyer - the tedium of document review or research on things. Being able to focus on the interesting part - I want to go backcountry skiing, I don't want to research how to do it.

[15:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=905s) As for what I'm concerned about - this is very powerful technology and we're constantly working through what are the right guardrails. It's a fine balance. Some of the tools we've got - if we completely unconstrain them, they could do more interesting things, but they also could do some things we're not comfortable with.

[15:30](https://www.youtube.com/watch?v=0noURBiNFEA&t=930s) Finding that right balance of constraining and setting up the problem in the right way to be safe but still preserve the "wow, that's incredible - I didn't know it could actually do that." The GitHub agent can solve issues from your backlog, understand the issue, test them out, write code and run it. It can't check it in and deploy it. It still has a person. We've given it guardrails. It can't email the code out to someone else. That balance is going to be key.

[16:05](https://www.youtube.com/watch?v=0noURBiNFEA&t=965s) From the clients, what do you hear? What are their questions and concerns? We certainly hear from customers "how am I going to manage this across my enterprise?" Every corner is really excited about this. "I don't know the rules I need to put in place. I want to make sure I don't leak out information in ways I'm not supposed to."

[16:25](https://www.youtube.com/watch?v=0noURBiNFEA&t=985s) Some of the work we announced - the integration of Entra ID - now you can give an ID to each agent, you can give it governance and control over what access it has, you can manage that in a centralized way. Those are going to be super important for adoption. Making stuff work in an enterprise environment is hard. These types of controls that Microsoft has spent decades working on are super important.

[16:48](https://www.youtube.com/watch?v=0noURBiNFEA&t=1008s) What is the book that you go back to often that helps you? There's books on how to interact with people that have been really important. There's a book called "Crucial Conversations" which is about how to have those hard emotionally charged conversations. It's one of those books where you're reading it and you're like "this is going to change the way I talk to my wife." Just knowing how to bring up the subject, how to have that interaction - that's a super important skill.

[17:20](https://www.youtube.com/watch?v=0noURBiNFEA&t=1040s) On the fiction side, I gravitate towards science fiction. The high school book - my son just read it - but "Brave New World" is always a book where dystopian societies are always fun and entertaining. Just thinking about what if society went in a particularly different direction.

[17:50](https://www.youtube.com/watch?v=0noURBiNFEA&t=1070s) Most dystopias need some triggering event to ruin the world. The Silo series I just recently read - people live in vertical nuclear silos buried underground. Hunger Games had a big war and then a terrible government. It's interesting how few of them are AI-focused.

[18:15](https://www.youtube.com/watch?v=0noURBiNFEA&t=1095s) I think education will help us from this dystopia. Thank you so much for this interview. It was great to talk with you. I hope you have a great rest of your Build.
