---
video_id: LQIrsmercPw
title: "How to Make AI Actually Do Things | Alex Hancock, Block, Goose, MCP Steering Committee"
channel: Turing Post
duration: 1490
duration_formatted: "24:50"
view_count: 939
upload_date: 2025-08-09
url: https://www.youtube.com/watch?v=LQIrsmercPw
thumbnail: https://i.ytimg.com/vi/LQIrsmercPw/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Alex Hancock
  - Block
  - Goose
  - MCP
  - Model Context Protocol
  - AI Agents
---

# How to Make AI Actually Do Things | Alex Hancock, Block, Goose, MCP Steering Committee

## Summary

This episode of Inference features Alex Hancock, a Senior Software Engineer at Block and core contributor to Goose, the open-source multi-purpose AI agent. As a member of the Model Context Protocol (MCP) Steering Committee, Alex provides deep insights into the infrastructure quietly powering the next wave of AI development. The conversation explores how MCP transforms models from isolated "brains in a jar" into agents with "arms and legs" that can actually interact with the world.

The discussion covers the explosive growth of MCP adoption, the steering committee's push for openness and governance, and critical technical developments including SDK parity, registry design, and OAuth 2.1 authentication. Alex shares practical insights from building Goose, discussing the challenges of context discovery and management - which he identifies as the hardest problems in agentic AI. He also addresses how MCP and A2A protocols relate to each other, predicting that MCP has already won the protocol race due to first-mover advantage.

Alex emphasizes that we're in a time of "tremendous change and opportunity" where creating software is "changing fundamentally." The key insight: if you give a model the right context, it can do a great job - but democratizing that ability to provide good context is the major challenge ahead.

## Highlights

### "A Brain in a Jar"

[![Clip](https://img.youtube.com/vi/LQIrsmercPw/hqdefault.jpg)](https://www.youtube.com/watch?v=LQIrsmercPw&t=56s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*0:56-1:35" "https://www.youtube.com/watch?v=LQIrsmercPw" --force-keyframes-at-cuts --merge-output-format mp4 -o "LQIrsmercPw-0m56s.mp4"
```
</details>

> "MCP is a protocol for giving the model more context about things... A really smart model is like a brain in a jar - it doesn't have access to anything that's immediately around it. So MCP kind of helps us just remove that jar and let the model connect to data sources that are proximal to it, call tools to affect change in different systems, and helps us give the models arms and legs to do things in the world."
> — Alex Hancock, [0:56](https://www.youtube.com/watch?v=LQIrsmercPw&t=56s)

### "MCP Won Already"

[![Clip](https://img.youtube.com/vi/LQIrsmercPw/hqdefault.jpg)](https://www.youtube.com/watch?v=LQIrsmercPw&t=1028s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*17:08-17:40" "https://www.youtube.com/watch?v=LQIrsmercPw" --force-keyframes-at-cuts --merge-output-format mp4 -o "LQIrsmercPw-17m08s.mp4"
```
</details>

> "I think MCP won already. You only need a slight edge with open source protocol and you're just zooming - it's really hard to catch up. Bitcoin and Ethereum - Ethereum will never catch up even though you can argue it's a better system. There's a first mover advantage that accumulates over time."
> — Alex Hancock, [17:08](https://www.youtube.com/watch?v=LQIrsmercPw&t=1028s)

### "This is a New Way of Working"

[![Clip](https://img.youtube.com/vi/LQIrsmercPw/hqdefault.jpg)](https://www.youtube.com/watch?v=LQIrsmercPw&t=0s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*0:00-0:42" "https://www.youtube.com/watch?v=LQIrsmercPw" --force-keyframes-at-cuts --merge-output-format mp4 -o "LQIrsmercPw-0m00s.mp4"
```
</details>

> "This is a new way of working. I mean a time of tremendous change and opportunity for all of us. Creating software is changing fundamentally... The nature of creating software is changing fundamentally. It's not changing in an incremental way. It's not an incremental improvement."
> — Alex Hancock, [0:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=0s)

### "Context is Everything"

[![Clip](https://img.youtube.com/vi/LQIrsmercPw/hqdefault.jpg)](https://www.youtube.com/watch?v=LQIrsmercPw&t=751s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*12:31-13:35" "https://www.youtube.com/watch?v=LQIrsmercPw" --force-keyframes-at-cuts --merge-output-format mp4 -o "LQIrsmercPw-12m31s.mp4"
```
</details>

> "I see one of the most interesting challenges in using this technology right now to be the models are capable. The models are getting very smart. Getting them the right context to perform a task is largely the task. If you give the model the right context, it can do a great job. And if you don't give the model the right context, it can do a terrible job."
> — Alex Hancock, [12:31](https://www.youtube.com/watch?v=LQIrsmercPw&t=751s)

### "AGI Will Be Incremental"

[![Clip](https://img.youtube.com/vi/LQIrsmercPw/hqdefault.jpg)](https://www.youtube.com/watch?v=LQIrsmercPw&t=1245s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*20:45-21:40" "https://www.youtube.com/watch?v=LQIrsmercPw" --force-keyframes-at-cuts --merge-output-format mp4 -o "LQIrsmercPw-20m45s.mp4"
```
</details>

> "It's a process that's going to be continual improvement and it's not going to be like a before and after. These things just continuing to get more and more and more capable and doing more for us, and at a certain point you're going to look at them and realize that they're incredibly powerful and incredibly intelligent."
> — Alex Hancock, [20:45](https://www.youtube.com/watch?v=LQIrsmercPw&t=1245s)

## Key Points

- **What is MCP** ([0:56](https://www.youtube.com/watch?v=LQIrsmercPw&t=56s)) - Model Context Protocol is a protocol for giving models more context, connecting them to data sources, and enabling them to call tools to affect change in different systems
- **MCP Steering Committee** ([2:40](https://www.youtube.com/watch?v=LQIrsmercPw&t=160s)) - A group of individuals involved in MCP through open source contributions, implementing clients/servers, and dedicating time to improving the protocol
- **Governance Framework** ([3:07](https://www.youtube.com/watch?v=LQIrsmercPw&t=187s)) - A new governance and stewardship framework was announced detailing how people can get involved and how decisions will be made
- **SDK Parity Challenge** ([3:55](https://www.youtube.com/watch?v=LQIrsmercPw&t=235s)) - There's a big push for spec compliance and consistency across SDKs in different languages to keep up with rapid protocol evolution
- **OAuth 2.1 Adoption** ([5:28](https://www.youtube.com/watch?v=LQIrsmercPw&t=328s)) - The adoption of OAuth 2.1 as the authentication standard is a major security improvement and helps agents automate tasks in platforms like Slack or Stripe
- **Long-running Processes** ([5:51](https://www.youtube.com/watch?v=LQIrsmercPw&t=351s)) - Active discussions on how to model asynchronous processes where agents need to wait for responses
- **MCP Dev Summit** ([8:04](https://www.youtube.com/watch?v=LQIrsmercPw&t=484s)) - In March, the steering committee met in person in San Francisco to discuss protocol development
- **Global Server Registry** ([8:52](https://www.youtube.com/watch?v=LQIrsmercPw&t=532s)) - A centralized registry of all MCP servers in the world is being developed so clients can discover servers
- **MCP vs A2A** ([10:23](https://www.youtube.com/watch?v=LQIrsmercPw&t=623s)) - A2A is complementary to MCP - MCP handles context and tools, while A2A is a higher-level protocol for agent-to-agent communication
- **Protocol Competition** ([11:48](https://www.youtube.com/watch?v=LQIrsmercPw&t=708s)) - Goose is protocol-neutral and may support A2A or other protocols if they prove complementary
- **Rate of Change** ([12:18](https://www.youtube.com/watch?v=LQIrsmercPw&t=738s)) - The increase in capabilities of models and tools in just 6 months has been staggering
- **Context Discovery** ([12:51](https://www.youtube.com/watch?v=LQIrsmercPw&t=771s)) - Context discovery and context management algorithms are the most interesting areas to focus on
- **Democratizing AI** ([13:33](https://www.youtube.com/watch?v=LQIrsmercPw&t=813s)) - The goal is to enable anyone with a goal to get results equal to what the most skilled AI professionals achieve today
- **Goose System Prompt** ([14:35](https://www.youtube.com/watch?v=LQIrsmercPw&t=875s)) - Goose has a top-level system prompt but is designed to need minimal changes to take advantage of model advances
- **Elicitation Feature** ([16:07](https://www.youtube.com/watch?v=LQIrsmercPw&t=967s)) - A newer feature in the June spec that most SDKs don't support yet
- **Productivity Impact** ([22:45](https://www.youtube.com/watch?v=LQIrsmercPw&t=1365s)) - Alex describes this as the biggest change in magnitude in productivity of his 15-year career as a software engineer

## Mentions

### Companies
- **Block** ([0:30](https://www.youtube.com/watch?v=LQIrsmercPw&t=30s)) - Alex's employer, where he works as a Senior Software Engineer
- **Microsoft** ([7:43](https://www.youtube.com/watch?v=LQIrsmercPw&t=463s)) - Has members on the MCP steering committee
- **OpenAI** ([7:43](https://www.youtube.com/watch?v=LQIrsmercPw&t=463s)) - Has members on the MCP steering committee
- **Anthropic** ([1:15](https://www.youtube.com/watch?v=LQIrsmercPw&t=75s)) - David Parra, who created MCP, gave original presentations about it

### Products & Technologies
- **Goose** ([0:34](https://www.youtube.com/watch?v=LQIrsmercPw&t=34s)) - Open-source multi-purpose AI agent that Alex works on
- **MCP (Model Context Protocol)** ([0:50](https://www.youtube.com/watch?v=LQIrsmercPw&t=50s)) - Protocol for giving models context and tools
- **A2A** ([10:14](https://www.youtube.com/watch?v=LQIrsmercPw&t=614s)) - Higher-level protocol for agent-to-agent communication
- **OAuth 2.1** ([5:28](https://www.youtube.com/watch?v=LQIrsmercPw&t=328s)) - Authentication standard adopted by MCP
- **Slack** ([5:42](https://www.youtube.com/watch?v=LQIrsmercPw&t=342s)) - Example platform where agents can automate tasks
- **Stripe** ([5:42](https://www.youtube.com/watch?v=LQIrsmercPw&t=342s)) - Example platform for agent automation
- **Square** ([5:42](https://www.youtube.com/watch?v=LQIrsmercPw&t=342s)) - Example platform for agent automation
- **Cash App** ([11:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=660s)) - Example of isolated system MCP can connect to

### People
- **Alex Hancock** ([0:30](https://www.youtube.com/watch?v=LQIrsmercPw&t=30s)) - Senior Software Engineer at Block, Goose maintainer, MCP Steering Committee member
- **David Parra** ([1:11](https://www.youtube.com/watch?v=LQIrsmercPw&t=71s)) - Creator of MCP

## Surprising Quotes

> "A year already feels like a long time, right? ... A few months is already like ancient history."
> — [12:14](https://www.youtube.com/watch?v=LQIrsmercPw&t=734s)

> "Right now you have a situation where you have a top percent of people who understand the models and they know what you have to give the model in order for it to do a good job. Democratizing that is the work ahead."
> — [13:28](https://www.youtube.com/watch?v=LQIrsmercPw&t=808s)

> "When you can have code generated for you in a matter of minutes that used to take hours to write, hours of focused effort to write... the challenge is how do we then interface with that increased output?"
> — [22:15](https://www.youtube.com/watch?v=LQIrsmercPw&t=1335s)

> "I think there's a big risk in AI like any other technology, but I don't think there's a Skynet type risk from that movie Terminator where there's a single AI entity that's taking over the world. I don't think that's plausible."
> — [20:10](https://www.youtube.com/watch?v=LQIrsmercPw&t=1210s) (paraphrased from Alex's perspective on AGI)

## Transcript

[0:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=0s) This is a new way of working. I mean a time of tremendous change and opportunity for all of us. Creating software is changing fundamentally. What you have to give the model in order for it to do a good job.

[0:18](https://www.youtube.com/watch?v=LQIrsmercPw&t=18s) Hi Alex, thank you for finding time for this interview. It's not that easy during the summer times. Yeah, nice to see you. Thanks for taking the time as well. So Alex is a senior software engineer at Block and as far as I know you're deeply involved with the development and promotion of Goose, the open source multi-purpose AI agent. But while we met because of Goose, what really got my attention is that you were an active member of MCP steering committee. So let's start from the basics - what is MCP and why it became so important?

[0:56](https://www.youtube.com/watch?v=LQIrsmercPw&t=56s) MCP is a protocol for giving the model more context about things and I think at a high level I attribute its success and its rapid growth to it's getting at a core need. I think David, David Parra who created MCP, one of his original presentations about it was this idea of - a really smart model is like a brain in a jar, it doesn't have access to anything that's immediately around it. So MCP kind of helps us just remove that jar and let the model connect to data sources that are proximal to it, call tools to affect change in different systems, and it's just helps us give the models arms and legs to do things in the world.

[1:35](https://www.youtube.com/watch?v=LQIrsmercPw&t=95s) Not that many developers understood right away what the benefits of MCP were. Why do you think that happened? Yeah, it's a good question. I don't know. I mean I can speak from our experience. We looked at MCP early in its trajectory and at the time we were looking for - we were building an agent, right? So we were working in this space and we were looking for a way to give our agent more capabilities and a flexible set of tools to read resources, to perform actions, to do things like edit files or change settings in another application, things like that. And when we heard about MCP and read the spec, it fit our needs very well. So we just adopted it because it was doing the job that we were looking for a tool to do. It seemed great to us. I've been really pleased with the pickup and the acceleration of growth in MCP adoption worldwide. I mean, it feels like it's just exploding right now and I think for a good reason.

[2:28](https://www.youtube.com/watch?v=LQIrsmercPw&t=148s) Yeah. It's on everyone's mind and everyone talks about it on the conferences. But MCP steering committee is still kind of a secret organization. I couldn't really find a lot of information about it. So, what is MCP steering committee? Yeah, we're trying to make that better. The first thing I'd say is we're trying to make that not the case. The MCP steering committee has just been a group of individuals who have been involved in MCP in different ways - on the open source repositories, contributions to the spec, people who have adopted it and are implementing either MCP clients or MCP servers and have been dedicating time to improving the protocol, thinking about the protocol. And this perception of it as a sort of secretive organization is something that we want to fix. There was a governance and stewardship framework announced just last week I think that went up on the website which details how people can get involved in the project and how decisions will be made for the protocol. And that's kind of the first steps I think of opening this thing up and letting more people come and participate, which is great.

[3:27](https://www.youtube.com/watch?v=LQIrsmercPw&t=207s) Yeah, you told me that there is a lot of things going on on the MCP steering committee recently. What's happening? Can you give us more details? Yeah, so a lot of this is just happening in the spec repository itself. So in the Model Context Protocol GitHub repositories the issues and the discussions there are a lot of what's going on from my vantage point. And the things that I've been involved in - there's sort of a big push and effort around spec compliance. You have SDKs in different languages that implement the spec and kind of trying to drive more consistency and faster updates there is one of the things that's in mind. So you know MCP is moving at a pretty rapid clip - there was a version of the spec that was detailed and cut in March and then there was another one that was cut in June. And so a lot of the SDK implementations are just trying to catch up.

[4:15](https://www.youtube.com/watch?v=LQIrsmercPw&t=255s) I see some of the interesting work ahead is like how do we not keep ourselves in a position where the SDKs are trying to keep up? How do we drive consistency and speed up development of the SDKs so that they can be in sync with the spec at all times and we can push forward really fast? So you have great server and client support in any language that you'd want to work in that corresponds with the most recent version of the spec rapidly. There's some work happening on the steering committee to try to figure out how to drive that. I think that's really good. There's also an agents working group that's kicking off talking about things that are relevant to people that work on agents and agentic projects - relevant because I work on Goose. There's a lot of exciting work for how you drive consistent implementations of the protocol and the development of the protocol itself.

[4:57](https://www.youtube.com/watch?v=LQIrsmercPw&t=297s) Tell me more about how it works with agents. What are the bottlenecks? What are the next implementation goals of MCP with agents? I think some of it comes back to fundamental pieces. It's like if you have an agent in a particular language - so say you're writing something on Mac and you're writing in Swift - then you need an SDK that implements all the concepts. And so that's an example of where foundational work is going to support agentic projects as well as other projects. OAuth is a big one as well. So OAuth, the recent adoption of OAuth 2.1 as the authentication standard for MCP I think really helps because then there's a straightforward path to having an agent which can automate tasks for you in a given platform like Slack or Stripe or Square. That's a great help to agents.

[5:46](https://www.youtube.com/watch?v=LQIrsmercPw&t=346s) There's some active conversations happening around long-running processes. So how you have a tool call that can be done sort of immediately and get a response back. But you can also imagine longer term processes that require asynchronous access by an agent - the agent tries to do something, it knows that it has to wait a while for a response. How we model that in the protocol - those are early discussions but all of those things are sort of relevant to agents.

[6:13](https://www.youtube.com/watch?v=LQIrsmercPw&t=373s) What about privacy and security for MCP protocols? Yeah, security - I think the OAuth 2.1 development is a really good step. At the beginning there wasn't - I mean six months ago there wasn't an OAuth component to MCP at all. It was just a transport protocol and a format of messages that went back and forth between clients and servers. So the adoption of OAuth is great. Now you have a secured connection between the client and the server that relies on an industry standard bedrock piece of technology in OAuth that's been battle tested for years. I think that's great.

[6:43](https://www.youtube.com/watch?v=LQIrsmercPw&t=403s) Privacy and security - if you use an MCP server, similar to using servers or libraries in any other system, you need to know something about the source of that. That's something that the protocol hasn't said that much about itself yet, but I'm going to be looking for different projects to spin up to verify the authenticity and security of a server. Authorization between clients and servers was a big one that was missing at the beginning and they wanted to take their time to make a good choice on how that would work and not put something out prematurely. I think the result and where it landed was really good in leveraging OAuth 2.1. That's a great security improvement to what the project's posture on security was at the beginning, which was that it didn't encompass it at all.

[7:36](https://www.youtube.com/watch?v=LQIrsmercPw&t=456s) Just to make it even clearer about the steering committee - what are your goals and how often do you meet? How do you involve members? Because there are members from Microsoft, there are members from OpenAI. How does this organization work? Communication's been pretty informal so far to be honest. It's been just discussion online in the GitHub projects themselves around the spec itself. And then more recently in March, we all had a really nice opportunity to meet up in person in San Francisco at the MCP Dev Summit. We hosted a day for people that could make it in person to meet up with the steering committee. And that was really great because you put faces with names and you all get in a room and sit together. And what I could say is that I felt really impressed with the people in the room and the conversation in the room. People's dedication to wanting to improve this protocol and have it be a useful thing for everybody in the world. It's a special moment, I think, in this technology in general and particularly with the people that are helping push MCP forward. I've just been really happy and grateful to be part of that conversation.

[8:39](https://www.youtube.com/watch?v=LQIrsmercPw&t=519s) What are the main topics you're discussing now for the future? It's becoming a bigger group and there are a lot of different working groups and projects going on. So I can really only speak from personal experience of what I've been engaging with. The registry of servers - a global registry of all the MCP servers in the world - is how I kind of first got involved with the steering committee. I suggested that idea and then some other people have picked it up and have really been driving that work in recent months. A registry of servers so that clients can discover what servers are out there that might fit their needs and server authors can publish their servers into a centralized registry. That's a big work stream.

[9:18](https://www.youtube.com/watch?v=LQIrsmercPw&t=558s) Like I said, SDK support - having good support for all the MCP features in any language that someone would want to work in and driving sort of consistent spec compliance across all those different languages. That's another one. The agents working group that I mentioned is just kind of getting off the ground and starting to think about meetings soon but haven't had any yet. So just discussing how agentic projects make use of MCP and where there are things that the protocol may need to do to support the kinds of access patterns that agents need to use. That's another work stream. There's a lot else going on as well. All this is open - the spec is open, the GitHub repository is open - so people can go to the Model Context Protocol GitHub organization and see the discussions and issues.

[10:11](https://www.youtube.com/watch?v=LQIrsmercPw&t=611s) How do you look at other protocols like A2A? Is there any possible collaboration between those protocols? Because A2A and the registry that comes from Microsoft might be useful for MCP. Yeah absolutely, the way I see this is that it's early for all of this. We're trying to figure out the best way to give models access to the information and the tools that they need to perform useful actions for the user of an AI powered application. It's early for all of this. I think when A2A was announced, my view is that the framing was correct - that it's very complementary to MCP. MCP is very useful for getting a model, an AI powered application, access to the right information, context that it may need, tools that it can call to perform actions in isolated systems like Slack or Square, Cash App or whatever it is. MCP really makes sense for all of that.

[11:05](https://www.youtube.com/watch?v=LQIrsmercPw&t=665s) And then A2A is sort of a higher level protocol where there's less shared infrastructure for agents to communicate. It's like where the protocol between them is almost like English - so and so's agent tells this other agent to do this thing. And that's not to say that that will be the only attempt at that, but I see them largely as complementary. And then where there are areas where responsibilities or areas of focus start to collide, then that will be a discussion and there'll be healthy competition between different protocols. Working on Goose, we're a model neutral project, we're protocol neutral as well. We support MCP today. We may support A2A or any other protocols that emerge if we see them as complementary.

[11:51](https://www.youtube.com/watch?v=LQIrsmercPw&t=711s) You said it's all very beginning for the protocols and how we work with the models and connecting this brain to the actual action, making it a doer instead of just isolated brain. How do you see the development of the space in a year? I mean I don't think we can extrapolate to five years - too many things happening. Yeah, a year already feels like a long time, right? Right. A few months is already like ancient history. How do you see it?

[12:18](https://www.youtube.com/watch?v=LQIrsmercPw&t=738s) I've been working on this stuff for six months and I think the rate of change is the most surprising thing. The increase in capabilities of both the models and the tools that we're building around the models in 6 months has been staggering. And so another two iterations of that 6 months - it's hard, I think, for anybody to say where we're going to be. What I will say is I see one of the most interesting challenges in using this technology right now to be - the models are capable, the models are getting very smart. Getting them the right context to perform a task or to perform some unit of work is largely the task. You can have a task in mind for a software project or automating something in a desktop application and if you give the model the right context, it can do a great job. And if you don't give the model the right context or you give it no context or you give it the wrong context, it can do a terrible job.

[13:11](https://www.youtube.com/watch?v=LQIrsmercPw&t=791s) And so I think right now it's like the model development has been fast and then we're realizing that we need to build scalable approaches to giving the model the right context - context discovery algorithms, context management algorithms. Those are the interesting areas that at least we're focusing on in our project and trying to improve.

[13:33](https://www.youtube.com/watch?v=LQIrsmercPw&t=813s) From a human perspective, working with models requires constant adjustment because if a new model comes out and then suddenly you need new language to talk to it because something changed in the system prompt and then it gives you different results from the previous model. So if we speak about Goose, you said it's model agnostic - but how do you adjust these things? How do you work with new models with the variety of models to actually make the task completed?

[14:15](https://www.youtube.com/watch?v=LQIrsmercPw&t=855s) Yeah, it's a great question. Goose does have a top level system prompt that is in the Goose project and that applies whatever model you're using. We have a system prompt that tells it you are Goose, you are an AI agent that helps the user with something. And we have found that as we've experimented with new models that have become popular, we've had to make tweaks to that system prompt at times to make Goose perform well with a given model. It's in theory hopefully designed so that we don't need to do that very often. And in practice, we've found that we don't. But it is fun, and it's interesting - as these new models come out, you start to notice increased performance in certain areas and then you notice other behaviors that maybe surprise you or that you weren't expecting.

[14:55](https://www.youtube.com/watch?v=LQIrsmercPw&t=895s) But I think that's all part of it - each time these models develop and advance, they're going to behave slightly differently. And hopefully that curve is going up in terms of quality in general. But for example, with a lot of the newer models, I've noticed - I code with the models because I'm a software engineer - and I've noticed that they document what they did. They spend a lot more time and energy documenting what they did, which is helpful as a software engineer because you can read a markdown file that it generates that documented the few hundred lines of code that it wrote for you. So you can kind of just read quickly and understand. That's been a welcome addition. We just have to upgrade and try them and see how they behave and make adjustments where we need to. But Goose is hopefully designed - and what we found is it's designed - to not need many changes to take advantage of advances in the model.

[15:45](https://www.youtube.com/watch?v=LQIrsmercPw&t=945s) Well, if we get back to the connections and protocols, what is still missing? It's a good question. I think the registry is a big one. Deploying the registry and getting the registry out in the world I think is a big one. It's in large part been designed and the API is coming together. People are working on implementation and getting a deployment of that registry out in the world I think is a big one. I can't speak to when it will be out - I started working more on one of the SDKs. So my immediate focus has shifted a little bit away from the registry project. There's a checklist that people are working down that's on GitHub - there's an issue that's tracking everything that needs to be done before release.

[16:27](https://www.youtube.com/watch?v=LQIrsmercPw&t=987s) I think getting a version of the registry out in the world so that you can have clients able to discover servers via search and by API will be great. Spec compliance - a lot of the SDKs are not up to date with the June spec. So elicitation is a great feature in a newer version of the spec, the one that was formalized in June. And as far as I know, not many of the SDKs support that at all yet. So spec compliance, getting the SDKs up to date so that there's a reference implementation in every language - that's a missing piece as well.

[17:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=1020s) I'm just trying to understand because trying to think ahead like six months ahead - it should be agents working consistently together finding all these protocols, being able to connect to them. Yeah, sort of blue sky thinking - what would it be or what are the missing pieces if everything were to go really well? I think context discovery and context management are two big pieces. Because like I said, if you have an agentic system and you give a model a task and you give it the right context, it can do a great job. And if you don't give it the right context, it can't even complete the task.

[17:28](https://www.youtube.com/watch?v=LQIrsmercPw&t=1048s) I think MCP won already. You only need a slight edge with open source protocol and you're just zooming - it's really hard to catch up. Bitcoin and Ethereum - Ethereum will never catch up even though you can argue it's a better system. There are AI systems now that claim to be better than the transformer but it's really hard to catch up because the transformer is good enough and everyone's investing in it. So you just need a slight edge and you're off to the races and there's a first mover advantage that accumulates over time. So I think MCP won.

[17:54](https://www.youtube.com/watch?v=LQIrsmercPw&t=1074s) Right now you have a situation where you have a top percent of people who understand the models and they understand AI really well and they know what you have to give the model in order for it to do a good job at a particular task. And so democratizing that - figuring out what the algorithms are that enable agentic systems to discover the right context by themselves in a proactive way - is a great high-level goal. The technical pieces that we'll need to build to get there, I think, are not yet in focus for anyone. But that's the work ahead - figuring out how you can get to a system where anybody who has a goal can interact with an agentic system and get a good result equal or better to what the most skilled professionals at using AI are getting.

[18:35](https://www.youtube.com/watch?v=LQIrsmercPw&t=1115s) Because yeah there are so many software developers that are not yet fully involved with AI and agentic systems. How did you get involved? I got involved because I started working on this project. I started working on Goose at Block - I joined this team in November of last year to help out with a particular work stream for the project. And as soon as I started working on it, I saw how powerful it was and I just said I need to find a way to join this team and work on this project all the time, and so that's what I did.

[19:05](https://www.youtube.com/watch?v=LQIrsmercPw&t=1145s) Yeah, I see a lot of software developers reading the newsletter just trying to understand what's happening, what are all those terms mean, how to get in. It's such a huge force coming into AI. Yeah it's a fascinating time. It's a time of tremendous change and opportunity for all of us I think. The whole nature of creating software is changing fundamentally. It's not changing in an incremental way, it's not an incremental improvement, it's not a new developer tool. This is a new way of working, this is a new way of creating software and automating any other kind of work that occurs on a computer. That's not a small change, that's a fundamental change and one I'm really excited to be part of.

[19:45](https://www.youtube.com/watch?v=LQIrsmercPw&t=1185s) How much are you accelerated, how much empowered have you become? Yeah, these measurements that people give of what percent improved they are - I don't know. It's funny. I definitely think my output is dramatically increased as a software engineer. Quantifying it is hard for me. I haven't come up with any mechanism to measure in any scientific way how much my productivity has increased. But I would say it's the biggest change in magnitude in productivity of my career - in my 15-year career so far as a software engineer. I've never experienced something that's increased my productivity this much.

[20:20](https://www.youtube.com/watch?v=LQIrsmercPw&t=1220s) My husband is a software developer and he was telling me - I have four open windows with four different projects, completely different, and while one model and one agent works on one task there's time to work on the other. So at least four times acceleration. It's just from observation - it's a tremendous help. Yeah, it changes completely. When you can have code generated for you in a matter of minutes that used to take hours to write - hours of focused effort to write - I think part of the challenge is how do we then interface with that? How do we interface with that increased output that's now possible?

[20:55](https://www.youtube.com/watch?v=LQIrsmercPw&t=1255s) And that's like I discussed - context, getting the model the right context, is a really important thing. I think the interface to these models is also tremendously important to get right. If you have multiple agents working at the same time and there's something that's time-sensitive or requires you to give input and you have multiple work streams going - how do we surface that to the user in a really clear way? Like hey, this project that you're working on needs your input and it's important, and you can let those other things that are still working sit in the background. Surfacing a notification or something that gets the user to weigh in - so it's almost like the traditional stuff of interface design is what we need to do and we need to figure out what the right interfaces are to this new capability that we've never had before in the models.

[21:40](https://www.youtube.com/watch?v=LQIrsmercPw&t=1300s) I liked what you said about when you give the right context to your model it can complete the task and if there is no context it fails. But my question would be - what do you think in this context about artificial general intelligence? You are very deep in the trenches but like what about this bigger picture?

[22:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=1320s) Sort of above my pay grade I think. I see these systems as getting more capable day by day and week by week, month by month. I think my unscientific hunch is that that will continue and that these tools will get more powerful, simply based on my observation that in the last 6 months there have been drastic changes in their capability on the time scale of a few months. So I think with access to more data opening up, more modes of interaction and modes of output from the models, and more relevant context for the model to perform different tasks, I think we'll continue to see rapid improvement in terms of agents like Goose - what they're able to accomplish for you.

[22:40](https://www.youtube.com/watch?v=LQIrsmercPw&t=1360s) The AGI discussion is an interesting one. And I think - I forget who said this, but I liked the description of it that I heard - that it's a process that's going to be continual improvement and it's not going to be like a before and after. These things just continuing to get more and more and more capable and doing more for us, and at a certain point you're going to look at them and realize that they're incredibly powerful and incredibly intelligent. So I'm not sure there's going to be like a before and after moment.

[23:10](https://www.youtube.com/watch?v=LQIrsmercPw&t=1390s) Yeah, I think it's - I mean it's Yann LeCun's constant saying that it will be incremental, constantly improved. There is no you wake up and AGI is here - it doesn't work that way. But I hear when you're saying about context - I hear that there's always human in the loop in that scenario.

[23:30](https://www.youtube.com/watch?v=LQIrsmercPw&t=1410s) Right, and there's still a tremendous amount of human expertise as well. Because you can have two people sit down with a given task and an agentic system like Goose and one person who really knows the project that's being worked in can effectively drive a tool like Goose to get a really great result right away. And someone who's never worked in the project before may not know the files to indicate to the model are important to look at. And so there's still a tremendous amount of human expertise involved as well getting good results from these tools.

[24:00](https://www.youtube.com/watch?v=LQIrsmercPw&t=1440s) Yeah, I believe it will stay that way. Wrapping up our interview - I always ask this question about a book that shaped you and it can be related to your professional life or completely unrelated. I have to go to another big piece of my life which is running - competitive distance running. So I run track and field and cross country and road races. And I'll call out the book "Once a Runner." If you ask a runner - ask anybody who runs track and field - they'll know this book. It's a seminal book about running and one that I constantly go back to for inspiration when I'm building up to a big race.

[24:25](https://www.youtube.com/watch?v=LQIrsmercPw&t=1465s) Give me a little details - what are the main lessons you learned from that? The idea of going all in on something. The protagonist in the book - it's written by a guy named John Parker, and John Parker was a sub-4 miler in high school or college. The protagonist of the book is not him but it's a character that's based around him and his pursuit of running a mile under four minutes. What I like about the book is that it shows the importance of - if you really want to achieve something, if you want to do a great job at something, if you don't want to just do a good job but you want to be excellent, you want to run the sub-4 mile - what it requires, what it really looks like for somebody to go all-in on something and to dedicate their life to it. I just find a great deal of inspiration from that idea of picking something that's important to you and structuring your life around it so that you can achieve greatness.

[24:50](https://www.youtube.com/watch?v=LQIrsmercPw&t=1490s) That's awesome. Thank you. I love this question about books. It opens up people.
