---
video_id: RW01xM8Jj3o
title: "Solving the Hallucination Crisis: Sharon Zhou (Lamini) on the Future of Enterprise AI"
channel: Turing Post
duration: 2294
duration_formatted: "38:14"
view_count: 1054
upload_date: 2025-07-07
url: https://www.youtube.com/watch?v=RW01xM8Jj3o
thumbnail: https://i.ytimg.com/vi/RW01xM8Jj3o/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Sharon Zhou
  - Lamini
  - Hallucinations
  - Enterprise AI
  - Fine-tuning
---

# Solving the Hallucination Crisis: Sharon Zhou (Lamini) on the Future of Enterprise AI

## Summary

In this in-depth conversation, Sharon Zhou, CEO of Lamini, discusses her journey from teaching millions of people generative AI through Coursera courses to founding a company dedicated to solving the enterprise AI hallucination problem. Sharon reveals her unique path from studying classics (Latin and ancient Greek literature) to becoming an AI researcher under Andrew Ng at Stanford, where her dissertation focused on generative models and she developed what she calls a "maternal instinct" watching early image generation models improve.

The technical heart of the conversation centers on Lamini's breakthrough approach to hallucinations. Sharon explains that hallucinations are a technical problem, not a philosophical one - they discovered that certain tokens need to be more deterministic in certain contexts. Their solution involves "surgery to the models" - creating a new post-training recipe that alters LoRA adapter layers and turns them into a mixture of experts, effectively embedding retrieval capabilities directly into model weights rather than relying on external RAG systems. This approach has achieved dramatic accuracy improvements: from 30% to 90% for Colgate, and from 6% to 90% for another Fortune 100 company.

Sharon also shares insights on why AI researchers are surprised by market excitement around "agents" and "RAG" - these are different views into the same technology, with agents being like object-oriented programming while models are like functional programming. She emphasizes that the future requires democratizing AI expertise: "There are only a few hundred of us AI experts who can successfully teach and control AI. The future would suck if we were the only ones who could define what intelligence could be."

## Highlights

### "These Are My Children" - Maternal Instinct for AI Models

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=93s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*1:33-2:20" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-1m33s.mp4"
```
</details>

> "It weirdly turned on my maternal instinct. I was like, 'These are my children.' Because you could see the model improve over time. Like over time, you see eyes as it trains and then you see a full face and then you're like, 'Oh my gosh, I nurtured it to get to this stage. I tuned the right hyperparameters, I put in the right data to get it into the right place.'"
> — Sharon Zhou, [1:33](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=93s)

### "Hallucinations Are a Technical Problem"

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=454s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*7:34-8:25" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-7m34s.mp4"
```
</details>

> "We realized it was actually a technical problem, not a philosophical one. For many of them it was just that certain tokens needed to be a little bit more deterministic in certain contexts and they couldn't be made up. Once we were able to frame the problem correctly, we were able to solve it technically."
> — Sharon Zhou, [7:34](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=454s)

### "From 6% to 90% Accuracy"

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=654s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*10:54-11:40" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-10m54s.mp4"
```
</details>

> "For Colgate, it was from 30% accuracy using OpenAI's latest model to 90%. For another Fortune 100 company, they had even more complex stuff - it was 6% to 90%. The most magical thing for me is seeing them do it - not us. I was not there. I did not write a line of code for them. Their developers did it."
> — Sharon Zhou, [10:54](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=654s)

### "Agents vs Models: Object-Oriented vs Functional Programming"

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=874s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*14:34-15:30" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-14m34s.mp4"
```
</details>

> "The agent view of the world is centered around almost a human or an individual. The AI is an individual as opposed to AI as a model. The equivalence in software engineering is OOP - object-oriented programming - as opposed to functional programming. It's just a different view into almost effectively the same thing."
> — Sharon Zhou, [14:34](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=874s)

### "Cancer Research: 3-5 Years to Weeks"

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1133s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*18:53-19:35" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-18m53s.mp4"
```
</details>

> "They're trying to bring down a three to five year timeline of regular cancer research to just weeks. If you just step back and think about it, that transforms an industry completely. That completely and fundamentally will change human health."
> — Sharon Zhou, [18:53](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1133s)

### "It's Never the User's Fault"

[![Clip](https://img.youtube.com/vi/RW01xM8Jj3o/hqdefault.jpg)](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1755s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*29:15-30:10" "https://www.youtube.com/watch?v=RW01xM8Jj3o" --force-keyframes-at-cuts --merge-output-format mp4 -o "RW01xM8Jj3o-29m15s.mp4"
```
</details>

> "I only went into computer science because I took a class where the professor said, 'It's never the user's fault.' And I just thought it's never been my fault. I was made fun of for using technology growing up and I was not good with it. And I was really inspired to think, well, if I am the dumbest user, I can think of ways to design the system for that dumbest user like me."
> — Sharon Zhou, [29:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1755s)

## Key Points

- **From Images to Language** ([2:43](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=163s)) - Sharon started in generative AI around 2017 with image models, then moved to language models around 2020-2021 due to commercial relevance
- **Coursera Teaching Scale** ([0:11](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=11s)) - Started teaching one person, grew to 100,000, now teaches millions through Coursera
- **Why Start Lamini** ([4:07](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=247s)) - Vision to let more people steer models, define safety, and shape model behavior - not just OpenAI and Anthropic
- **300 Customer Interviews** ([6:33](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=393s)) - Talked to 300 potential customers to find the right vertical - hallucinations emerged as the biggest problem
- **Technical Solution** ([8:09](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=489s)) - Created a recipe that alters LoRA adapter layers and turns them into mixture of experts, embedding retrieval in weights
- **Extreme Accuracy** ([8:37](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=517s)) - Can retrieve facts "to the nines of accuracy" by putting retrieval into model weights rather than external RAG
- **Enterprise Evals Don't Care About MMLU** ([9:48](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=588s)) - Enterprises don't care about benchmarks like MMLU or Spider - they need custom evals on their complex schemas
- **Hands-On Coding** ([11:57](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=717s)) - Sharon still pulls all-nighters coding; believes best product people in AI need to work with models directly
- **Agent Confusion** ([13:44](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=824s)) - AI researchers are surprised by market excitement around "agents" - it's just a different view into the same technology
- **RAG Misconception** ([15:16](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=916s)) - RAG isn't AI - it's information retrieval (no backpropagation), but people conflate it with AI because it plugs into models
- **Biotech Use Case** ([18:53](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1133s)) - Global 2000 biotech company using Lamini to reduce cancer research timeline from 3-5 years to weeks
- **Objective Outputs Key** ([20:13](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1213s)) - Most important thing is that use cases have objective outputs where experts agree on what's good
- **Creativity as Next Vertical** ([22:33](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1353s)) - After hallucinations, creativity could be the next vertical of intelligence to optimize
- **Open Source Dependence** ([25:50](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1550s)) - Lamini depends heavily on open source, particularly Meta (Llama), Mistral, and DeepSeek
- **Classics Background** ([29:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1740s)) - Before PhD, Sharon studied Latin and ancient Greek literature, then was a product manager

## Mentions

### Companies
- **Lamini** ([0:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=0s)) - Sharon's company solving enterprise hallucination problem
- **Colgate** ([9:43](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=583s)) - Enterprise customer, improved from 30% to 90% accuracy
- **OpenAI** ([4:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=270s)) - One of the few organizations currently able to steer foundation models
- **Anthropic** ([4:32](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=272s)) - One of the few organizations currently able to steer foundation models
- **Meta** ([25:55](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1555s)) - Partner for Llama models
- **Mistral** ([26:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1565s)) - Partner for open source models
- **DeepSeek** ([26:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1570s)) - Open source models beneficial for Lamini's customers
- **Stanford** ([5:35](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=335s)) - Medical school collaboration on healthcare AI projects

### Products & Technologies
- **LoRA Adapter** ([8:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=495s)) - Technical component modified in Lamini's approach
- **Mixture of Experts** ([8:18](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=498s)) - Architecture Lamini transforms adapter layers into
- **RAG** ([15:16](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=916s)) - External retrieval approach that Lamini replaces with in-weight retrieval
- **Text-to-SQL** ([6:38](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=398s)) - Original focus area for Lamini
- **Spider/Bird Benchmarks** ([10:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=600s)) - Common SQL benchmarks that enterprises don't care about

### People
- **Sharon Zhou** ([0:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=0s)) - CEO of Lamini, former Stanford PhD, Coursera instructor
- **Andrew Ng** ([2:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=125s)) - Sharon's PhD adviser at Stanford

## Surprising Quotes

> "Image-based models, they were producing images that looked like nightmares - kind of people that would show up in horror movies. But that was considered good - better than just random pixels."
> — [0:46](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=46s)

> "I talked to my friends at OpenAI and Anthropic and they're like, 'I don't know why the market cares about agents, but I guess we have to do this for marketing.'"
> — [13:47](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=827s)

> "RAG isn't AI - it's information retrieval. The ultimate retrieval is Google. And it's actually not AI - there's no backpropagation - but people view RAG as AI because it plugs into AI."
> — [15:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=925s)

> "There are only a few hundred of us AI experts who can successfully teach and control AI. The future would suck if we were the only ones who could define what intelligence could be."
> — [27:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1650s)

> "I created a hundred memes for my Stanford class to help people study. One of the extra credits was: if you can create a meme and I laugh at it, you get extra credit - because if you understand something, you can make a joke about it."
> — [32:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1965s)

## Transcript

[0:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=0s) You've been doing generative AI way before it became fancy. Yes. And you taught a huge Coursera course. Yes. How many people? I now teach millions of people, but it started with one. It started with one. At some point it was like 100,000. Now it's millions.

[0:24](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=24s) How do you think the audience changed when you started? Oh, this whole - yes. Well, I think the biggest thing is how commercially relevant it is today. So, initially it was a very just magical piece of technology. You know, you could almost - or at least I could see the promise of it where it was going, but of course the outputs it was producing not really usable, right?

[0:46](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=46s) Image-based models, they were producing images that looked like nightmares - kind of people that would show up in horror movies. But that was considered good - better than just random pixels. And so that was really compelling at the time and now we can generate videos that look completely realistic so it's completely different. I started working on generative AI around 2017.

[1:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=75s) Yeah, I remember thinking about in 2019 I was creating this whole concept of media that would use generated images anchors and no one believed me. I said no, it's... So, well, you're a visionary, but it was amazing to see these horrifying pictures and like being fascinated. Oh, yes. Absolutely.

[1:33](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=93s) I feel like it weirdly turned on my maternal instinct. Yes. I was like, "These are my children." Because you could see the model improve over time. Like over time, you see eyes as it trains and then you see a full face and then you're like, "Oh my gosh, I nurtured it to get to this stage. I tuned the right hyperparameters, I put in the right data to get it into the right place."

[1:58](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=118s) And so, it did weirdly turn on my maternal instinct and I would call them my children. And I think my PhD adviser, Andrew, was like, "That's a little weird, but okay." And I would have all these, honestly, I had all these screenshots on my computer of these generated faces, which looked really weird at the time, but I think now it's like ubiquitous, right?

[2:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=145s) People are generating things all over the place, and it's magical seeing how creative people are. So something that makes me really happy is I feel like a lot of people have also seen the magic in this technology. And it's not just me. That's been just captivated by it. Yeah, it's absolutely magical.

[2:43](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=163s) How did you move from creating working with images to what you do now? Yes, such a good question. So in between I started working on language as well. My background actually before my PhD I was a product manager but before being a PM I actually studied classics - like Latin and ancient Greek literature - and I loved languages.

[3:07](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=187s) So all of that kind of combines into language and communication for product and storytelling. And so I loved all those pieces. I love Disney and Pixar movies. Maybe that's a big piece of it. I love putting that all together. And so I started working on language as well. I was the head of AI research of a nonprofit - not OpenAI but nonprofit - for aligning language models similar to OpenAI safety for these language models and working with them there.

[3:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=220s) That was probably around 2020ish, 2021 maybe. I started working on the language models more because they really took off from a commercial standpoint and I felt like the use cases could make a very big difference in the enterprise where I have my experience professionally in product. I was an enterprise product manager.

[4:07](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=247s) And so that's what really motivated me to start this company. And a few things kind of drove me to start Lamini. One was seeing all these amazing foundation models. I thought, well, wouldn't it be even more magical if more people in the world could steer these models, right? More people could define safety, more people could define where these models could grow and what these models could be capable of. They could really steer what this model's behavior should be and what the model's knowledge should be.

[4:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=280s) Which is what, you know, currently is a little bit more confined to the likes of OpenAI, Anthropic, etc. because they have those AI researchers. So I thought what if we can enable more people - developers starting with developers, maybe not my grandma yet - but starting with developers to be able to steer these models. And there are 24 million developers out there, probably more now given AI.

[5:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=305s) But what if we could give them the keys to doing that? I think we'd be able to build better models. I do believe that AI experts like myself - we can't define all the different definitions of safety, of what goodness is in these models, of what useful applications are in these models, what real capabilities they can give to the world and how they could serve the world.

[5:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=325s) I believe that people who understand their own problems best, when given the right tools, are best suited to solve them. And they can definitely see those problems better than myself. And I saw that during my PhD too. I studied generative models - that was my dissertation. But I also did some projects that were applied in healthcare. So we collaborated with the medical school at Stanford.

[5:50](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=350s) And it was very clear to me that the doctors had such deep insight into what machine learning could actually help with that was not super obvious to me. In terms of how could this help with cancer - oh, it's predicting this bacteria that predicts cancer. I didn't know that. And so they understand that very deeply and how this could be an assistive tool, how could this be helpful in diagnostics.

[6:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=375s) I feel like for all these disciplines, if we could give this magical technology as a tool to all these people, that would just enable so much more impact in terms of what we do. And so that was kind of the seed of starting Lamini.

[6:33](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=393s) And then Lamini grew into finding - okay, what vertical of intelligence do we want to help people steer these models to first? We can't do everything - even OpenAI doesn't do everything, they're focused on reasoning today. And so what vertical do we want to focus on? Talked to 300 potential customers and came up with this idea of - actually initially it was helping people access their structured data with text to SQL.

[7:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=420s) And then it morphed as I talked to more customers - oh, we need to be able to steer these models further, not just for this vertical but more broadly in this horizontal platform. So then it turned into fine-tuning these models, editing these models directly - taking it to the next step, not just prompting them, but deeply editing them and doing backprop on them.

[7:22](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=442s) And then the next stage was realizing - oh actually, we don't want to cover everything because that's a lot for a startup to do and it also is confusing to the end customer. So let's focus on one vertical of intelligence and do that really well. And the biggest problem that we saw was hallucinations. People kept mentioning hallucinations.

[7:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=465s) We decided to double click and ask - and not just ask but really inspect in the customer's data and understand what their objective was exactly, what was hallucinations to them. And we realized it was actually a technical problem, not a philosophical one. And that for many of them it was just that certain tokens needed to be a little bit more deterministic in certain contexts and they couldn't be made up.

[8:09](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=489s) And I'm sure there's multiple definitions of hallucinations, but that was one of them. And this is - like once we were able to frame the problem correctly, we were able to solve it technically. Now, was it easy? Like no, we had to do surgery to the models and we had to edit the way the models were post-trained, fine-tuned.

[8:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=510s) And we basically created a new kind of recipe that alters the LoRA adapter layer of these models and turns them into a mixture of experts which effectively is equivalent to learning a retriever in a learned index - like putting that into the adapter layer as opposed to an external retriever for an index, which is like RAG. And so putting that into the weights of the model so that it could retrieve these facts very, very accurately - like at extreme accuracy levels, like to the nines of accuracy.

[9:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=545s) And so we discovered this by working with these design partners - maybe like a handful of them, not all 300 of course - and realizing, oh, we can solve this problem. This is really exciting. It's not impossible. It's not just... and this was when OpenAI was releasing papers like "hallucinations are by design" - like these models are designed to hallucinate.

[9:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=565s) No, that's very interesting because from my perspective when people talk about hallucinations, it's sort of like a vibe thing. Oh, yeah. It is not very accurate. So, it's more like an impression or you find something very concrete but is it technical? People don't talk about it, right?

[9:52](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=592s) So, when you found it, do you have any like metrics or inside benchmarks for that to show companies? Yes. Well, I think two types of benchmarks matter most. One is around - we have a comparison between like a base model on a Wikipedia page, for example on the Golden Gate Bridge, and it just hallucinates on the facts in it versus our model doesn't hallucinate on the facts. Right? And so it goes from something like 30% to 90% accuracy.

[10:22](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=622s) So being able to show that. And then of course for our customers, often enterprises - for example Colgate's one of our customers - they and other companies don't really care about general evals, right? They don't care about MMLU or like how the models do on math. Like none of this matters to them. Many of them don't even care about the text-to-SQL benchmarks out there.

[10:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=645s) So I think for example Spider and Bird - these are very common text-to-SQL benchmarks in the machine learning community and have been around for a while. And they don't care because they're like, just because a model does well on that doesn't mean it does well on my pretty complex schema. It's a very, very different task. And if you go inspect it, it's actually an extremely different task - not just that the schemas are much more complex, like the task itself is ill-defined for what the enterprise actually wants the model to do.

[11:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=675s) And so what we do instead is - okay, well, let's inspect your own internal evals. Let's actually help you craft that in a way that - and we have a framework for that they can follow and easily be able to craft that now. And so they can just follow that - easy, medium, hard is kind of the simple breakdown - and let's get the model to actually tackle easy, medium, hard questions.

[11:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=700s) And get to typically the threshold is usually around that 90% because I always want to see a nine in there. For Colgate, it was from 30% accuracy using OpenAI's latest model. For another Fortune 100, they had even more complex stuff - it was 6% to 90%. So yeah, just very big leaps of what they can do.

[12:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=725s) And the most magical thing for me is seeing them do it - like not us. Like I was not there. I did not write a line of code for them. They did it. Their developers did it. And that's really magical because it's not like they poached a team from OpenAI to do it, right? Like they're able to steer these models to that extreme accuracy.

[12:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=750s) "Oh, we can now rely on these models for these particular tasks, tokens and in this particular context, but it can still be this magical probabilistic system that can handle similarities. It can handle things that are fuzzier as well." And so it combines almost the good aspects of determinism with the good aspects of probabilistic nature of these models. And so I find that really exciting.

[12:55](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=775s) That's incredible. How involved are you in the technical, coding? Yes. These days actually more so than - I guess it fluctuates. But I will dive into the code. Recently I may have pulled like three all-nighters on the weekend to write something, build something out. But yeah, I think diving into the code is actually incredibly important, especially in the space.

[13:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=805s) I actually have an opinion that the best product people in the space are people who can work with these models - either just work very comfortably with these models, write code around that, or actually be a machine learning expert themselves. Because there's so much at the Pareto frontier of feasibility and usability here that we're working with. Like let's say you're a product person and you imagine ChatGPT but you couldn't actually like really prototype all the pieces - like the instruction fine-tuning, RLHF - you would never... that would just be an impossible thing to build. Like you have to actually do both.

[14:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=840s) And so I think it's incredibly important to do both. You have such a deep understanding of so many levels. People not that knowledgeable - what is the most often misconception you see, you hear from the clients, from the enterprises specifically? What don't they understand about GenAI? What do you need to constantly explain to them?

[14:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=865s) Oh, what do I need to constantly explain to them? I think there are a few things. For AI researchers, we find - funny is not the right word, but maybe we're just surprised that the market is interested in a few things. One is just the word "agent." I think AI researchers - like I talked to my friends at OpenAI, Anthropic, and they're like, "I don't know why the market cares about this, but I guess we have to do this for marketing."

[14:55](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=895s) And it's interesting because I feel like my gut reaction was also an allergic reaction, but then I double-clicked more and started to talk to more and more people about it, including just non-AI researchers. And I think that's where it really clicked for me. This is just a different view into the same thing.

[15:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=915s) So I think in a very model-centric way because I'm very comfortable with these models and that's how I've been working for the past decade. But other people might not view it that way. They view it as like how does this AI work with, interact with a person or mimic a person. And so I think the agent view of the world is centered around almost a human or an individual. The AI is an individual as opposed to AI as a model.

[15:48](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=948s) And I think the equivalence in software engineering is OOP - like object-oriented programming - essentially that's like object-centered as opposed to like functional programming. So it's just a different view into almost effectively the same thing that you can accomplish.

[16:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=970s) So I think that's one of the things that I find there being a mismatch between the experts and the folks who recently jumped into the space and are very excited about it. I think the other thing is around RAG. So I think people are kind of mesmerized by RAG. And for those of us who've been in the space for a long time, we're surprised they are because the ultimate retrieval is Google. Like the ultimate retrieval has been built.

[16:42](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1002s) And it's actually not AI - but people view RAG as AI. It's actually information retrieval which has been around for much longer than AI but it plugs into AI and so it connects to the AI brain. And it's just fascinating to me that I think it's confused with AI - because there's no backpropagation, you're just - it's like what you effectively put into the prompt.

[17:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1030s) And of course it affects the model as input but it's just fascinating to me that people kind of conflate that together because from a technology standpoint that doesn't really mean anything. But when I think about it along with agents it actually kind of makes sense because I think then it's like the full agent does all these things and comes together and it's this entity that's an individual, and then it kind of makes sense that they view this whole system as an AI as opposed to just the model piece.

[17:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1065s) Yeah. So, it's - so I find those kind of really interesting. No, I think they're important to understanding things, hence why they're so big in the market because I think they explain a lot to people. I think it actually is the almost user experience or interface that makes the most sense to other people.

[18:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1090s) And it's just funny that I think in some ways experts like myself, we have expert blind spot, right? So we just are so used to viewing the world from a model-centric way that it's almost a little confusing to us to see it that way. But I actually think it's a media person who opened my eyes the most. When I had a conversation with her, I realized, oh wow, like having the agent view of things actually makes way more sense to her of what AI does and how AI actually impacts the world.

[18:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1125s) Like otherwise, if it's model-centric, she's like, how does that really impact the world? It doesn't impact the world or it's not clear how it impacts the world. It's just like - it's not a clear story, right? It's not a clear line. But when it's agent-centric, it suddenly is very clear what it is. And so, or it also matches all the sci-fi movies better. And so it just clicks.

[19:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1155s) So, it's more about narrative. Yeah. Yeah. Yeah. Or a view into things. And I think in a lot of disciplines including software engineering - like I know narrative sounds subjective but like object-oriented programming is a legitimate way of programming that's different from functional but it does help you or at least some people develop things in that way. It's almost like each individual object is an individual, right? But it doesn't necessarily have to be that way.

[19:50](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1190s) Well, a lot of people ask and learn about use cases. So, you said about Colgate. What are other industries and cases that you're proud of? Yes. There's one that I'm very excited about. It's a global 2000 biotech company, one of our customers, and it's actually crazy what they're trying to do. They're trying to bring down a three to five year timeline of regular cancer research to just weeks.

[20:20](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1220s) And that's just - if you just step back and think about it, that transforms an industry completely, right? Like that completely and fundamentally will change human health. And so I'm very excited about that because it not only helps them make money but it also does good for the world I believe.

[20:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1245s) So I think that's transformational in a way that I can't even imagine how that industry will operate moving forward if it does that - because now this one company is going to leapfrog other companies who can't do this. So that's very exciting. And what they're doing specifically is they're using our platform on-premise and they are combining both public patent data as well as private PII data together because that's how they get the best information.

[21:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1275s) But they're doing it in a private way so it's safe and the data is secure because they're not comfortable sending that away. But they needed to be highly accurate and specialized and the goal was to get quote "better than a scientist." And that is what they said. So very exciting times I think.

[21:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1300s) Is it important for you for the companies to have like super structured data? Oh, I see. No, actually it's not important. Actually, the most important thing for us is that the use case that these companies have has objective outputs - meaning you can tell me what's good, better, and best and your experts will agree with each other on it.

[22:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1325s) Because the more subjective it is, you're basically giving the model multiple north stars and it doesn't know where to go. And it can optimize for one but then it'll just be worse at the other. And so these models are really good at optimization so you want to be very clear what your north star is. You don't want to have like a giant fuzzy blob and then everyone's upset that it didn't go in the right way.

[22:35](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1355s) Biggest challenge we often face with our customers initially is just scoping that use case in a way where it is an objective use case. So that's why we actually like text-to-SQL. We can see - not only does it permeate every enterprise because every enterprise has been putting their data into structured formats for a long time - for decades - and their most valuable data is there because that's how we've done analytics historically.

[23:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1385s) Not only that, but they also - like when the SQL query fails, we can all agree it failed. We can all agree. There might be some subjectivity around some stuff, around some calculations, but we can write that down together and we can look at it and we can say like we agree the model should do this.

[23:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1410s) When we've done factual reasoning cases as well - so like, these models are really good at reasoning but they might not be grounded in the facts of your business and you want to put a lot of facts into it. But sometimes people disagree - sometimes domain experts will disagree with each other on what the right output is. Even stylistic things like, "Oh well I wish the model would be more concise" and then another person's like, "I want it to be more verbose."

[24:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1440s) Basically you have to be very clear what you want. And in the text-to-SQL case it's just so clear - it's already laid out. So we like that for that reason and there are some other use cases where it's clear like that.

[24:20](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1460s) But I think something that's been surprising to me is that sometimes a use case can seem very clear on the outset - like function calling. Function calling typically is clear but in some cases it's actually not clear in the way that our customer has set it up. And so I'm like, "This is not clear - like no person would agree with this labeled response."

[24:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1485s) Do you think you will go from hallucination to cover some other? Yes. What's next? Oh my goodness. Okay, I can't say exactly what's next because I do think hallucinations will take up a lot of time for us. And I think our customers will help show what would be prioritized next.

[25:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1510s) But in terms of ideas what's next - one is creativity. Like what if these models could be even more creative than they are now and optimizing for that could be one thing. That's another vertical of intelligence. I don't know - just putting token after token, actually creating something new... or thinking divergently with people. But I don't know how valuable that is for us to create a business that does work and that does bring in revenue.

[25:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1545s) We do have to kind of follow where the value is. And right now hallucinations is probably where we see the biggest value - maybe the same amount of work as going after creativity but they value this hallucination piece a lot more today.

[26:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1565s) What is your general take on open source? Oh, I love the way the open source is going. I mean, we leverage a lot of open source. We enable our customers - usually our customers are actually comparing, effectively using one of the open source models using our system to post-train it, edit it on their own model - like using Llama or DeepSeek first and then using our system to modify it towards their data set so it doesn't hallucinate on their data.

[26:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1600s) And comparing that against either OpenAI or cloud-based models. And so that's typically what's going on. So we depend so much on open source and we're partnered very closely with Meta in particular on that. Also a bit with Mistral. And yeah the DeepSeek stuff has been very helpful for us.

[27:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1625s) And very helpful for our customers of course - like some of our pipelines, it does benefit from reasoning, and so yeah those really - we use it so much. Yes, we do. Because our thesis is not to - for us as infrastructure to not own the models. It's for our customers to own them because they are deep derivatives of their data at the end of the day.

[27:35](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1655s) And so we want them to be able to have that - effectively apply their same data governance to their models and the weights. And so we don't need to see them, but we're just the infrastructure that helps them modify it.

[28:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1680s) In your bio on LinkedIn, you wrote, "There are only a few hundred of us AI experts who can successfully teach and control AI. The future would suck if we were the only ones who could define what intelligence could be." I also find lack of knowledge about AI combined with the pace it's developing jarring and concerning. Tell me about your thinking. What should we do about this lack of knowledge?

[28:35](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1715s) Oh yes. I think there are a few things we can do about it. So I think one is making the barrier to entry lower. So being able to make these tools much easier to use. So the fine-tuning recipe, post-training recipe that we've developed is much much easier to use than say OpenAI's fine-tuning API. For Colgate for example, they can successfully use it - so that's a big deal.

[29:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1745s) It becomes easier and easier to use - that will become the de facto way an AI expert might even use it. Like now we default all use these phones because it's so easy to use but before that was originally maybe not the intended purpose - or it's for accessibility initially. And I actually deeply believe that this post-training and fine-tuning and these RL methods - these can become as easy as prompting. And I think everyone can kind of do prompting, right?

[29:40](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1780s) If you can Google search, you're prompting. Yeah, relatively easy - relative to like monitoring loss curves and understanding what that even means. And so that's really exciting to me. And I think more automation around it or more intelligent design of these systems - whether they be either more verticalized towards a form of intelligence or it just deeply understands what people want to influence or not in the model - can actually offer the right types of inputs.

[30:15](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1815s) Like you don't want to overwhelm people with "these are all the hyperparameters you can possibly play with" because I think that becomes really overwhelming. And you have to understand all this math to edit them. And 90% of them don't matter for your use case and there's default ones and you actually don't need to know the math. So why bother making it seem so complex when it can be so simple?

[30:45](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1845s) And then the other thing is leveling people up. So lowering the barrier to entry and leveling people up will get people to be able to meet in that middle and be able to access this more. And so leveling people up is something I'm personally very passionate about around teaching.

[31:10](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1870s) And my background is actually - like I said, classics. So I actually didn't have a computer science background going in and I was studying literature. And I actually only went into computer science because I took a class where the professor said, "It's never the user's fault."

[31:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1890s) And I just thought, it's never been my fault. I was made fun of for using technology growing up and I was not good with it. And I was really inspired to think, well, if I am the dumbest user, I can think of ways to design the system for that dumbest user like me - because I can see it. The experts can't see it.

[32:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1920s) So I can see it and I can make it so easy to use that then everyone won't feel intimidated by technology anymore. And so that's what inspired me. That's why I went into product management actually because you really think about the end user and you want to empathize very deeply with that end user and have a lot of user empathy and compassion for them.

[32:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1950s) And so that's what motivated me. And then of course I just kind of fell in love with the magic of generative AI. And so combining that together is this company and it's my courses of how can we make this all more accessible - how can we make this more accessible by lowering the barriers to entry and then leveling people up and not making it intimidating.

[33:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=1980s) Like I try to make my courses as engaging as possible and try to make them as intuitive as possible too because I don't think you necessarily have to be bogged down by the math - or sometimes the math can actually be quite simple.

[33:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2005s) Probably an extreme case - I spoke to policymakers in DC and gave them like a masterclass on it and they were like, "This is the first time I've actually understood neural networks." And I explained everything. I got pretty deep and I kept it - the most technical language I used was multiplication and addition and that's it. But they actually got it and we went through the math, we went through math.

[33:55](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2035s) And so I think it's possible - 100% possible - and it doesn't have to feel intimidating and you can actually understand how this all kind comes together and it is magical once it all comes together. I do think people can understand all the pieces and I think it can be done in an engaging way too.

[34:25](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2065s) I'm kind of a believer of like - I thought about starting something like TikTok for education, but essentially edutainment. Yeah. Because one of my big thinking right now about kids is they use it as a natural part of their life. Yes. They're AI natives. AI natives. But I believe they do need to know what's the technology and what is machine learning and what are all this prompting...

[35:00](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2100s) Prompting is not very easy because you need to know what to communicate to the computer and it's different from fine-tuning when you need to have more technical knowledge. But I just think learning about this stuff can be very engaging and fun.

[35:30](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2130s) The class I taught at Stanford previously - I actually created a hundred memes for it to help people study. Because like why not laugh when you're studying? And one of the extra credits I gave people was - if you can create a meme and I laugh at it, okay fine, if it was funny, I don't have to laugh that hard, but like if it was funny and you created a meme and you demonstrated your knowledge of the concept and you could even have humor around it - because that means you demonstrate your knowledge.

[36:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2165s) Like if you understand something, you can make a joke about it. But if you don't understand it, it's harder to make a joke about it. And so if you can demonstrate that, then you get an extra credit point. And so why not make learning fun?

[36:35](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2195s) That's amazing. I think that's wonderful. You know, making things fun and accessible and engaging - I think that's really the key. Because ultimately this technology is going to shape everybody's lives, and the more people who understand it, the better decisions we'll make as a society about how to use it.

[37:05](https://www.youtube.com/watch?v=RW01xM8Jj3o&t=2225s) So thank you so much for sharing all of this. It's been a really fascinating conversation. Thank you for having me. This was fun.
