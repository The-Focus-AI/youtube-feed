---
video_id: Uh8_RX-Ik1o
title: "Why do we need a special Operating System for AI?"
channel: Turing Post
duration: 1558
duration_formatted: "25:58"
view_count: 1145
upload_date: 2025-10-17
url: https://www.youtube.com/watch?v=Uh8_RX-Ik1o
thumbnail: https://i.ytimg.com/vi/Uh8_RX-Ik1o/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Neural Networks
  - AI Breakthroughs
  - Technology and Society
  - AI in Real Life
  - Turing Post
  - AI Revolution
  - AI Trends
  - production AI
  - GPUs
  - exabyte storage
  - AIoperatingsystem
  - metadata
  - enterpriseAI
  - agenticOS
---

# Why do we need a special Operating System for AI?

## Summary

Renen Hallak, founder and CEO of VAST Data, joins Ksenia on The Inference Show to discuss the emergence of what he calls an "AI Operating System"

## Highlights

### "Every single human endeavor will change drastically"

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uh8_RX-Ik1o?start=131&end=195" frameborder="0" allowfullscreen></iframe>

> "If we're looking 10 years into the future, there is not anything I can think of that will not need to change drastically. It's not just developers and lawyers and support assistants. It's going to be every single human endeavor. Art, science, physical endeavors, construction work, carpenters, they will all be augmented in a very serious way by these new technologies."
> — Renen Hallak, [2:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=131s)

### "Metadata is far more important than raw data"

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uh8_RX-Ik1o?start=423&end=490" frameborder="0" allowfullscreen></iframe>

> "Metadata is important a lot more than it used to be because historically we were analyzing numbers and we were putting those numbers in columns of a database and it was relatively easy to understand what's going on. And now we have all this unstructured data. It's fuzzy. We don't really know what to do with it. And so we need to give it meaning."
> — Renen Hallak, [7:03](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=423s)

### "First give agents the ability to build their own model of the universe"

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uh8_RX-Ik1o?start=785&end=860" frameborder="0" allowfullscreen></iframe>

> "First thing we need to do is give agents the ability to build their own model of the universe. They can't all be based on the last model from OpenAI or xAI. They need to fine-tune their own models as they progress based on data that they are exposed to. And then instead of having one AI, we will have a million AIs or 10 million AIs."
> — Renen Hallak, [13:05](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=785s)

### "It's the same with our kids - instill values, then trust them"

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uh8_RX-Ik1o?start=1043&end=1105" frameborder="0" allowfullscreen></iframe>

> "I think it's the same with our kids, right? We're not trying to control our kids. We're trying to raise them with certain values and then trust them that they have those values and that they will make good decisions based on those values that we instilled in them."
> — Renen Hallak, [17:47](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1067s)

### "Evolution on steroids - 800 billion computers, new generation every minute"

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uh8_RX-Ik1o?start=1506&end=1558" frameborder="0" allowfullscreen></iframe>

> "We can have instead of 8 billion computers, we can have 800 billion computers. And we can have a new generation spin up every minute, not every 20 years. It's evolution on steroids."
> — Renen Hallak, [25:37](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1537s) - a foundational infrastructure layer that connects data, compute, and policy for the agentic era. Hallak explains how VAST Data evolved from a storage company in 2016 to building a comprehensive operating system for AI workloads, driven by customer demands for increasingly sophisticated capabilities including databases, compute management, and agent orchestration.

The conversation explores the profound changes AI will bring over the next decade, with Hallak predicting that every human endeavor - from art to construction work - will be dramatically augmented by AI. He emphasizes that enterprises underestimate the magnitude of coming changes while overestimating how fast they will happen. The discussion delves into the critical importance of metadata over raw data, the need for systems that handle both structured and unstructured data like human memory, and why legacy infrastructure simply cannot support modern AI workloads.

Hallak articulates a compelling vision for achieving AGI: giving agents the ability to build their own models of the universe, enabling millions of AIs to communicate with each other, and connecting them to the physical world through robots. He draws an analogy between raising AI systems and raising children - instilling values rather than imposing rigid control - while emphasizing the importance of observability, security, and reproducibility in the AI operating system layer.

## Key Points

- **Enterprise AI Adoption** ([1:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=71s)) - Hundreds of enterprises are moving from sandbox environments and proofs of concept into production AI workloads with agents over the past year
- **Magnitude vs Speed Misconception** ([2:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=131s)) - Enterprises underestimate how drastically everything will change in 10 years while overestimating how fast changes will happen
- **Universal AI Augmentation** ([2:37](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=157s)) - AI will augment every human endeavor including art, science, construction work, and carpentry - not just knowledge workers
- **Neural Nets Paradigm Shift** ([4:17](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=257s)) - The breakthrough came not from algorithmic changes but from having massive amounts of data to feed training systems
- **Exabyte-Scale Systems** ([5:57](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=357s)) - Modern AI requires systems at exabyte scale feeding hundreds of thousands of parallel GPUs
- **Metadata Importance** ([7:03](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=423s)) - Metadata is now far more important than raw data because unstructured data needs meaning derived from understanding
- **Agents as Human Cognition** ([7:46](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=466s)) - Agents process experiences (unstructured), form thoughts (structured), and correlate memories over time - like human cognition
- **Global Distributed Systems** ([8:34](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=514s)) - Old systems were built locally; new AI infrastructure must be globally distributed across edge locations and devices
- **Exponential Ladder Metaphor** ([8:58](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=538s)) - Progress feels like walking up an exponential ladder where each step reveals how much more is required
- **Evolution from Storage to OS** ([9:13](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=553s)) - VAST evolved from storage system to database to data platform to full operating system based on customer needs
- **Late Start Advantage** ([11:31](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=691s)) - Starting in 2016 was "late" but allowed them to architect for AI from the ground up with new underlying technologies
- **AGI Definition** ([13:05](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=785s)) - AGI and superintelligence means computers that can think of new ideas, not just summarize and parrot back information
- **Multi-Agent Model Building** ([14:18](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=858s)) - Instead of one AI, we need millions of AIs that fine-tune their own models and communicate with each other
- **Data Access Policies** ([15:38](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=938s)) - OS must encode complex policies about which agents can see which data and what they can communicate to others
- **AI as Raising Children** ([17:47](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1067s)) - Like raising kids, AI should be instilled with values rather than rigidly controlled, then trusted to make good decisions
- **No 5-Year Plans** ([18:20](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1100s)) - VAST doesn't have 5-year plans; they experiment, learn what works, and update quarterly
- **Everything is New Challenge** ([19:21](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1161s)) - The entire stack is changing at once - from power plants to data centers to racks to applications
- **First Principles Thinking** ([23:36](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1416s)) - Asking "why not?" exposes false assumptions and reveals what is actually possible versus assumed impossible
- **Evolution on Steroids** ([25:44](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1544s)) - Computers can have 800 billion instances with new generations every minute instead of human 20-year generation cycles

## Mentions

### Companies
- **VAST Data** ([0:33](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=33s)) - Storage and AI infrastructure company founded in 2016, now building an AI operating system
- **OpenAI** ([14:26](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=866s)) - Referenced as provider of base models that agents shouldn't all rely on exclusively
- **xAI** ([14:26](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=866s)) - Referenced alongside OpenAI as provider of base models

### Products & Technologies
- **VAST Database** ([7:33](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=453s)) - VAST's proprietary database developed for AI workloads combining structured and unstructured data
- **GPUs** ([6:04](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=364s)) - Hundreds of thousands of parallel GPUs are being fed by exabyte-scale storage systems
- **DPUs** ([9:45](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=585s)) - Data Processing Units mentioned as part of new compute infrastructure
- **Neural Networks** ([3:51](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=231s)) - Previously thought not to work, now foundational to AI revolution
- **Transformer** ([3:18](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=198s)) - Paper came out in 2017, the year after VAST was founded
- **Siri** ([0:59](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=59s)) - Example of technology that seemed terrible initially but gradually improved
- **iPhone** ([0:59](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=59s)) - Platform where Siri was introduced
- **HPC Parallel File Systems** ([12:21](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=741s)) - Legacy technology being displaced by new AI-native storage

### People
- **Renen Hallak** ([0:30](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=30s)) - Co-founder and CEO of VAST Data, the interview subject
- **Ksenia** ([0:25](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=25s)) - Host of The Inference Show by Turing Post
- **Andrew Ng** ([6:50](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=410s)) - Referenced for saying "data is the new electricity" during big data era
- **Elon Musk** ([23:03](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1383s)) - Biography mentioned as recent reading, noted for first principles thinking
- **Leonardo da Vinci** ([23:07](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1387s)) - Biography mentioned as fascinating for understanding how innovative people think

## Surprising Quotes

> "If we're looking 10 years into the future, there is not anything I can think of that will not need to change drastically. It's not just developers and lawyers and support assistants. It's going to be every single human endeavor."
> — [2:20](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=140s)

> "We can have instead of 8 billion computers, we can have 800 billion computers. And we can have a new generation spin up every minute, not every 20 years. It's evolution on steroids."
> — [25:37](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1537s)

> "AI is the first one that can invent new things if it gets to a certain point. None of the previous revolutions - PC, mobile, internet - created better versions of themselves."
> — [17:23](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1043s)

> "I think it's the same with our kids, right? We're not trying to control our kids. We're trying to raise them with certain values and then trust them that they have those values and that they will make good decisions based on those values that we instilled in them."
> — [17:47](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1067s)

> "We don't have a 5-year plan. We barely know what's going to happen next year. We do have a one-year plan, but it gets updated every quarter as we learn more and as things change."
> — [18:32](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1112s)

## Transcript

[0:00](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=0s) It's evolution on steroids. There's always a lot more missing than there is built. First thing we need to do is give agents the ability to build their own model of the universe. It's going to be every single human endeavor.

[0:25](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=25s) Welcome to the inference show by Turing Post and today I'm joined by Renen Hallak the co-founder and CEO of VAST Data. Let's jump straight in. When will we shift from experimenting with AI models what we do now to living inside environments where thousands of agentic systems and agents act on our behalf?

[0:47](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=47s) I think it's already happening. You know, these shifts, we feel like they're very, very slow. And then suddenly, all at once, we realized that it happened. We have these moments. It happens with every technology. When Siri was introduced into the iPhone, it was terrible. It didn't understand anything we could say. We said, but then after a few years, suddenly it understands everything. And so, I think that shift is starting. It takes us a while to notice it.

[1:12](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=72s) But I can tell you over the last year, we've been involved in hundreds of projects within enterprises that are moving from sandbox environments and proofs of concepts into production workloads with their agents. And yeah, there's a few more steps to get to where you said, but it shouldn't take more than a few years.

[1:31](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=91s) How do their sandbox environments look like? It depends. Most of these places it's a silo over to the side with a few team members that are testing stuff out and trying to understand what works, what doesn't work. Try and get a feel for these new abilities so that then they can say okay this we feel is safe enough, low risk, adds a lot of value. Let's move that into production. And then one after the other they hop over into the production environment.

[1:58](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=118s) And what would you say because you have a lot of experience with enterprises. What is the biggest overestimation they have about AI systems and environments and what they underestimate?

[2:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=131s) I think they underestimate the magnitude of the difference that's going to happen here. I think they overestimate how fast it will happen. In my personal opinion, if we're looking 10 years into the future, there is not anything I can think of that will not need to change drastically. It's not just developers and lawyers and support assistants. It's going to be every single human endeavor. Art, science, physical endeavors, construction work, carpenters, they will all be augmented in a very serious way by these new technologies. It'll take a bit of time.

[2:46](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=166s) You say 10 years. I think 10 years, this is a very very different world than the one that we have today. All kinds of questions about what does money mean? What does the economy look like? What do people spend time on? I think we don't know. We don't have the answers to those questions. It was very easy 10 years ago to describe what the world would look like today. I think today it's very hard to answer that same question.

[3:10](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=190s) You think so? Well, it's actually interesting because you started the company in 2016, the year before Transformer paper came out. So I don't think it was that easy to imagine the world today and can you unfold the path that you went what was changing what you were solving at the beginning what was the contrarian bets that seemed crazy at the time and what were the pivots can you uncover this like turning points for me because it's actually like 10 years we're talking about.

[3:44](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=224s) It is 10 years and I think when I was at school there was a class off to the side that neural nets. And what we all knew about neural nets is that they don't work and that it's a waste of time. It was an interesting idea to have computers program themselves and work more like the human brain does. But then we all realized that we don't really know how the human brain works. And it would be silly for us to think that we could get these artificial brains to work before we understood it.

[4:12](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=252s) I think 10 years ago, it was already becoming clear that the opposite is true. That those old neural nets from 30 years prior were starting to show results. I remember sitting at home and watching a YouTube video of how they could recognize cats in pictures and that was something that nobody had any reason to think computers would be able to do. Computers were good with numbers. They were good with exact things. They were not good at understanding anything that was fuzzy. You needed humans for that.

[4:41](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=281s) And so I double clicked. I often go in these journeys of trying to understand what's changed and how does it work and what's the limiting factor and I realized that it was not very different from an algorithmic perspective versus what they taught us at school but it was very different in the sense that now we had a lot of data to feed into these training systems and when you have so much data and you have that much access to so much data you can start to see these very simplistic results and we know how the brain worked and yet we could get the computer to recognize a cat.

[5:17](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=317s) Maybe if we give it more access to more data, it can recognize a dog and maybe then it can recognize people and maybe then it could understand more and more things in the way that we understand them. And so that's why we started the company. We wanted to enable that. We wanted to see how far we could stretch it. Can we build a thinking machine or is it just sensory type activities that we know how to replicate? Yeah, we're still on that journey.

[5:41](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=341s) I don't know that we have the answer of can we build a thinking machine yet, but over that decade, we've realized a lot of things. That it's an even bigger problem than I expected it to be in terms of you need more access to more data by more computing power. We have systems that are exabytes in scale that are being fed into hundreds of thousands of very hungry parallel GPUs now. And I'm really really glad that we architected for those extreme levels of scale when we started because it's impossible to rearchitect once you choose a path.

[6:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=371s) Over the years, our customer base changed from early adopters in AI like hedge funds and life science institutes to generative AI companies and AI clouds and now to enterprises that are starting to adopt these new abilities. So every phase is different. Training is different than inference. Inference is different than inference at scale. That's different from agents. That's different from what we will have with fine-tuning and with physical robots. That's what keeps it interesting and exciting.

[6:42](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=402s) Have your understanding about data changed because if we remember those times that was big data times then Andrew Ng at some point said that you know data is new electricity but I believe data now it's changing because it's more it's less data-centric it's more context centric. Do you agree with that? What's your take?

[7:03](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=423s) Yes, metadata. I think metadata is important a lot more than it used to be because historically we were analyzing numbers and we were putting those numbers in columns of a database and it was relatively easy to understand what's going on. And now we have all this unstructured data. It's fuzzy. We don't really know what to do with it. And so we need to give it meaning and the way we give something meaning is by understanding it and putting that understanding in a database. It's not the same database that we had 20 years ago. That's why over the last few years we needed to develop our own database, the VAST database for these new workloads.

[7:37](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=457s) But it's that dichotomy of structured data on the one hand and unstructured data on the other hand that is really really interesting. If you think of these agents, then you start to use human terms. We have experiences as this unstructured stuff comes into our eyes and ears or into their cameras and microphones. And then you need to make sense of those experiences. And then you have thoughts and those are structured types of things. And then you remember those. You remember the experiences, the pictures and you remember the thoughts.

[8:03](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=483s) So those are memories and you go back in time and you cross-correlate between your memories and new experiences. So you need the ability to access information as it comes in as well as something that was there for 10 years both on the structured and the unstructured side. It introduces a lot of complexity.

[8:19](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=499s) It's like whole system. It's a new system. That's right. And you can't use the old stuff because it was not built for this. It wasn't built for the scale or for the performance or for the resilience that we need. It was built as a local thing within one location. We now need to build a global system that's distributed across edge locations and into the devices. Eventually, everything needs to be different up and down the technology stack to enable this new era.

[8:46](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=526s) Where are we in building the system? What is still missing? There's always a lot more missing than there is built, but that's because we keep understanding more about what is needed. I like to say we're walking up an exponential ladder. Every step is two times or three times higher than the previous step, but we're still just at the very very beginning because every step that we go up, we can see so much further into the future and we understand how much more is required.

[9:13](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=553s) VAST. We started with building a storage system because we thought we need fast access to a lot of data and we needed to break that trade-off between price and performance and scale and resilience and ease of use. And we built an architecture that breaks that fundamental computer science trade-off and then we built a storage solution on top of it. And our customers told us it's great but it's not enough. We need a new type of database. And so we added the VAST database to the VAST data store.

[9:39](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=579s) And then they said that's great but that's not enough. We need a new way of managing all of this compute. We have GPUs now and DPUs and we have training and inference and this one is urgent but that one is more important. This one needs to run close to where the people are. This one can run overnight. We need a way to manage all of this and it needs to be data driven. If that picture comes in, we need it to trigger the inference function that understands what's inside the picture. When we see whatever it may be a stoplight within the picture, we need to call another function that handles stoplights.

[10:13](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=613s) And so it became what started as a storage system very quickly became a data platform and it's now becoming the operating system, the full software infrastructure layer between new hardware and new agentic applications. And so what is missing? Everything that the agents need. Security, observability, reproducibility, ways to make things simpler to deploy for enterprises that aren't experts, ways to make things more compliant with regulation. Wherever you open a box, there's 100 more things that need to be done. Again, that's what makes it interesting.

[10:48](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=648s) But I think today we have the foundation, which is the architecture and the first few building blocks to get started with our customers. So you're building AI OS, AI operating system. And how do you see the competition field? It feels like there's a lot of data operations companies. How do you see this field evolving in terms of building new operation systems?

[11:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=671s) Yeah. So you mentioned big data before. I think big data is a good analogy. The difference between machine learning and deep learning. Machine learning was all about analyzing numbers and finding anomalies. Deep learning is everything in the world and so the same is true for our competition. We were very very lucky to start late. If we were to start even a year or two earlier, we would not have seen this deep learning revolution in front of our eyes. And also even if we were able to predict the future, we wouldn't have had the underlying technologies to architect in the way that we did.

[11:45](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=705s) And so starting in 2016 and taking those first 3 to four years to really build that minimum viable product enabled us to architect for this AI problem and to leverage the underlying technologies as they became available to build that architecture. Our competition started before that whether it's 5 years before that or 30 years before that. They did not have that advantage and so the systems they built were for the old world and they don't scale to the levels that are required today. They're not built for these new workloads and they're being displaced up and down the stack.

[12:21](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=741s) Again, if you look at storage, it's old enterprise systems and old HPC parallel file systems. If you look at database, it's old data warehouses. If you look at compute, it's old streaming services and orchestration frameworks. All of those need to be redone for this new era of AI. It's funny that you said that you started late because 2016 feels like ancient times.

[12:43](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=763s) It is late compared to our competition. I think it's very early with respect to this new AI wave.

[12:51](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=771s) When you're talking about this AI operating system is it like a scaffolding for AI? Is it part of this narrative of building AGI? How do you think about it? And what's your definition of AGI?

[13:05](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=785s) As I understand AGI and the next step beyond AGI, which is super intelligence, it's thinking machines, computers that can no longer just parrot back information that we feed into them, summarizing it, making it very accessible, understanding it in a way, but computers that can think of new ideas. And I think we're not there yet. And we have a few steps that we need to get to in order to get there.

[13:31](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=811s) When I think of what is missing in order for us to get there, well, I look at us. How do we think of new ideas? Usually, it's not a really smart person sitting in the ivory tower and thinking. It's through interaction. And each of us has a slightly different model of the universe based on our experiences. And then we talk to each other and we misunderstand each other and a new idea forms. And then we start to analyze that idea and see where it takes us.

[13:56](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=836s) The other thing that we have is ability to test things. So if I'm a scientist, I can go and drop an apple and I can measure how fast is that apple going or I can look in a telescope and see stars that are very far away and run experiments and see how the natural world interacts with those experiments.

[14:13](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=853s) And so I think we need to give AI all of those abilities that I just said. First thing we need to do is give agents the ability to build their own model of the universe. They can't all be based on the last model from OpenAI or xAI. They need to fine-tune their own models as they progress based on data that they are exposed to. And then instead of having one AI, we will have a million AIs or 10 million AIs.

[14:38](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=878s) The next thing we need to do is allow them to talk to each other. And so operating system is important for both of those things - building this inference fine-tuning loop, the data pipeline, and providing a mechanism that is persistent, that is queryable, that is observable for us humans to know what these AI agents are talking about, but to give them the ability to interact with each other and then give them access to the natural world through physical robots, whether they're cars or drones or humanoid robots. Give them the sensors that we have, give them the ability to interact with nature.

[15:14](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=914s) And I think those steps will get us closer and closer to thinking machines. But to do that, we need a software infrastructure layer to enable it. Those drones and humanoid robots as they expose themselves to more information, we need a way to monitor that and a way to control that and a way to tell them this you're allowed to do, this you're not allowed to do. Here you're allowed to go to, over there you're not.

[15:38](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=938s) We need a way to tell these agents, you're allowed to see this piece of data, but not that piece of data. This data you can see because you're my agent and this is my data. But I don't want you to communicate it to a stranger because it's none of their business. This data both of these agents can see, but they're not allowed to know that the other one is allowed to see it and so they're not allowed to talk about it. All of this needs to be coded somewhere into policies that allow us to control the information, that allow us to observe what's going on, that allow us to reproduce and answer questions like why did that agent give that response to this question last month?

[16:16](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=976s) All of that needs to be baked into an operating system such that the agent developers can focus on building their applications and not on the infrastructure.

[16:24](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=984s) I feel like this is exactly the place where P-doomers and technical people can meet and argue because if you work in trenches you understand this is like very precise work of guardrails and putting control into it but on the other side from what you describe it's like building this huge huge system where it's easy to lose control. I don't believe in P-doom, I'm deep into technical understanding of that. But how would you talk to people who don't see this technicality of that?

[16:59](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1019s) I think with every new technology comes the potential for good and the potential for evil. And I think with this technology it's more because this I believe is a bigger change than what we've had in the past. We've had the PC revolution, we've had the mobile revolution, we've had the internet revolution. None of those inventions created better versions of themselves. AI is the first one that can invent new things if it gets to a certain point. And that's powerful.

[17:28](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1048s) On the one hand, we have a lot of questions that we don't know the answer to. How to better create energy, how to solve disease. And if we can get a machine to think and to exponentially get better at it, it can help us solve those hard problems. But on the other hand, it can get out of hand and we can lose control over it.

[17:47](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1067s) And I think it's the same with our kids, right? We're not trying to control our kids. We're trying to raise them with certain values and then trust them that they have those values and that they will make good decisions based on those values that we instilled in them. And I think that that is the way I would think about this revolution as well. We need controls in place to observe to make sure that mistakes aren't being made, but we should also give them some space for interesting things to happen.

[18:15](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1095s) With such an incredible speed of development, how far ahead do you plan?

[18:20](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1100s) We don't plan far ahead at all. I was just in a conversation with an investor, a potential investor, someone who hasn't invested in us yet this morning, and they asked for a 5-year plan, and I said, "We don't have a 5-year plan. We barely know what's going to happen next year. We do have a one-year plan, but it gets updated every quarter as we learn more and as things change. And it's very, very, very hard to forecast. It's very hard to predict."

[18:49](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1129s) I don't try to forecast and predict anymore. Our process is a simple one. We experiment. We try things. We try to understand what works and then we do that. And we hopefully tell others within the company, we found something that works here. You should try it too. You should do that. Or we found something that doesn't work. Don't waste your time on trying this. And it's a very iterative approach and it's a very simple process, but it's the best one we found.

[19:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1151s) If you can rank what are the biggest challenges in the current situation for you building this operation system, power, data movement, governance. Can you rank it for me?

[19:21](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1161s) The biggest challenge is that everything is new. The entire stack is different. And so if you look at power plants, they get built in a different way. Now, if you look at data centers, they get built in a different way. If you look at the racks, they get filled up with different pieces of equipment. If you look at the applications on top of us, they're being written in a very different way. And so, everything is changing all at once and we need to make sure that we are at the forefront of all of it so that we don't lose relevance. That is challenging.

[19:51](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1191s) The other challenge is that everything is growing extremely fast and so we need to be responsive to our customers growth needs on the one hand and not break the company as we try and grow so quickly on the other. Every 3 months, 6 months, it's a completely different company because of this new level of scale that we need to contend with. That's challenging. Yeah, it's not easy. None of what we do is easy, but I think it's extremely interesting and it's a lot of fun. It's the most exciting time and exciting place I feel to operate in. Definitely since I was born, maybe since a lot before then.

[20:29](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1229s) Yeah, it's crazy and fascinating times. What concerns you the most about these times and what excites you the most apart from that being so crazy?

[20:39](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1239s) I think what concerns me, I can answer that in terms of macro or micro. I tend to look at things in a very tactical way. And so every morning that I wake up, there are 50 things waiting on my phone that concern me. Different things that aren't working in the company, different fires that need fighting. Again, as we grow at this pace, there's always something that needs fixing and that needs improving and that needs to be done anew. And so that concerns me every morning that I wake up and then hopefully by the time I go to sleep, that list is taken care of. But I know there will be a new list the next day. And so I'm always concerned about a lot of things.

[21:17](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1277s) I think from a macro perspective, we need to make sure that we make the best of this new technology and this new ability, we need to make sure that it doesn't accidentally fall into the wrong hands and that it doesn't get misused. And I don't know the answers there, but I think having these conversations and making sure that we keep one step ahead of it is very very important.

[21:38](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1298s) And what excites you the most? What excites me the most? The possibilities. I think every day, every week, we find that computers can do things that we didn't think they were able to and that they couldn't do before. And again, technology, it happens in S-curves. And I don't know if we're on the beginning of the S going up or if we're starting to plateau and we will need some new ideas in order to get to the places that we all hope to get to.

[22:05](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1325s) But in both of those cases, it's really exciting. If we need new ideas, maybe AI will be able to help us find those ideas. And if we're just at the beginning of that ascent, then it's extremely exciting to see what it will look like a year from now and 2 years from now and 3 years from now. And we at VAST are extremely fortunate to be working with the smartest people in the world that are building the application layer of these new technologies and they're building the hardware layer of these new technologies and so it's all very exciting.

[22:32](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1352s) Thank you. My last question is always about books. What book has influenced you the most? And it can be a recent one or the one from your forming years.

[22:42](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1362s) That's a hard question because recently I don't have time to read as much as I would like. I need to work 7 days a week as this opportunity presents itself and we don't want to miss out and we don't want to screw it up. I've been reading some biographies lately. I read the Elon Musk biography and I read the Leonardo da Vinci biography and I read a bunch of others. I find those fascinating because you learn how people think and how they approach things.

[23:09](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1389s) Earlier in my career, I used to read a lot of business books because I don't have a business education. I learned computer science but in a position where I need to build a company and so I tried to read as much as I can about that so I don't make stupid mistakes only smart mistakes. Those are the types of books that I read most often.

[23:29](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1409s) I noticed that both you and Elon Musk talk a lot about first principles, thinking from the first principles. How does that help you?

[23:36](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1416s) It allows us to understand what is possible and what is not possible and then we can try and do the things that are possible whereas most people just assume that almost everything is impossible. When I was at school, I studied math and it was very theoretical. It was proving things. And when you try to prove something, you're not sure what the answer is. Are you going to prove that it can be done or that it cannot be done? But in both cases, you learn something and then you understand, you stretch the understanding of nature, assuming you consider math to be nature.

[24:11](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1451s) And it's the same with everything else. If it's physically possible by the laws of physics, then we should try and do it. And if it's not, then we should prove that it isn't. And when you think of things in that way, you end up asking a lot of why questions. Somebody says, "Well, we can't do that." And then you ask them, "Why not?" And they say, "Because of this." And you realize that no, that's not true. They're making an assumption somewhere that maybe isn't the correct assumption to make.

[24:36](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1476s) And so you peel it back until you get to those first principles. And then you get an understanding of, "Yeah, this really can't be done or we haven't proven that it can't be done, so we should try and do it and then when you try and do it usually it doesn't succeed because these are hard things but once in a while you stumble onto something that you can do and nobody did it before."

[24:55](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1495s) This is one of the biggest augmenting powers of LLMs this endless amount of questions you can ask and really go deep to the main thing to the roots.

[25:06](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1506s) Yes. Because they're starting to reason now and they don't have the same limitations that we have. If you look at the human race, how many people are there? And how many of those people will come up with a new idea, something that nobody ever thought about before? Out of those people, they're likely going to come up with one new idea and then write books about it and give lectures about it. And then you need to wait another 20 years until there's a new generation for another new idea. And it's a very slow process of advancing humanity.

[25:35](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1535s) Computers can accelerate that. We can have instead of 8 billion computers, we can have 800 billion computers. And we can have a new generation spin up every minute, not every 20 years. It's evolution on steroids.

[25:46](https://www.youtube.com/watch?v=Uh8_RX-Ik1o&t=1546s) That's super fascinating. Thank you so much. It was a pleasure talking to you. It was my pleasure. Thank you for having me.
