---
video_id: 5DQ3yab_9ys
title: "What's That About SORA (That Veo3 and Google Missed)"
channel: Turing Post
duration: 779
duration_formatted: "12:59"
view_count: 537
upload_date: 2025-10-13
url: https://www.youtube.com/watch?v=5DQ3yab_9ys
thumbnail: https://i.ytimg.com/vi_webp/5DQ3yab_9ys/maxresdefault.webp
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Neural Networks
  - AI Breakthroughs
  - Technology and Society
  - AI in Real Life
  - Turing Post
  - AI Revolution
  - AI Trends
  - Thought Provoking AI
  - Innovators in AI
  - Sora
  - OpenAI
  - VideoGeneration
  - PhysicalAI
  - AINews
  - Azeem Azhar
  - Google
---

# What's That About SORA (That Veo3 and Google Missed)

## Summary

This video analyzes OpenAI's Sora 2 video generation model, arguing that it represents far more than just a video creation tool - it's a sophisticated human-in-the-loop training ecosystem disguised as a social app. The host explains how Sora 2 combines the interface accessibility of ChatGPT with the social engagement of TikTok, creating what she calls a "freaking genius" approach to video generation that competitors like Google's Veo 3 completely missed.

The video explores three key strategic pillars of Sora 2 for OpenAI: identity and provenance through its cameo system that captures user likeness under consent, a creator funnel that merges creation/publication/metrics in one loop for future monetization, and most importantly, training signals for world models where every user interaction teaches the system about physical AI - how things move, interact, and behave in the real world. The host emphasizes that while Veo 3 may be technically superior as a model, Google missed the crucial point of social interaction and data collection.

The analysis draws on insights from Azeem Azhar of Exponential View, who notes that OpenAI is betting on building a creator economy without relying on YouTube or TikTok - potentially owning generation, distribution, and monetization layers. While acknowledging risks around copyright, privacy, and potential misuse for misinformation, the host encourages viewers to engage with the tool to understand its capabilities rather than fear it.

## Highlights

### "ChatGPT + TikTok - That was freaking genius"

[![Clip](https://img.youtube.com/vi/5DQ3yab_9ys/hqdefault.jpg)](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=72s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*1:12-2:00" "https://www.youtube.com/watch?v=5DQ3yab_9ys" --force-keyframes-at-cuts --merge-output-format mp4 -o "5DQ3yab_9ys-1m12s.mp4"
```
</details>

> "We also saw recently when Veo 3 by Google was launched. It was quite mind-blowing but also bulky to use. And the OpenAI team came up with an idea to marry ChatGPT and TikTok. That was freaking genius."
> — Host, [1:31](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=91s)

### "Your data is in the system"

[![Clip](https://img.youtube.com/vi/5DQ3yab_9ys/hqdefault.jpg)](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=142s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*2:22-3:20" "https://www.youtube.com/watch?v=5DQ3yab_9ys" --force-keyframes-at-cuts --merge-output-format mp4 -o "5DQ3yab_9ys-2m22s.mp4"
```
</details>

> "If you want to create a Sora video for yourself, you need to record a super short clip. First, you read three digits from the screen that captures both your voice and your mimics. Then, you turn your head left. Then, you turn your head right or up and down, depends what the system tells you. And that's it. Your data is in the system."
> — Host, [2:22](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=142s)

### "Just do the same prompt again"

[![Clip](https://img.youtube.com/vi/5DQ3yab_9ys/hqdefault.jpg)](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=275s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*4:35-5:20" "https://www.youtube.com/watch?v=5DQ3yab_9ys" --force-keyframes-at-cuts --merge-output-format mp4 -o "5DQ3yab_9ys-4m35s.mp4"
```
</details>

> "What I noticed, and it's kind of almost stupid, is that if for the first time when you prompt it, it says it violates our rules or blah blah blah, you just do it again. You just do the same prompt again and then you receive a video."
> — Host, [4:35](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=275s)

### "Will YouTube need Sora more than Sora needs YouTube?"

[![Clip](https://img.youtube.com/vi/5DQ3yab_9ys/hqdefault.jpg)](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=593s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*9:53-10:45" "https://www.youtube.com/watch?v=5DQ3yab_9ys" --force-keyframes-at-cuts --merge-output-format mp4 -o "5DQ3yab_9ys-9m53s.mp4"
```
</details>

> "OpenAI are betting that they can build a creator economy without relying on YouTube, TikTok or others. They could own the generation layer, distribution layer, and eventually a monetization channel. Will YouTube need Sora more than Sora needs YouTube? If OpenAI can crack retention and monetization, they own both the supply and demand side, that's a different game than being a model provider."
> — Azeem Azhar, [10:11](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=611s)

### "Veo 3 completely missed the point"

[![Clip](https://img.youtube.com/vi/5DQ3yab_9ys/hqdefault.jpg)](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=701s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*11:41-12:30" "https://www.youtube.com/watch?v=5DQ3yab_9ys" --force-keyframes-at-cuts --merge-output-format mp4 -o "5DQ3yab_9ys-11m41s.mp4"
```
</details>

> "Sad to say, though Veo 3 by Google can be superior as a model, it completely missed the point of social interaction. Let's remember OpenAI created just in a few days a social network and a massive training playground."
> — Host, [11:41](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=701s)

## Key Points

- **Sora's History and Turbo Release** ([0:13](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=13s)) - First Sora appeared February 2024 as research preview with the famous "Walking Woman in Tokyo" demo; Sora Turbo released December 2024 for ChatGPT Pro users but physics weren't there and hype had died

- **ChatGPT + TikTok Formula** ([1:31](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=91s)) - OpenAI team asked what made ChatGPT successful (friendly interface) and married that concept with TikTok's social features, creating a genius combination for video generation

- **Sora 2 Launch Success** ([1:37](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=97s)) - Launched September 2025, still #1 in App Store by mid-October; got over 1 million downloads in less than 5 days

- **Physical AI Data Collection** ([2:01](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=121s)) - Sora 2 serves as massive data collection for physical AI training - models that understand movement, contact, and cause/effect in the real world

- **User Onboarding as Data Capture** ([2:22](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=142s)) - Users must record short clips reading digits, turning head left/right - capturing voice, mimics, and movements that feed into OpenAI's data

- **Crowdsourced Physical AI Training** ([2:44](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=164s)) - Millions upload real videos of themselves, then create synthetic variations (different hairstyles, clothes), providing both real and synthetic training data

- **Current Limitations and Ratings** ([3:59](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=239s)) - App has 2.8 rating; users love it but say it's buggy; main problems are guardrails and copyright infringement concerns

- **Guardrail Weakness** ([4:35](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=275s)) - Noted that if a prompt is rejected for violating rules, often just resubmitting the same prompt works - a significant safety gap

- **Italian Language Test** ([4:55](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=295s)) - Host created video of herself speaking Italian to test on mother-in-law; fooled casual acquaintances but grammar mistakes made it seem more authentic

- **Music and Lyrics Generation** ([5:40](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=340s)) - Sora generates phenomenal lyrics and music on the fly; will eventually consolidate avatar, voice, and music tools that previously required stitching multiple services together

- **Cameo Feature** ([6:24](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=384s)) - Can create videos with friends or celebrities who allow it; Sam Altman gave himself as a cameo option, appearing more relaxed and human in AI-generated videos

- **Remixing Feature** ([7:52](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=472s)) - One of the best features - users can take any video's prompt and add their own spin, creating endless creative iterations

- **Three Strategic Pillars for OpenAI** ([7:59](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=479s)) - Identity/provenance (consent-based likeness capture), creator funnel (unified creation/publication/monetization), and training signals for world models

- **Azeem Azhar's Analysis** ([9:53](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=593s)) - OpenAI betting they can build creator economy without YouTube/TikTok, potentially owning generation, distribution, and monetization - a different game than being just a model provider

- **Scale Difference from ChatGPT** ([10:44](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=644s)) - With ChatGPT it was text/images, with Sora it's videos and synthetic data - millions of short prompts each teaching the system about human imagination of movement and sound

- **Veo 3 Missed the Point** ([11:41](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=701s)) - Though Veo 3 may be superior as a model, Google completely missed the social interaction element; OpenAI created a social network and training playground in days

- **Detection Patterns Emerging** ([11:13](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=673s)) - After weeks of use, patterns become recognizable - voice speed variations, depth changes - but first-time viewers can still be fooled

## Mentions

### Companies

- **OpenAI** ([0:13](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=13s)) - Creator of Sora and Sora 2, central focus of video discussing their strategic moves
- **Google** ([1:21](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=81s)) - Creator of Veo 3, criticized for missing the social interaction element despite having a potentially superior model
- **Meta/Threads** ([3:50](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=230s)) - Referenced as comparison for hype that didn't sustain user engagement
- **YouTube** ([9:53](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=593s)) - Mentioned in context of OpenAI potentially bypassing traditional distribution platforms
- **TikTok** ([1:33](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=93s)) - Key inspiration for Sora's social network features
- **Midjourney** ([1:12](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=72s)) - Referenced as previous AI tool that was fun but limited by Discord interface

### Products & Technologies

- **Sora 2** ([0:10](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=10s)) - Main subject; OpenAI's video generation model launched September 2025 with social features
- **Sora Turbo** ([0:41](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=41s)) - Previous version released December 2024 for ChatGPT Pro users
- **Veo 3** ([1:21](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=81s)) - Google's video generation model, described as potentially superior technically but missing social elements
- **ChatGPT** ([0:57](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=57s)) - Referenced as model for accessible AI interfaces
- **Physical AI** ([2:01](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=121s)) - AI models that understand movement, contact, and cause/effect in real world
- **World Models** ([9:36](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=576s)) - AI models being trained through Sora user interactions to understand real-world physics
- **Cynthia** ([5:54](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=354s)) - Avatar creation tool that Sora may replace
- **ElevenLabs** ([5:56](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=356s)) - Music/voice tool referenced as previously needed for avatar creation

### People

- **Sam Altman** ([6:42](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=402s)) - OpenAI CEO who gave himself as a cameo option; described as appearing more relaxed and human in AI-generated content
- **Azeem Azhar** ([9:53](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=593s)) - Founder of Exponential View newsletter, quoted extensively on OpenAI's strategy to own generation, distribution, and monetization layers
- **Cassinia** ([12:47](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=767s)) - Host's avatar character promoting Turing Post newsletter

## Surprising Quotes

> "The OpenAI team came up with an idea to marry ChatGPT and TikTok. That was freaking genius."
> — [1:31](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=91s)

> "If for the first time when you prompt it, it says it violates our rules or blah blah blah, you just do it again. You just do the same prompt again and then you receive a video."
> — [4:35](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=275s)

> "Will YouTube need Sora more than Sora needs YouTube? If OpenAI can crack retention and monetization, they own both the supply and demand side - that's a different game than being a model provider."
> — [10:11](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=611s)

> "Sad to say, though Veo 3 by Google can be superior as a model, it completely missed the point of social interaction."
> — [11:41](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=701s)

> "It's so important to play with it to understand how it works and the potential of it... that will prevent you from fear and not knowing what you are looking at."
> — [11:31](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=691s)

## Transcript

[0:00](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=0s) Am I real or not? It's kind of hard to tell in this new world. Welcome to Attention Span. Today we will discuss Sora.

[0:13](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=13s) That wasn't the first time OpenAI released a realistic video generation model. The first version appeared in February 2024 as a research preview. If you remember, Walking Woman in Japanese like city and the physics of it blew everyone's mind. But not that many people could try it. So while the hype was hot, everyone talked about Sora for a couple of days and then it died out.

[0:39](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=39s) Even though by December 2024, OpenAI released Sora Turbo for ChatGPT Pro users, but the physics were not there and it was already behind the hype. So the excitement died out as did the usage. The OpenAI team working on Sora 2 asked themselves what was so cool about ChatGPT and of course it's an interface - for the first time anyone could use a generative model in a friendly way. That was with ChatGPT, so why not use the same idea with video generation model.

[1:12](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=72s) I mean in the beginning Midjourney was also fun to use but it was in Discord and it was limiting how many people could use it. We also saw recently when Veo 3 by Google was launched. It was quite mind-blowing but also bulky to use. And the OpenAI team came up with an idea to marry ChatGPT and TikTok. That was freaking genius.

[1:37](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=97s) In September 2025, Sora 2 blew everyone's minds and I waited - I decided to wait a couple of weeks to see how this hype and how this excitement unfolds. Here we are in the middle of October. Sora is still number one in App Store. But there are few important things that we need to understand about Sora 2, what it is for OpenAI and if it can survive the hype.

[2:01](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=121s) One of the things why Sora 2 is so important is that it tapped into OpenAI's data collection for physical AI purposes. And we know how extremely hard the data collection for physical AI is. And by physical AI, I mean models that understand movement, contact, and cause and effect in the real world. So, let's see how it works.

[2:22](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=142s) If you want to create a Sora video for yourself, you need to record a super short clip. First, you read three digits from the screen that captures both your voice and your mimics. Then, you turn your head left. Then, you turn your head right or up and down, depends what the system tells you. And that's it. Your data is in the system.

[2:44](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=164s) So imagine how many millions of people uploaded their videos with themselves, real themselves to OpenAI and then people like to change what they uploaded. They want to have different hairstyle, different clothes. So more and more and more data, real data goes into OpenAI and then people create videos. This is sort of synthetic data that OpenAI receives from Sora. It's an outstanding crowdsourcing of data for physical AI. Just mind-blowing how well they executed that part.

[3:20](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=200s) Sora 2 runs on two interfaces. It's still an invite only iOS app and web interface for ChatGPT Pro users. And though it is by invite, you can easily get an invitation on Twitter from one of OpenAI team. So of course in less than 5 days Sora got more than 1 million downloads and the executives of Sora say that it's faster than ChatGPT. Well of course ChatGPT came from zero and Sora came from 800 million users of ChatGPT.

[3:50](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=230s) We saw the same thing with Threads and we know that Threads didn't live up to the hype. Not that many people use Threads as it was in the beginning. So we see about Sora the ratings are not extremely good. It's 2.8. And the main thing is that people actually love it. It's just that they say it's buggy. It has the potential.

[4:08](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=248s) And the main problem is of course guardrails and the infringement of copyright that might actually blow OpenAI's idea up because the amount of creation of different animation, video games using actors is mind-blowing. And even if OpenAI puts limitations, people often find a way to go around it.

[4:35](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=275s) What I noticed, and it's kind of almost stupid, is that if for the first time when you prompt it, it says it violates our rules or blah blah blah, you just do it again. You just do the same prompt again and then you receive a video. What I wanted to talk about is actually what are the unusual ways to use it and why Sora might stick.

[4:55](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=295s) I tried it on my parents-in-law. My mother-in-law is from Italy. She speaks Italian. So, I asked Sora to create a video where I speak Italian. I sent it into the group chat. And for me and my husband, it was obvious it wasn't me. But for people who know me, but maybe not that well, it fooled them.

[5:19](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=319s) And there was some doubt if it's me or if I'm really speaking Italian. But it was funny that my mother-in-law noticed a grammar mistake in the Italian that I was speaking. And because of that, she thought it could actually be me. It's interesting that the shorter the prompt, the better the result, at least in my experience.

[5:40](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=340s) And what is absolutely phenomenal is the lyrics and music Sora generates on the fly. And here comes the next big moment that is not fully realized yet. If before to create your own avatar, you had to stitch together a few tools like Cynthia for avatar, ElevenLabs for music, etc. With Sora, you'll soon be able to do it all in one place.

[6:01](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=361s) As always with models and prompts, no matter video or text, if it gets you from the first prompt, that's phenomenal. But if it doesn't, and in 99% it doesn't, then you need to do a lot of work to align and adjust to make it work for you. So many videos failed. So many videos look unrealistic completely. When it hits the point, it's crazy.

[6:24](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=384s) Another thing about Sora, you can use cameos. For the first time, you can actually create videos with your friends or even with some celebrities who allowed to do that. And I think it was very brave of Sam to give himself away for the Sora Bonanza. Maybe it is probably the first time when we can see Sam Altman that relaxed. It kind of makes him a little more human even if it is completely AI.

[6:48](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=408s) "Yes, that's me running AI from the back. Can't stop. Head above water. Flush that tune. Everybody bouncing Sam in the room."

[6:55](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=415s) You can also use Sora for any time of experiments or visualizations. If you have an idea for how to visualize a story, a poem, if you want to see how an educational material can look like in different video styles, that's super helpful. I think people will pay a lot being able to create realistic videos for the time that they need because now 10, 15 seconds, it's just too short, of course.

[7:24](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=444s) And also here comes the TikTok part because you have all these people who you can follow and who see your videos and can like and follow you. It's like a regular social network and it's very addictive because the imagination of people is just mind-blowing. You keep scrolling because there's a bear on a bicycle or there is a like live recording from police.

[7:52](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=472s) One of the best things that Sora came up with is remixing. If you like a video, you can use the same prompt and add something that makes it yours. Super fun actually. So now the most important part. What is this for OpenAI? Why is Sora 2 so important?

[8:09](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=489s) Sora 2 extends OpenAI reach in three directions. Identity and provenance. The cameo system captures user likeness and voice under consent. That's important. And each upload becomes part of controlled identity graph. OpenAI's right holder controls opt-ins and granular restrictions position it as a trusted ledger for digital identity. That's the idea at least.

[8:33](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=513s) Of course, as OpenAI usually does, they're failing on the right way to do restrictions and copyright, but who knows? They always find a way to deal with that. And again while they are dealing with copyright they are amassing a huge amount of data for physical AI training.

[8:55](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=535s) Creator funnel number two - the app merges creation, publication, and metrics in one loop. Future monetization can rely on compute tiers, pro subscriptions, and API access for studios. Also, I'm pretty sure, as I said, people and advertisement agencies and Hollywood studios will pay a lot of money to use it as a constant iteration tool or imagination tool or whatnot. It's just so much easier.

[9:23](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=563s) And again, OpenAI gains direct feedback on what captures attention and what fails. A data stream competitors cannot usually copy. It's a big thing. Number three, again training signal for world models. Every bounce, stumble, and lighting error refines the model's internal physics.

[9:42](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=582s) At some point, OpenAI will introduce "what's wrong about the video" so people can comment and then that will be also a feedback. Sora becomes a controlled playground for training reasoning about real world dynamics.

[9:53](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=593s) Another important thing was that Azeem Azhar from the Exponential View noticed. He said, "OpenAI are betting that they can build a creator economy without relying on YouTube, TikTok or others. They could own the generation layer, distribution layer, and eventually a monetization channel. Will YouTube need Sora more than Sora needs YouTube? If OpenAI can crack retention and monetization, they own both the supply and demand side, that's a different game than being a model provider."

[10:23](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=623s) And I completely agree with that. And of course the company accepts the risk that legal and privacy frameworks may lag behind its experiments. They're fighting. They've been fighting. They are fighting now and they will be fighting with all those complaints and legal issues. But meanwhile a lot of data going that way.

[10:44](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=644s) The difference this time is scale. With ChatGPT text, images - with Sora its videos. It's synthetic data. It's physical AI. The training of their world models. Millions of short prompts. Each one teaching the system something about how people imagine movement and sound. Sound of Sora 2 is amazing.

[11:08](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=668s) "Hear the hush before in the pine where the night moves on."

[11:13](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=673s) Of course, now after a couple of weeks already, you can recognize the pattern of creation. Sometimes the voice is too fast and the depth of the voice is different. But again, if it's the first time and if you don't know how it looks, it will fool you. We just need to be aware of it.

[11:31](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=691s) The tool is here. It's so important to play with it. It's so important to play with it to understand how it works and the potential of it. And sad to say, though Veo 3 by Google can be superior as a model, it completely missed the point of social interaction.

[11:49](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=709s) Let's remember OpenAI created just in a few days a social network and a massive training playground. They made it the way that other companies missed. They created the social interaction, this loop of humans watching other humans creating AI and you can interact with it and you can use it adding on top layer after layer.

[12:10](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=730s) People will ask if it's dangerous and yes there is a lot to use from fake news and misinformation but the tool is here. This new social network is here. What you need to do, you need to play with it and understand how it works and that will prevent you from fear and not knowing what are you looking at.

[12:32](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=752s) And of course, it's on OpenAI and other companies to create guardrails and watermarks and whatnot to be able for people to distinguish if it's real or not. Subscribe and share with your friends. It goes a long way. Thank you. I am real by the way. I am.

[12:47](https://www.youtube.com/watch?v=5DQ3yab_9ys&t=767s) Hey explorers, it's Cassinia. Out here in the bricks, I've uncovered a different kind of treasure. My newsletter, the Turing Post.
