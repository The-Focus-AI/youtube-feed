---
video_id: bb4FHFpokkY
title: "When Will Inference Feel Like Electricity? Lin Qiao, co-founder & CEO of Fireworks AI"
channel: Turing Post
duration: 1551
duration_formatted: "25:51"
view_count: 907
upload_date: 2025-08-22
url: https://www.youtube.com/watch?v=bb4FHFpokkY
thumbnail: https://i.ytimg.com/vi/bb4FHFpokkY/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Neural Networks
  - AI Breakthroughs
  - Technology and Society
  - AI in Real Life
  - Turing Post
  - AI Revolution
  - AI Trends
  - Thought Provoking AI
  - Innovators in AI
  - AI Interviews
  - AI Pioneers
  - GPT and LLMs
  - AI Explained
  - Human vs Machine
  - AI for Good
  - AI Startups
  - Lin Qiao
  - Fireworks AI
---

# When Will Inference Feel Like Electricity? Lin Qiao, co-founder & CEO of Fireworks AI

## Summary

Lin Qiao, co-founder and CEO of Fireworks AI and former head of PyTorch at Meta, discusses the future of AI inference infrastructure and why making it affordable and reliable is crucial for the industry. She explains the fundamental challenge facing GenAI application developers: achieving product-market fit can be the beginning of bankruptcy because GPU infrastructure costs are orders of magnitude higher than traditional CPU-based applications. Lin uses the iceberg metaphor to illustrate how most potential applications remain submerged underwater due to high infrastructure costs.

The interview explores Fireworks AI's unique approach to inference optimization through their "3D optimizer" that simultaneously optimizes for quality, speed, and cost. Unlike one-size-fits-all solutions, Fireworks treats every application workload differently, similar to how database query optimizers work. Lin discusses the convergence of open and closed models, the rise of Chinese AI labs like DeepSeek and Qwen, and why 2025 is the year of AI agents across coding, hiring, SRE, customer service, and marketing domains.

Lin also shares her personal leadership journey, revealing how she overcame self-doubt through the support of people who challenged her and pushed her beyond her comfort zone. She emphasizes that the inner voice telling you "maybe other people are better at doing those things" is often the real limitation, not external factors.

## Key Points

- **Product-Market Fit Paradox** ([1:58](https://www.youtube.com/watch?v=bb4FHFpokkY&t=118s)) - In GenAI, hitting product-market fit can be the beginning of bankruptcy because GPU infrastructure costs are orders of magnitude higher than traditional applications
- **The Iceberg Metaphor** ([3:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=185s)) - Most AI applications are submerged underwater because infrastructure costs are too high; if costs shrink 10x, enormous applications will emerge above the waterline
- **Data Alignment Problem** ([3:49](https://www.youtube.com/watch?v=bb4FHFpokkY&t=229s)) - The fundamental root cause of accuracy and latency gaps is the misalignment between training data distributions and production application data
- **Inference-First Strategy** ([6:32](https://www.youtube.com/watch?v=bb4FHFpokkY&t=392s)) - Fireworks chose inference over training in September 2022 because inference scales with world population while training scales only with researchers
- **One Size Fits One** ([8:08](https://www.youtube.com/watch?v=bb4FHFpokkY&t=488s)) - Fireworks rejects one-size-fits-all API approaches, treating every application workload differently through automatic optimization
- **3D Optimizer** ([8:51](https://www.youtube.com/watch?v=bb4FHFpokkY&t=531s)) - Fireworks' three-dimensional optimization simultaneously optimizes quality, speed, and cost across 100,000+ possible combinations
- **2025: Year of Agents** ([9:59](https://www.youtube.com/watch?v=bb4FHFpokkY&t=599s)) - Explosive growth in AI agents across coding, hiring, SRE, customer service, and marketing domains
- **Enterprise Customer Service Scale** ([10:47](https://www.youtube.com/watch?v=bb4FHFpokkY&t=647s)) - Some enterprises have more than 20,000 human agents in customer service, making AI automation a huge cost-saving opportunity
- **Open Model Philosophy** ([11:37](https://www.youtube.com/watch?v=bb4FHFpokkY&t=697s)) - Fireworks focuses on open models for enterprise transparency and control, while remaining objective about closed model performance
- **Chinese Models Innovation** ([13:08](https://www.youtube.com/watch?v=bb4FHFpokkY&t=788s)) - DeepSeek R1, Qwen 3, and GLM are setting new precedents despite resource constraints because they lack powerful GPUs but innovate anyway
- **Model Convergence** ([13:44](https://www.youtube.com/watch?v=bb4FHFpokkY&t=824s)) - Base models are converging because no one has absolute secret sauce in training techniques or data; talent and data labeling are flattening
- **Training-Inference Alignment** ([15:13](https://www.youtube.com/watch?v=bb4FHFpokkY&t=913s)) - Model providers are increasingly thinking about inference time during training, leading to architectural innovations
- **Multimodal Gap** ([16:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=965s)) - Closed models are still ahead of open models in multimodal capabilities; open models focus more on text, reasoning, and coding
- **Meta's Open Source Debate** ([17:27](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1047s)) - There are continuous internal discussions at Meta about whether to push product-first or ecosystem consolidation on Llama
- **Virtuous Data Cycle** ([19:36](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1176s)) - Better models drive better products, which drive more user engagement, which generates more data, which drives even better models
- **100x Efficiency Target** ([20:43](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1243s)) - The industry should see 100 times more efficient AI infrastructure; Fireworks already demonstrates 4-10x improvements
- **GPU Evolution Like CPU** ([21:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1281s)) - AI hardware will follow the CPU journey from single-core to multi-core with dramatic price-performance improvements
- **Operating Principles** ([23:00](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1380s)) - Fireworks' two fundamental operating principles are customer-first and high-velocity operation
- **Inner Voice as Limitation** ([24:31](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1471s)) - Lin's personal growth came from overcoming the inner voice that said "maybe other people are better at doing those things"

## Mentions

### Companies
- **Fireworks AI** ([0:34](https://www.youtube.com/watch?v=bb4FHFpokkY&t=34s)) - Lin Qiao's company focused on inference infrastructure, founded October 2022
- **Meta** ([0:36](https://www.youtube.com/watch?v=bb4FHFpokkY&t=36s)) - Lin's former employer where she led PyTorch and AI infrastructure for 7-10 years
- **DeepSeek** ([13:11](https://www.youtube.com/watch?v=bb4FHFpokkY&t=791s)) - Chinese AI lab mentioned for R1 model setting new precedents
- **Zhipu AI (Z AI)** ([13:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=801s)) - Chinese AI company behind GLM models, obsessed about AGI through open source
- **Google** ([17:57](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1077s)) - Mentioned as driving open models from the US side

### Products & Technologies
- **PyTorch** ([0:36](https://www.youtube.com/watch?v=bb4FHFpokkY&t=36s)) - Deep learning framework Lin led at Meta, used for both training and inference
- **3D Optimizer** ([8:51](https://www.youtube.com/watch?v=bb4FHFpokkY&t=531s)) - Fireworks' three-dimensional optimization technology for quality, speed, and cost
- **DeepSeek R1** ([13:11](https://www.youtube.com/watch?v=bb4FHFpokkY&t=791s)) - Chinese open model setting new precedents
- **Kimi K2** ([13:17](https://www.youtube.com/watch?v=bb4FHFpokkY&t=797s)) - Chinese model mentioned as innovative
- **Qwen 3** ([13:17](https://www.youtube.com/watch?v=bb4FHFpokkY&t=797s)) - Chinese open model from Alibaba setting new benchmarks
- **GLM** ([13:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=801s)) - Open model from Zhipu AI
- **Llama** ([17:47](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1067s)) - Meta's open model family, subject of internal ecosystem consolidation discussions

### People
- **Lin Qiao** ([0:31](https://www.youtube.com/watch?v=bb4FHFpokkY&t=31s)) - Co-founder and CEO of Fireworks AI, former head of PyTorch at Meta
- **Ksenia Se** ([0:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=21s)) - Host of the Inference interview series on Turing Post
- **Mark Zuckerberg** ([17:19](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1039s)) - Meta CEO, mentioned regarding their statement about potentially not open-sourcing everything

## Surprising Quotes

> "Having a product market fit is the beginning of going to bankruptcy."
> — [2:58](https://www.youtube.com/watch?v=bb4FHFpokkY&t=178s)

> "We actually don't believe in one size fits all. We believe in one size fits one and every application is different."
> — [8:16](https://www.youtube.com/watch?v=bb4FHFpokkY&t=496s)

> "So does anyone has absolute secret sauce? Probably not."
> — [14:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=845s)

> "The industry should see 100 times more efficient in AI infrastructure."
> — [21:01](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1261s)

> "Find the people who really challenge you and make you uncomfortable is a blessing... don't be afraid of failure. Once you get to the other end of this tunnel you'll be a different person."
> — [25:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1521s)

## Transcript

[0:00](https://www.youtube.com/watch?v=bb4FHFpokkY&t=0s) What would it take for inference to feel like electricity? Inference scales fundamentally differently. So we actually don't believe in one size fits all. So does anyone has absolute secret sauce? Probably not.

[0:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=21s) Hello everyone and welcome back to Inference the interview series on Turing Post and today I'm thrilled to talk to Lin Qiao. She is the co-founder and CEO of Fireworks AI and the former head of PyTorch at Meta where she led the rebuild of Meta's entire AI infrastructure stack. Welcome Lin. Thanks for having me.

[0:44](https://www.youtube.com/watch?v=bb4FHFpokkY&t=44s) Let's start with the big question. When will inference become a solved problem? Like what would it take for inference to feel like electricity reliable, cheap and invisible? And what still stands in the way? That's an interesting question. I think we are just at the starting point of optimizing inference and there are many different dimensions to look at. I want to probably look at from the eyes of app developers. Those are the cohort we care the most about.

[1:14](https://www.youtube.com/watch?v=bb4FHFpokkY&t=74s) There's no question that GenAI is a revolutionary technology. It's able to generate content closest or beating humans interaction with the real world, right? So that's kind of the biggest value. Because of that, I think it's inevitable. It's pretty safe to predict there will be many generational companies able to define new user experience that never existed before, building on top of this technology. They are going to disrupt the industry and how we interact with software with applications day-to-day.

[1:45](https://www.youtube.com/watch?v=bb4FHFpokkY&t=105s) Through that lens I think we already see a lot of innovation that is happening in the field but one interesting phenomenon that's happening is before we talk about product market fit right so if you hit the product market fit then you just scale right so that's kind of a well understood runbook if you hit product market fit then you're going to have a viable business. In GenAI for applications built on top of AI, hitting product market fit and having a viable business are two separate problems.

[2:13](https://www.youtube.com/watch?v=bb4FHFpokkY&t=133s) It's very interesting because you can build a new user experience having a lot of value to the end users whether they're consumers or developers but it doesn't mean you can quickly scale to a viable business because your operation cost is going to be so much higher. Everything around the GPU infrastructure, GPUs are orders of magnitude higher than traditional applications built on top of CPU.

[2:37](https://www.youtube.com/watch?v=bb4FHFpokkY&t=157s) So we often hear stories that companies talking to us, they are like hey we're very confident about our product. A lot of great signals. We're about to launch it. We have a waiting list of millions of users waiting. We couldn't open up the floodgate because we know if we open up, we're going to run out of money. In another way, having a product market fit is the beginning of going to bankruptcy. So, isn't that interesting? That's very interesting. Yeah. It's a new thing.

[3:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=185s) It's a new thing and that's fundamental because you can visualize this, right? The new application is like the iceberg, right? It's a very big iceberg that is being built right now, being created right now. But right now, most of the iceberg is submerged under the water line because infrastructure cost is very high. And if you imagine the cost starts to shrink down to 10 times lower, then the amount of applications that will emerge above the water line is going to be enormous, right? That's where the future is going to be.

[3:33](https://www.youtube.com/watch?v=bb4FHFpokkY&t=213s) But when it comes to how will the infrastructure cost shrink down, there are so many different approaches and we would love to talk about our opinion, our observation, especially working with the leading application providers. What is your approach to making this iceberg smaller?

[3:49](https://www.youtube.com/watch?v=bb4FHFpokkY&t=229s) So fundamentally it boils down to the fundamental misalignment or disparity of two sets of data. One set of data are the data being used to train a foundation model in a research lab. It doesn't matter whether it's closed model, open model, doesn't matter. For the research lab training foundation model, they will have a team defining the objective of what are the most important areas the model will be very good at and based on that curate a lot of data related to the problem statement. So that's the data distribution they will control and manage and feed into the model and if the outcome is what they want to see. So that is one on one side.

[4:30](https://www.youtube.com/watch?v=bb4FHFpokkY&t=270s) On the other side there are so many application developers, their goal is to align their product design to user engagement. Right? Their goal is to maximize user engagement from their product design. So they're constantly experimenting the product features and design to drive those product metrics based on the product data they see. I would say the product data coming from the product is another data distribution.

[4:55](https://www.youtube.com/watch?v=bb4FHFpokkY&t=295s) And with these two data distributions as you can see it's built for different purposes by different companies by different groups of people. By design those are not aligned and now you're putting them together. The app developers when they build product they're going to use those models and these models will power the product and this misalignment is the fundamental root cause of accuracy gap, of latency gap.

[5:20](https://www.youtube.com/watch?v=bb4FHFpokkY&t=320s) We have seen many great companies, despite they're new, they're young, they figure out how to create this alignment themselves. They are able to control their destiny to have a better model for themselves, faster model and also cost-efficient model for them to scale viable business after product market fit. So this is the kind of fundamental observation we have across the industry. That is the missing part that a few small set of people are able to figure out now but much more people are staying at the space where they think about model API as a utility. They just send their request to the model even though there's a big misalignment that exists. That's kind of an interesting dynamic space we observe right now and we are trying to help our application developers to be able to close the alignment gap.

[6:09](https://www.youtube.com/watch?v=bb4FHFpokkY&t=369s) So you're working with enterprises to align these two data columns, right? Can you just tell me a little more about your journey to that? Because you founded Fireworks in October 2022 before ChatGPT. So why did you start it then and how your vision changed and your approaches changed when generative AI really boomed?

[6:32](https://www.youtube.com/watch?v=bb4FHFpokkY&t=392s) Yeah, so I would say the founding team, we have a very big founding team, seven of us. We have been working at Meta between 7 to 10 years, pretty much bootstrapped the AI infrastructure across both training and inference at Meta. When we started we had the option to do both because PyTorch has been used on both sides, or pick training or pick inference. And at that time, this is September 2022, most people on training, they're either training a model themselves or selling GPU for training or building some kind of training infrastructure.

[7:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=425s) We have decided to go all in on inference. We only like to do inference. We have experience on both sides because we believe inference scales fundamentally differently. It scales with the number of consumers or developers where world population is the upper bound. Training scales with a very small talent pool of researchers. So we feel like the inference TAM is way bigger. It also has high production requirements and complexity goes with it and those are the problems we love to add value to.

[7:38](https://www.youtube.com/watch?v=bb4FHFpokkY&t=458s) So that's kind of the initial focus and the strategic decision we made. If you look back feels like we were against the trend. People at that time would say we care about inference, there's... people are still early and so on. But I think thanks to that decision we made, we made the investment early and we have built a very sophisticated tool chain for us to be the best provider on the infra side.

[8:02](https://www.youtube.com/watch?v=bb4FHFpokkY&t=482s) The idea goes back to the data alignment problem I mentioned. So our infra stack is not one size fits all. You don't use our inference stack as hey this is just another API. No matter what is the workload shape and pattern it's the same. So we actually don't believe in one size fits all. We believe in one size fits one and every application is different.

[8:25](https://www.youtube.com/watch?v=bb4FHFpokkY&t=505s) In some sense, this idea is not new. It exists in many other compute spaces. For example, databases, right? A database will take a query and then optimize it underneath through a query optimizer to find the most efficient plan, right? So, a database is not one size fits all. Every query is treated differently. So similar idea here is we treat every application workload differently but the optimization happens automatically.

[8:51](https://www.youtube.com/watch?v=bb4FHFpokkY&t=531s) We call it three-dimensional optimization, 3D optimizer. So three dimensions are quality, speed and cost. We optimize across all three dimensions at the same time. So in that sense it's a much more complicated problem than a database query optimizer. And the bad news is the search space is big because there are a lot of underlying components we need to optimize for. Each component has lots of options to pick and choose from and those options stack on top of each other leading to hundreds of thousands of combinations. So we are picking one needle from these 100,000 haystacks. So that makes the problem very complicated. But the good news is we're very good at solving those kinds of problems and almost all customers onboarded to Fireworks are using our 3D optimizer today.

[9:39](https://www.youtube.com/watch?v=bb4FHFpokkY&t=579s) It's probably very hard to explain that to enterprises on such a multi-layered level. Yeah. So this is more like what's happening under the hood. But when we talk with enterprises, we will map it to their business values, right? And the use cases.

[9:55](https://www.youtube.com/watch?v=bb4FHFpokkY&t=595s) Right now we have seen a wide variety of very interesting use cases. Especially 2025 is the year of agents. It's amazing how fast this industry moves. The space is across startups and enterprises. They're all building some form and shape of agents, right? All the way from coding agents, various different kinds of coding agents, vibe coding or non-vibe coding, to significantly increase productivity.

[10:24](https://www.youtube.com/watch?v=bb4FHFpokkY&t=624s) There are hiring agents where given a job profile, they automatically source talents and even conduct interviews for you and assess performance. There are SRE agents and those production engineers that can help you debug and triage issues during incidents. There are customer service agents, very popular one because all large enterprises have customer service. Some enterprises even have more than 20,000 human agents in customer service. To make them productive is a huge cost saving for those enterprises.

[10:58](https://www.youtube.com/watch?v=bb4FHFpokkY&t=658s) There are marketing agents. So given your marketing campaign, automatically generate outbound with a very specific target audience. And we also see vibrant adoption from the medical space, from retail space, from education space, from finance space across the board. So usually when we talk with those enterprises we will talk about case studies and impact from this 3D optimizer and that lands much better than talking about technical terms.

[11:26](https://www.youtube.com/watch?v=bb4FHFpokkY&t=686s) How do you talk to them about models? What is your approach? I know it's not one size fits all but is it a general model? Is it a small model but it's much more narrow?

[11:37](https://www.youtube.com/watch?v=bb4FHFpokkY&t=697s) Yeah obviously we believe in open development, in open. So our business model mainly focuses on open models because it provides transparency and full control that enterprises can have and they do care about that a lot. But at the same time we also want to look at the problem from our users' eyes, right? So their goal is not to make open model successful. That's not their goal. Their goal is to solve today's problems and land big business impact and they will use whatever tool it takes to make sure they'll be successful.

[12:09](https://www.youtube.com/watch?v=bb4FHFpokkY&t=729s) So during enterprise engagement we have a cookbook for them to build their AI gateway where they will connect with whatever model provider they would like to and we will be one of the providers and we help them standardize that stack. We also have a set of evaluation, our private evaluation benchmarks, for them to assess different use cases, which model is the best. And there we are very objective. If a closed model wins, then we will just give them the report and then they can pick and choose from. And for the cases that they want to tune open models to drive the best quality, we also give them tools to do that.

[12:49](https://www.youtube.com/watch?v=bb4FHFpokkY&t=769s) So we often come to where we meet them where the needs are. That's kind of our fundamental operating principle. We do not want them to bend themselves to think about how to use a vendor. We want to go to where they are.

[13:05](https://www.youtube.com/watch?v=bb4FHFpokkY&t=785s) Well, talking about open models, Chinese models are completely crushing it lately. And why do you think DeepSeek R1 and the latest Kimi K2 and Qwen 3 and GLM from Z AI, why do they set new precedents for all model providers, open and closed? What is so special about them?

[13:28](https://www.youtube.com/watch?v=bb4FHFpokkY&t=808s) Yeah I would say this is very interesting, right? So because they're more resource constrained, they don't have the powerful GPUs as we have here but that doesn't prevent them. It doesn't stop them. And this is a bunch of things, right? Overall I think there's a sign that the models are converging overall. It doesn't matter if it's closed or open model because at the end there are two things, right?

[13:52](https://www.youtube.com/watch?v=bb4FHFpokkY&t=832s) One is training techniques. You have secret sauce that goes back to talent. I think talent is kind of flattening as in people move around and there's a lot of information sharing. So does anyone have absolute secret sauce? Probably not. And then the second is data, right? So as I mentioned, the data distribution determines the model quality at the end. And amount of data is converging from publicly available data you can crawl or from labeling companies where they can provide additional labeled data to increase quality.

[14:23](https://www.youtube.com/watch?v=bb4FHFpokkY&t=863s) My understanding is all the labs are using more or less similar kinds of labeling companies. That part is going to flatten out. And then it's about how you generate more data, right? And people generate synthetic data. People train the largest model in order to go small. The largest model can generate synthetic data to train the smaller model, right? So then the synthetic data generation is going to be capital heavy. There's also specific kinds of tools or approaches to generate good high quality synthetic data. I feel that probably no one has unique advantage in the long run. Those are kind of various different factors.

[15:02](https://www.youtube.com/watch?v=bb4FHFpokkY&t=902s) But at the same time, people are also being more and more creative. When they train, they don't just think about training time quality. They are also thinking about inference time together at the same time. So cross training and inference alignment becomes a focus. And that's where various different model providers, especially recent models, we see a lot of innovation, creativity because they are doing experiments in order to make the inference time go fast. What are the new model component tweaks they can implement? And they did implement that. It shows up as very effective.

[15:36](https://www.youtube.com/watch?v=bb4FHFpokkY&t=936s) I would expect to continue to see a lot of tweaks, model architecture at a small level, not kind of major level, to make the model quality and speed and cost much more optimized continuously from various different providers. But overall my prediction is the overall space of the base model is convergent.

[15:58](https://www.youtube.com/watch?v=bb4FHFpokkY&t=958s) If we only look at one modality, right? So one modality is text-based. Another dimension is hey what about multimodal? I think multimodal, the closed model is still ahead of open model by a good margin. That's the investment in data and the focus. I think the open model providers are more laser focused on the text-based, the logical reasoning model, the coding capability, the tool calling capability for agent development and so on. But less on voice, vision, video. There's some effort there but less of a focus compared with LLM. So we'll see the convergence on LLM to go much faster and then other modalities will catch up.

[16:37](https://www.youtube.com/watch?v=bb4FHFpokkY&t=997s) Yeah, I'm pretty sure they'll catch up. It's probably just much more expensive and there is more commercial use in multimodal. So for the closed companies, it makes much more sense to protect their invention. But I agree with you, they're going to catch up pretty soon.

[16:53](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1013s) So we were talking about these Chinese models and they've been super innovative and they are open. It feels like they benefit from that. Z AI, which is now Z AI, they've been obsessed about AGI. So for them it's apparently their way to achieve AGI through open source. If we talk about the US companies like your ex-employer Meta, they recently published this statement about super intelligence where Mark Zuckerberg says they might not open source everything. They will think more carefully. Why such difference here? How do you think about it?

[17:27](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1047s) I think on the Meta side we are yet to be seen, right? So I don't think that's a final call but I can understand there's continuous internal discussion which is healthy about where to focus. Right? So whether pushing the product first to drive the business top line or pushing the ecosystem to drive consolidation on Llama models. Right? So those are just business decisions. I would expect continuous discussion within Meta.

[17:54](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1074s) At the same time I think Google has been driving open models and I think I heard other providers are also driving open models from the US. So I would say very excited about that. They do care about the open model community and want to contribute. The interesting part of contributing to the open model community is the bar is not low. You release a model not because it's easy. Because today whoever launches a new open model, they have to show benchmarks across the board compared with closed models as well and the latest open model which is already a very high bar.

[18:31](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1111s) It will push the open model to become better and better because no one is willing to lower the bar. If you lower the bar, no one cares anyways. It's a waste. So I remain very excited to see what's yet to come. It's kind of a demonstration of showing the depth of the research and showing the talent density and an output from a particular company. It's good for their reputation. It's also good for the broader community.

[18:59](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1139s) If we talk more about super intelligence and AGI, what's your take on it? Is it like solving intelligence or is it more about building better tools? Or you just do not think about it?

[19:10](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1150s) We have a strong opinion where Fireworks provides value. Obviously different companies will have different positioning. Where we want to provide value is we want to make application developers shine. We want to provide the best tools, a tooling infrastructure for them to build on top of where they can easily create a data flywheel from their production data and drive the last mile data alignment with the model.

[19:36](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1176s) So the model becomes better tuned towards their application. The product becomes better because of a better model and drives better user engagement. More user engagement drives more data. More data drives a better model. And this is a virtuous cycle we want them to create and that's where we are very passionate about building and delivering to the hands of application developers.

[19:55](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1195s) So that's our strong opinion. We add value as tools, as infrastructure, and we want to enable them to create the best social value that will show up in our day-to-day. That my family, my mom will be using it and say oh this is really cool. And I will be able to say hey actually they use Fireworks. And actually I can already say that to many of the newer applications and I want to be able to enable way more.

[20:25](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1225s) When do you... What's your prospects on when AI infrastructure will be much easier, much lighter?

[20:30](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1230s) I think we have already demonstrated that capability that through our 3D optimizer we can significantly accelerate speed and reduce cost and sometimes without sacrificing quality or even improving quality. The order of magnitude of improvement can be between four times to more than 10 times better. So that's the power we have demonstrated. We plan to continue to maximize that and continue down this journey.

[21:01](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1261s) But I think the industry should see 100 times more efficient AI infrastructure. Yeah that future is definitely coming. Obviously we are adding a lot of value in that layer but I also believe the fundamental infrastructure, the fundamental hardware, underlying hardware and everything will be much more efficient over time.

[21:21](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1281s) That's where we see the CPU journey. The CPU itself from single core to dual core, quad core, and with newer generations the price performance became significantly better. And with massive adoption the manufacturing cost gets much better and everything around that becomes much more efficient operationally. CPU not GPU. We have seen that in the CPU era. So right now I think we should see that in the current space of AI hardware, on GPU, other hardware accelerators, ASICs across the board.

[21:53](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1313s) Your approach is very pragmatic and you're building this AI world. What excites you and what concerns you the most about the world you're building?

[22:02](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1322s) What excites us, being very consistent from the beginning of our journey, is this is an extremely fast-moving and dynamic market and we firmly believe we are providing a generational new technology that will shift the industry. And we are in this huge wave, a huge tidal wave of industrial shift, probably even much bigger than the previous wave of cloud first, of mobile first.

[22:30](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1350s) Most likely we day-to-day, we wake up, we go to sleep and wake up immediately thinking about how to solve problems, what is the strategy. That's kind of very energetic and it peaks our intellectual curiosity and creativity. So the whole team is very energetic around that.

[22:50](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1370s) What keeps us up at night is how to strike a balance because we tend to go really fast. Our company's operating principle one is customer first. I talked about that. And the second is high velocity operation. So these two are the fundamental operating principles and everything else derives from that.

[23:10](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1390s) On the move fast side there's a flip side of move fast tends to break things. And how to manage that because we do provide high quality infrastructure and we're proud of ourselves for doing that and maintaining a good balance between continuing to move really fast but infrastructure is highly stable and reliable. Our customers are pushing hard for us to strike a good balance. Those are the interesting challenges we're seeing.

[23:34](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1414s) And we want to also be building infrastructure so we can scale very quickly, scale our fleet very quickly, scale our product features very quickly, scale very different customizations very quickly. So there are different levels of velocity and speed we are adding or compounding on top of the base layers all the time. So those are the kind of interesting problems we like to solve. It is a very complex infrastructure problem but we are very good at solving those and that also keeps us up at night all the time.

[24:00](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1440s) Thank you so much. My last question will be what is a book or idea that shaped the way you think about your leadership or the future? But basically what is the book that shaped you?

[24:12](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1452s) I probably cannot pinpoint one book. It's more like the life experience that shaped me. The interaction with many people that I have learned from and the journey, the internal journey I work with myself to think differently, that has shaped who I am today.

[24:29](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1469s) You know, 7-10 years ago I'm a complete different person. I had a lot of passion to do things but it's more like myself telling myself, hey maybe other people are better at doing those things, not you. And it took me multiple years to take that inner voice out. That's a very interesting journey to work with because it's not like I put myself in a challenging position to grow. It's other people who pushed me and forced me to embrace that I can accomplish and gave me a different level of imagination.

[25:00](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1500s) This is a very unique journey I've experienced. I would say I really highly appreciate it. It also gave me a lot of firsthand insight to share with other people. Whenever I see that their inner voice is actually the limitation, not anything else. That's kind of the interesting part of my personal journey.

[25:18](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1518s) So your book is the people around you. Definitely. And find the people who really challenge you and make you uncomfortable is a blessing. And go through the pain of embracing those challenges with the possibility you may fail. And don't be afraid. Once you get to the other end of this tunnel you'll be a different person.

[25:40](https://www.youtube.com/watch?v=bb4FHFpokkY&t=1540s) That's very inspirational. Thank you so much for this interview. Thank you for having me.
