---
video_id: SQVGjnV-ikM
title: "We Entered an Era Where No One Knows What Comes Next"
channel: Turing Post
duration: 535
duration_formatted: "8:55"
view_count: 200
upload_date: 2026-02-02
url: https://www.youtube.com/watch?v=SQVGjnV-ikM
thumbnail: https://i.ytimg.com/vi/SQVGjnV-ikM/maxresdefault.jpg
tags:
  - Singularity
  - AI
  - ElonMusk
  - RayKurzweil
  - JohnVonNeumann
  - AttentionSpan
  - TechHistory
  - AIProgress
  - ComputerChronicles
  - AIFuture
  - TuringPost
---

# We Entered an Era Where No One Knows What Comes Next

## Summary

In this thoughtful episode of Attention Span, Turing Post explores the concept of the singularity by examining how AI predictions have changed from 1984 to today. Starting with a fascinating clip from the Computer Chronicles where Nils Nilson correctly predicted that natural language conversation with computers would be the next major frontier, the host reflects on how back then, progress felt linear with clear bottlenecks to solve.

Today's AI landscape is fundamentally different. When asked what comes after large language models, there is no single answer - it could be agents, robotics, multimodality, world models, or all of these simultaneously. Progress no longer feels sequential but layered and interconnected. This observation connects to why Elon Musk and others are increasingly using the word "singularity" - not because machines are becoming sentient, but because our ability to predict what comes next has essentially collapsed.

The episode traces the concept back to John von Neumann's original 1958 definition (via Stanislaw Ulam): the singularity as a point where acceleration makes familiar ways of understanding stop working - a "limit of explanation" rather than autonomous machines. The host concludes that whether or not 2026 is technically "the singularity," we have clearly entered a period where our ability to narrate the future has weakened, even as our ability to build new systems keeps improving.

## Highlights

### "Progress felt linear enough to narrate. Even uncertainty had structure."

<iframe width="560" height="315" src="https://www.youtube.com/embed/SQVGjnV-ikM?start=130&end=175" frameborder="0" allowfullscreen></iframe>

> "Progress felt linear enough to narrate. Even uncertainty had structure. And that's what made me thinking about how different things feel now. If I ask you today what comes next after large language models, there is no single answer."
> — Turing Post, [2:10](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=130s)

### "The singularity is not a machine. It's a limit of explanation."

<iframe width="560" height="315" src="https://www.youtube.com/embed/SQVGjnV-ikM?start=249&end=290" frameborder="0" allowfullscreen></iframe>

> "Acceleration reaching a point where familiar ways of understanding stop working. In the original sense, the singularity is not a machine. It's a limit of explanation."
> — Turing Post, [4:09](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=249s)

### "The future stopped being easy to describe even without dates"

<iframe width="560" height="315" src="https://www.youtube.com/embed/SQVGjnV-ikM?start=382&end=430" frameborder="0" allowfullscreen></iframe>

> "When someone says that 2026 is the year of the singularity, I think it's not about machines becoming sentient and us becoming united with machines. It's becoming closer to that original von Neumann intuition that the pace and structure of change no longer fit the way we're used to talking about progress."
> — Turing Post, [6:22](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=382s)

### "We don't have an exact bottleneck anymore"

<iframe width="560" height="315" src="https://www.youtube.com/embed/SQVGjnV-ikM?start=337&end=380" frameborder="0" allowfullscreen></iframe>

> "Today there is no single bottleneck like that. Do we need compute for pre-training? Do we need compute for mid-training? Or do we need compute for post-training? And where is the most thing to uncover and discover and explore? Everywhere. We don't have an exact bottleneck."
> — Turing Post, [5:37](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=337s)

## Key Points

- **1984 AI Prediction** ([0:47](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=47s)) - Nils Nilson on Computer Chronicles correctly predicted natural language conversation as the next AI frontier, even though the timeline was decades longer than expected
- **Linear Progress Era** ([2:10](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=130s)) - In the symbolic AI era, progress felt linear with clear bottlenecks, making the next step predictable even without knowing timelines
- **No Single Frontier Today** ([2:16](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=137s)) - After LLMs, there's no consensus on what comes next - could be agents, memory, robotics, multimodality, world models, or all simultaneously
- **Musk's Singularity Claims** ([2:51](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=171s)) - Elon Musk has repeatedly said we're on the "event horizon" of singularity and that 2026 is the year it arrives
- **Von Neumann's Original Definition** ([3:24](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=204s)) - Stanislaw Ulam's 1958 tribute to von Neumann described singularity as a point where "human affairs as we know them could not continue" - not about autonomous AI
- **Singularity as Limit of Explanation** ([4:20](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=260s)) - The original meaning was about acceleration reaching a point where familiar ways of understanding stop working
- **Kurzweil's Version** ([4:46](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=267s)) - Ray Kurzweil's definition focuses on AI improving itself autonomously and human ability to predict outcomes collapsing
- **Human Still in the Loop** ([4:46](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=289s)) - Current AI systems still depend on human decisions - data curation, hardware, energy, capital, institutions
- **Multi-Layer Progress** ([5:19](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=319s)) - Progress now happens across many layers at once: models improve, tools change, costs drop, institutions react
- **Prediction Collapse** ([6:17](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=377s)) - The future has become almost impossible to narrate, hard to see beyond a few months
- **2025-2026 as Marker** ([7:16](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=448s)) - The host speculates that end of 2025 and 2026 may be the dates we'll later attach to when the singularity period began

## Mentions

### People
- **Nils Nilson** ([0:55](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=55s)) - Director of AI center at SRI International in 1984, correctly predicted natural language as next frontier
- **John McCarthy** ([0:26](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=26s)) - Guest on 1984 Computer Chronicles discussing AI capabilities
- **Elon Musk** ([2:51](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=171s)) - Repeatedly states singularity is near and 2026 is the year
- **John von Neumann** ([3:24](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=204s)) - Original source of singularity concept as described by Stanislaw Ulam
- **Stanislaw Ulam** ([3:34](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=214s)) - Mathematician who wrote about von Neumann's singularity concept in 1958
- **Ray Kurzweil** ([4:24](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=264s)) - Author of "The Singularity is Near," popularized modern definition

### Companies & Technologies
- **Computer Chronicles** ([0:08](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=8s)) - 1984 TV show episode about AI referenced throughout
- **SRI International** ([1:00](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=60s)) - AI research center where Nils Nilson was director
- **LLMs (Large Language Models)** ([2:21](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=141s)) - The current AI paradigm with no clear single successor

### Concepts
- **Singularity** ([2:53](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=173s)) - Central concept explored - both von Neumann's original and Kurzweil's modern definitions
- **Symbolic AI** ([1:34](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=94s)) - The dominant AI paradigm in 1984 when predictions felt more linear
- **Deep Learning** ([1:41](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=101s)) - Not yet practical in 1984 when symbolic AI dominated

## Surprising Quotes

> "If I ask you today what comes next after large language models, there is no single answer. Sometimes it's agents. Is it memory? Is it robotics? Is it multimodality? Is it world models? Is it better infrastructure? Economics, regulation or all of it at once."
> — [2:21](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=141s)

> "Von Neumann was not talking about artificial intelligence becoming autonomous. He was not predicting machines redesigning themselves. The phrase can be interpreted in different ways, but at its core, it seems to describe something simpler. Acceleration reaching a point where familiar ways of understanding stop working."
> — [3:56](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=236s)

> "I don't have an answer to the question, is 2026 the year of singularity? But I'm pretty sure we entered a period where our ability to predict, to clearly say what comes next has weakened, almost disappeared. Even though our ability to build new systems keeps improving."
> — [6:56](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=416s)

> "It becomes almost impossible to see beyond a few months."
> — [6:16](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=376s)

## Transcript

[0:00](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=0s) Recently, my friend Raymond Petite, hi Raymond, sent me a link to an old video to an episode of the Computer Chronicles. It's from 1984, the year that I was born. And this episode is about artificial intelligence. I expected it to feel dated, to have some sort of a nostalgia about the good old days.

[0:22](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=22s) Of course, they were discussing chess playing machine. There was a guest John McCarthy and that was very interesting to see him in the time when artificial intelligence was in the time of hype. "Well, I see no limit short of human intelligence and then with faster machines one could do the equivalent that a human could do in a short time in a very long time."

[0:47](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=47s) But then there was a moment that really caught my attention. When Nils Nilson was the director of the AI center at SRI International, when he was asked about the future of AI, his answer was very clear. "Another very important application is computer programs that are able to converse with humans in English everyday ordinary language and that's going to make computers accessible to a much wider variety of people."

[1:22](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=82s) So the timeline was wrong. It took decades longer than many people expected when we reach natural language conversations with machines. But the prediction itself was absolutely right. What makes this especially striking is the context. There was the symbolic era of AI. Deep learning was not on anyone's mind yet at least not in any practical sense. Compute was limited. Data was limited. The dominant paradigm was rule-based systems and explicit knowledge representation.

[1:54](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=114s) And still he could name what came next. He was not guessing. It was not an assumption. It was how he made this prediction. There was a sense that progress had a direction that there was a bottleneck. That natural language was hard but clearly the next thing to solve. In other words, progress felt linear enough to narrate. Even uncertainty had structure.

[2:16](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=136s) And that's what made me thinking about how different things feel now. If I ask you today what comes next after large language models, there is no single answer. Sometimes it's agents. Is it memory? Is it robotics? Is it multimodality? Is it world models? Is it better infrastructure? Economics, regulation or all of it at once.

[2:37](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=157s) Natural language is no longer a frontier. It's the interface, but there is no single replacement frontier that everyone agrees on. Progress doesn't feel sequential anymore. It feels layered, interconnected, hard to summarize in one sentence.

[2:51](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=171s) And that's where the word singularity starts showing up more often. If you look on Elon Musk's Twitter, you can see that he repeatedly says that singularity is near, that we are on its event horizon. And most recently, he said that 2026 is the year of singularity.

[3:11](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=191s) Every time I hear it, every time I discuss it with my husband because he also thinks that we are in the beginning of singularity, I pause and it's not because I disagree or agree specifically, it's that I'm trying to understand what exactly do they mean. So I try to unpack it.

[3:27](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=207s) To do that, it helps to go back even further before AI as we know it today existed. In 1958, Stanislaw Ulam reflecting in conversations with John von Neumann wrote about accelerating technological progress and changes in the mode of human life giving the appearance of approaching a kind of singularity in human history beyond which human affairs as we know them could not continue.

[3:54](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=234s) That sentence is often quoted, but it's also easy to misunderstand. Von Neumann was not talking about artificial intelligence becoming autonomous. He was not predicting machines redesigning themselves. The phrase can be interpreted in different ways, but at its core, it seems to describe something simpler. Acceleration reaching a point where familiar ways of understanding stop working.

[4:16](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=256s) In the original sense, the singularity is not a machine. It's a limit of explanation. Decades later, the term takes on more specific meaning, especially through Ray Kurzweil and his book, The Singularity is Near. In that version, the singularity becomes a future threshold driven by compounding technological capability where artificial intelligence improves itself autonomously and human ability to predict or steer outcomes collapses.

[4:42](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=282s) That's a definition most people implicitly have in mind today. And by that definition, it's hard to say where we are because current AI systems still depend on human decisions. Human in the loop is present on data curation, on hardware, energy, capital. Institutions' control hasn't disappeared at all even if it's become more distributed and slower to act.

[5:04](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=304s) Even in the recent situation with Malbots, human was still in the loop. They were still creating this space for robots to communicate. So what's going on? Why does singularity language feel relevant now even when the strict definition doesn't quite apply?

[5:19](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=319s) And this is where I come back to that moment in 1984. Because back then, even without knowing timelines, people could correctly say what came next. Progress had a dominant bottleneck. Progress was linear. Natural language was hard. So it became the focus.

[5:35](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=335s) Today there is no single bottleneck like that. Do we need compute for pre-training? Do we need compute for mid-training? Or do we need compute for post-training? And where is the most thing to uncover and discover and explore? Everywhere. We don't have an exact bottleneck. We shouldn't have anything linear anymore.

[5:55](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=355s) Progress happens across many interesting layers at once. Models improve, tools change, deployment patterns shift, costs drop, institutions react, governments react, second order effects start to matter even more than first order improvements. And that makes the future almost impossible to narrate. It becomes almost impossible to see beyond a few months.

[6:22](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=382s) So when someone says that 2026 is the year of the singularity, I think it's not about machines becoming sentient and us becoming united with machines. It's becoming closer to that original von Neumann intuition that the pace and structure of change no longer fit the way we're used to talking about progress. It's mind-blowing for us humans.

[6:46](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=406s) However hard it is to predict the future, we were able to do that. Now the future stopped being easy to describe even without dates. So, I don't know. I don't have an answer to the question, is 2026 the year of singularity? But I'm pretty sure we entered a period where our ability to predict, to clearly say what comes next has weakened, almost disappeared.

[7:08](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=428s) Even though our ability to build new systems keeps improving. Though I don't know what exactly is singularity, my gut tells me we are in the beginning of singularity. And there will be a moment when we will need to look back and ask ourselves when did this start, when was the moment when the singularity started.

[7:31](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=451s) I bet the end of 2025 and 2026 will be that moment where we will be able to attach the date to the event. Is it true? I don't know. It's just absolutely fascinating for me to live in the times when so many things happening at once on so many layers. It's just absolutely mind-blowing.

[7:50](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=470s) That becomes the most important question is how we as humanity will deal with this unpredictable uncertainty. This is my thinking process. There is no conclusions in this particular episode. And in general, I address my audience through Attention Span as a way of thinking together. It's my train of thoughts.

[8:12](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=492s) I would love to hear your thoughts. I always appreciate when you leave your comments and when we can talk about it. Are we in singularity? What does it mean? Is Ray Kurzweil right about his definition or John von Neumann is more accurate about singularity becoming when event horizon is impossible to predict? We cannot look beyond event horizon.

[8:35](https://www.youtube.com/watch?v=SQVGjnV-ikM&t=515s) What do you think? I'm very curious. Please let me know and let's think together. Let's determine the present. Even if we cannot anymore predict the future, it will help us later. Thank you. Please subscribe, share, and as I said, leave your comments.
