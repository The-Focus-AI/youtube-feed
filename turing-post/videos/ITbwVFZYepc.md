---
video_id: ITbwVFZYepc
title: "When Will We Give AI True Memory? A conversation with Edo Liberty, CEO and founder @ Pinecone"
channel: Turing Post
duration: 1862
duration_formatted: "31:02"
view_count: 865
upload_date: 2025-05-16
url: https://www.youtube.com/watch?v=ITbwVFZYepc
thumbnail: https://i.ytimg.com/vi/ITbwVFZYepc/maxresdefault.jpg
tags:
  - Artificial Intelligence
  - AI Innovations
  - Future of AI
  - Machine Learning
  - Pinecone
  - Edo Liberty
  - Vector Database
  - AI Memory
  - AI Interviews
  - Turing Post
---

# When Will We Give AI True Memory? A conversation with Edo Liberty, CEO and founder @ Pinecone

## Summary

In this episode of Inference by Turing Post, Edo Liberty, founder and CEO of Pinecone and former Amazon scientist, discusses when AI will achieve true memory capabilities. Edo draws a crucial distinction between cognitive skills (reading, writing, reasoning, coding) and the machinery needed for knowledge and memory - the ability to read, consume, understand, organize, and index information for real-time decision making.

Edo argues that the state of memory and knowledge in AI is roughly where foundational models were 5 years ago - pre-ChatGPT. While we have good ideas and infrastructure components like vector databases, RAG systems, and MCPs, we're still "very far away from being truly good at this." He predicts that within 2 years, many will consider the memory problem "semi-solved" as systems improve to reliably ingest millions of documents and provide right-time context.

The conversation explores the technical challenges of scaling vector databases, why Pinecone had to completely rewrite their architecture multiple times to handle new workload patterns, and the philosophical questions about truth and contested information that arise when building knowledge systems. Edo shares his perspective that you cannot be intelligent without being knowledgeable, making AI memory a critical stepping stone toward AGI.

## Highlights

### "Knowledge is where models were 5 years ago"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=44&end=95" frameborder="0" allowfullscreen></iframe>

> "I think the state of memory and knowledge is where foundational models were maybe 5 years ago. When you look at foundational models today, they really specialize in having cognitive skills. Reading, writing, summarizing, reasoning, problem solving, math, coding - those are cognitive skills. That is a completely different kind of skill or completely different kind of machinery that you need for memory. Something has to be able to read, consume, understand, organize, and index in some way to make it available in real time for decision-making."
> — Edo Liberty, [0:44](https://www.youtube.com/watch?v=ITbwVFZYepc&t=44s)

### "We had to rebuild the architecture multiple times"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=800&end=870" frameborder="0" allowfullscreen></iframe>

> "We've evolved our architecture multiple times already, every time to unlock 10x in scale. Even with our design for only vector database, we already had to evolve our architecture multiple times and we're now very far away from what pretty much any node-based solution is offering. We had to rewrite everything and really make sure that you organize data a lot more effectively."
> — Edo Liberty, [13:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=800s)

### "What does knowledge mean?"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=1207&end=1280" frameborder="0" allowfullscreen></iframe>

> "The questions that we don't ask as a technology community enough is really what does knowledge mean? What do we expect from these systems? How accurate do they need to be in what setting? What does accuracy even mean? There are also really deep questions on what do you do with contested information. Sometimes you have a point of view and they have the opposite point of view, both in the data."
> — Edo Liberty, [20:07](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1207s)

### "I don't think you can be intelligent without being knowledgeable"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=1420&end=1480" frameborder="0" allowfullscreen></iframe>

> "100%. I don't think you can be intelligent without being knowledgeable. I just don't think that's possible. When you speak to your primary care doctor, it's not enough that they have a very high IQ. You really want them to have gone to medical school and you really hope that they've actually understood what they were reading and they remember it roughly."
> — Edo Liberty, [23:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1420s)

### "Competition is very good for the industry"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=624&end=680" frameborder="0" allowfullscreen></iframe>

> "Almost the definition of a category is that you have competition. It's like otherwise it's not a category. It is very good for the industry that there's competition. It's very good that we are being pushed to do better, faster, cheaper, more features. We're being pushed by our customers to be more efficient. We're being pushed to innovate on our technology and our architecture."
> — Edo Liberty, [10:24](https://www.youtube.com/watch?v=ITbwVFZYepc&t=624s)

### "The world has already changed"

<iframe width="560" height="315" src="https://www.youtube.com/embed/ITbwVFZYepc?start=1665&end=1730" frameborder="0" allowfullscreen></iframe>

> "I think that the world has already changed and will keep changing and the value that we'll unlock from this is massive. Companies are going to be smaller, people are going to be doing more. A lot of menial cognitive tasks, all the summarizing, putting your notes in Salesforce after the meeting - all that nonsense that people hate doing is just going to go away and be done better, faster, and cheaper."
> — Edo Liberty, [27:45](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1665s)

## Key Points

- **Cognitive Skills vs Memory** ([0:44](https://www.youtube.com/watch?v=ITbwVFZYepc&t=44s)) - LLMs specialize in cognitive skills (reading, writing, reasoning); memory requires different machinery
- **Pre-ChatGPT State** ([3:31](https://www.youtube.com/watch?v=ITbwVFZYepc&t=211s)) - Knowledge/memory capabilities are roughly where LLMs were before ChatGPT
- **Multiple Components** ([5:49](https://www.youtube.com/watch?v=ITbwVFZYepc&t=349s)) - True memory requires improving data digestion, organization, real-time access, and post-processing coherently
- **2 Year Prediction** ([5:11](https://www.youtube.com/watch?v=ITbwVFZYepc&t=311s)) - Within 2 years, many will consider the memory problem "semi-solved"
- **Hardware Unlocks** ([6:22](https://www.youtube.com/watch?v=ITbwVFZYepc&t=382s)) - Both LLM training and vector databases needed hardware/infrastructure unlocks
- **Storage Not Compute** ([6:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=408s)) - Vector database scaling is storage-bound, not compute-bound
- **Contextual Embeddings** ([7:17](https://www.youtube.com/watch?v=ITbwVFZYepc&t=437s)) - Pinecone developing embeddings trained specifically for retrieval with contextual token models
- **Sparse + Dense Search** ([7:34](https://www.youtube.com/watch?v=ITbwVFZYepc&t=454s)) - Combining word/concept search with meaning/context search like humans do
- **Query as Task** ([8:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=486s)) - Queries are tasks, not just search strings; requires knowledge/search agents
- **Category Creator** ([10:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=600s)) - Edo created the vector database category; admits timing was partly luck
- **Architecture Evolution** ([13:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=800s)) - Pinecone rewrote architecture multiple times as workload patterns changed
- **Three Workload Eras** ([13:50](https://www.youtube.com/watch?v=ITbwVFZYepc&t=830s)) - 2020: high throughput/small data; then: large indices; now: millions of small indices
- **Multi-Tenant Challenges** ([15:25](https://www.youtube.com/watch?v=ITbwVFZYepc&t=925s)) - New pattern requires millions of small, siloed indices (like email inboxes)
- **Dynamic Indexing** ([17:25](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1045s)) - No single indexing algorithm is best; system must choose dynamically
- **Truth vs Frequency** ([21:55](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1315s)) - Direct correlation between frequency and perceived truth is a bug to fix
- **Knowledgeable AI Definition** ([22:45](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1365s)) - System that ingests unstructured info, organizes it, and provides real-time insights for tasks
- **Memory as AGI Stepping Stone** ([23:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1420s)) - You cannot be intelligent without being knowledgeable; memory is required for AGI
- **Endurance Lessons** ([24:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1480s)) - Book about Shackleton expedition teaches leadership, hope, and resourcefulness

## Mentions

### Companies
- **Pinecone** ([0:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=0s)) - Edo's company, leading vector database for AI memory
- **Amazon** ([0:19](https://www.youtube.com/watch?v=ITbwVFZYepc&t=19s)) - Where Edo worked as a scientist before founding Pinecone
- **Rubrik** ([15:12](https://www.youtube.com/watch?v=ITbwVFZYepc&t=912s)) - Customer using agents on top of folders with millions of small indices

### Products & Technologies
- **Vector Database** ([5:57](https://www.youtube.com/watch?v=ITbwVFZYepc&t=357s)) - Core infrastructure for AI memory and retrieval
- **RAG** ([3:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=186s)) - Retrieval Augmented Generation, became standard for memory
- **MCP** ([3:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=200s)) - Model Context Protocol for connecting models to data
- **TensorFlow** ([6:27](https://www.youtube.com/watch?v=ITbwVFZYepc&t=387s)) - ML framework that enabled model training at scale
- **PyTorch** ([6:28](https://www.youtube.com/watch?v=ITbwVFZYepc&t=388s)) - ML framework that enabled model training at scale
- **LSM Structure** ([17:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1020s)) - Log-Structured Merge tree, rebuilt by Pinecone for dynamic indexing
- **OpenSearch** ([11:42](https://www.youtube.com/watch?v=ITbwVFZYepc&t=702s)) - Incumbent database adding vector search
- **PostgreSQL** ([11:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=708s)) - Incumbent database adding vector search

### People
- **Edo Liberty** ([0:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=0s)) - Founder and CEO of Pinecone, former Amazon scientist
- **Ernest Shackleton** ([24:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1480s)) - Subject of "Endurance" book about Antarctic expedition

## Surprising Quotes

> "I think the state of memory and knowledge is where foundational models were maybe 5 years ago."
> — [0:47](https://www.youtube.com/watch?v=ITbwVFZYepc&t=47s)

> "If you just want to have you just want to search over hundreds of millions or billions of documents with filters, with complex embeddings with text, all that stuff, you need strong infrastructure."
> — [6:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=366s)

> "When people need a large vector base, when people need production grade, when people need scale and they need this to be cheap and fast and reliable and managed, they come to us."
> — [13:03](https://www.youtube.com/watch?v=ITbwVFZYepc&t=783s)

> "The direct correlation in AI between how common or frequent something is versus how truthful the model thinks it is - that's a bug, that's a problem we have to fix."
> — [21:55](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1315s)

> "If I had 50 PhDs working on this, they would all be very busy."
> — [22:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1350s)

## Transcript

[0:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=0s) When will we give AI true memory? To make all of this work, you have to do all of these leaps. What does knowledge mean? I think that the world has already changed. It is very good for the industry that there is competition.

[0:19](https://www.youtube.com/watch?v=ITbwVFZYepc&t=19s) Hi Edo, thank you for joining Inference podcast for Turing Post. And let me start from the big question right away. When will we give AI true memory and what does that phrase mean to you and what does it not mean?

[0:38](https://www.youtube.com/watch?v=ITbwVFZYepc&t=38s) It's a fantastic question. I like that you go straight ahead strong. I think the state of memory and knowledge is where foundational models were maybe 5 years ago. Before I say what the state is, I want to maybe slightly zoom out and say what I think it is at all, the memory. Because I think people use it in different ways in the same way they use intelligence in different ways.

[1:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=66s) And so I want to first maybe spend a minute explaining where I think intelligence and knowledge and memory sort of where they're different and what different functions they play in true intelligence. Then I can sort of say where we are as a company, where our mission is, what do we do, where we are today, where the market is today and so on.

[1:31](https://www.youtube.com/watch?v=ITbwVFZYepc&t=91s) So let's start. When will we give AI true memory? When you look at foundational models today, the large language models and so on that we have, they really specialize in having cognitive skills. Reading, writing, summarizing, reasoning, problem solving, math, you know, stuff like that, proof generation, coding. Those are cognitive skills. By the way, I'm not even talking about computer vision and so on. Those are computational problems.

[1:58](https://www.youtube.com/watch?v=ITbwVFZYepc&t=118s) Those are problems that have to do with skills, with compute, with abilities that you train over time. That is a completely different kind of skill or completely different kind of machinery that you need. For example, to read all the Boeing technical manuals and being able to then go and replace some part in an engine. Something has to be able to read, consume, understand, organize, and index in some way to make it available in real time for decision-making.

[2:31](https://www.youtube.com/watch?v=ITbwVFZYepc&t=151s) We as humans, if you're a technical, if you're a mechanic, airplane mechanic, when you're presented with a problem, there is a wealth of information that you have at your fingertips to make those decisions. That's knowledge. That's memory. That's information.

[2:47](https://www.youtube.com/watch?v=ITbwVFZYepc&t=167s) And I think to make all of this work, you have to do all of these steps. You have to improve and make all of those steps coherently better. It's not enough to just digest the data correctly, understand it correctly, organize it correctly, in real time access it correctly, post-process it, and so on. It's a very complex system.

[3:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=186s) Today, people use RAG, the Retrieval Augmented Generation, that became a standard at least to have a very very crude version of this. And people have many different variations of RAG and search combined with models now with MCPs and other stuff, right?

[3:24](https://www.youtube.com/watch?v=ITbwVFZYepc&t=204s) Based on what I can see in terms of quality, in terms of reasoning, in terms of capabilities, we are now on the knowledge front roughly where models were maybe pre-ChatGPT. There are initial good results. We have some really good ideas that seem to be performing really well. There are good heuristics in the industry that start to already do something qualitatively better than we could before, but we're still very far away from being truly good at this.

[3:54](https://www.youtube.com/watch?v=ITbwVFZYepc&t=234s) We have a product called Assistant that does everything end to end. It does incredibly well. It's like an end to end RAG, drop in documents in one place and connect your MCP server or context engine on the other side. Everything works out. We had to improve all the components together. We had to invest in each part of them. And still I'm telling you we're very far away.

[4:15](https://www.youtube.com/watch?v=ITbwVFZYepc&t=255s) We work with thousands of customers who use our own vector database as a basis for RAG and almost everybody does something that is very basic. So everybody's like I'm going to start with the basic thing and then there are like 7,000 things I want to do on top of it.

[4:31](https://www.youtube.com/watch?v=ITbwVFZYepc&t=271s) So that's where we are as an industry. I think we've broken the first barriers. We have amazing ideas. We have infrastructure in place. We have a vector database. We have models. We have all the components. In terms of us truly unlocking this, we're on our way there.

[4:46](https://www.youtube.com/watch?v=ITbwVFZYepc&t=286s) I think we will be there fully as an end to end automated system that truly understands and members and has all the information available to it, you know, probably in a few years. How many years? It's hard to say. I think those things tend to move faster than I predict.

[5:01](https://www.youtube.com/watch?v=ITbwVFZYepc&t=301s) So already today with Assistant and with our own context capabilities and so on we're getting very good results end to end. I think within 2 years for a lot of people they would think about this problem as semi-solved. By semi-solved, I mean they would rely on somebody like Pinecone to be able to ingest a million documents and they rely on their agents that have access to their context from Pinecone to bring in the right information at the right time to make good decisions. In the same way that they sort of rely on language models to behave reasonably.

[5:42](https://www.youtube.com/watch?v=ITbwVFZYepc&t=342s) So when you say we're far away, let's address your scientist founder side. What breakthroughs do we need to achieve that? There are multiple components that have to be improved independently and they all have to be brought together to work really well.

[5:54](https://www.youtube.com/watch?v=ITbwVFZYepc&t=354s) Pinecone is very well known for leading the vector database space and the vector database is really just a search engine or the infra that keeps the data that does the raw search. So if you just want to search over hundreds of millions or billions of documents with filters, with complex embeddings, with text, all that stuff, you need strong infrastructure to be able to do that. In the same way by the way that we needed GPUs to train large models.

[6:22](https://www.youtube.com/watch?v=ITbwVFZYepc&t=382s) It's funny, in both those cases the unlock ended up being hardware. We had to develop TensorFlow and PyTorch to be a lot better and GPU acceleration and the distribution, all that stuff. So we had to do a lot of software investment to be able to train large models.

[6:38](https://www.youtube.com/watch?v=ITbwVFZYepc&t=398s) Pretty much the whole vector database space and our journey into it is basically to be able to throw an infinite amount of data into the same knowledge machine, right? Because that's how you unlock. So the scaling just looks different. It's more not a compute thing. It's a storage thing. But that's not nearly enough.

[6:54](https://www.youtube.com/watch?v=ITbwVFZYepc&t=414s) We have our own research team developing embeddings that are trained specifically for retrieval so that you organize your data such that you can retrieve from it, you can fetch it correctly based on the context. We're going to have a new version of our contextual token-based model. Basically different words in documents actually mean slightly different things or are less or more important depending on the context. That becomes incredibly important when you search. And so the only way to do that is with models. And so we do that as well.

[7:26](https://www.youtube.com/watch?v=ITbwVFZYepc&t=446s) We combine sparse and dense search which correspond roughly to searching by words and concepts versus searching by meaning and context and general relevance, right? And we as humans do have to do both to be accurate.

[7:42](https://www.youtube.com/watch?v=ITbwVFZYepc&t=462s) But even that is not enough in Assistant. And now we're breaking this off and allowing this to be an independent component even though it's not out yet. But in Assistant itself, the query part also has to be trained. When you send the query, this is not a search query for a traditional search engine in the sense that you just find words that appear in documents.

[8:06](https://www.youtube.com/watch?v=ITbwVFZYepc&t=486s) When the search query is a task that you're trying to complete, now something has to, an LLM or some other model needs to take that text or task or situation you're in and figure out, oh, what is all the information that I need to go get to be able to make a good decision, right?

[8:22](https://www.youtube.com/watch?v=ITbwVFZYepc&t=502s) So, that in of itself becomes a knowledge agent or a search agent. I'm not even sure how to call this thing. It's an iterative process of fetching all the information that you need based on the information you get back until you feel like I have all the context that I need to make a good decision.

[8:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=520s) And I'm not even going into hooking into data and PDF parsing and all, there's a whole universe around that of just software that needs to be built. So I think we have to improve all of those. The models we are hosting existing models because they're good and people want to use them. We ship our own models that are also there. We shipped our re-ranker and host Cohere ranker and host open source re-rankers for results that come back.

[9:07](https://www.youtube.com/watch?v=ITbwVFZYepc&t=547s) We have our Assistant product. We have our own context agent that is coming out that I told you about. The core DB itself, our ability to work at massive massive massive scale and make it extremely cheap so that you can operate at those scales and not lose sleep over the fact that you're burning through your cloud budget makes a big difference for companies.

[9:28](https://www.youtube.com/watch?v=ITbwVFZYepc&t=568s) When you first pitched the idea of vector database back when you just came out of Amazon, you said almost no one understood the concept. After the ChatGPT boom it became a hot category with a lot of competition. But now some people say it's becoming commoditized. It becomes just a layer of infrastructure. Do you agree with that and where do you think the future of vector databases is headed?

[9:57](https://www.youtube.com/watch?v=ITbwVFZYepc&t=597s) Yeah I mean I am incredibly lucky and fortunate to be one of the very few founders who actually started a category. It's a huge privilege, right? Again, this is some of it is insight and a lot of it is just dumb luck and serendipity and good timing which again was a version of luck. I didn't know ChatGPT was going to happen. Nobody was, I think almost everybody was surprised by the timing of that.

[10:21](https://www.youtube.com/watch?v=ITbwVFZYepc&t=621s) Almost the definition of a category is that you have competition. It's like otherwise it's not a category. I am obviously in a sales cycle or whatever. Like when you're competing on a customer, it's not fun. You don't like being undermined.

[10:38](https://www.youtube.com/watch?v=ITbwVFZYepc&t=638s) But it is very good for the industry that there's competition. It's very good that we are being pushed to do better, faster, cheaper, more features. We're being pushed by our customers to be more efficient. We're being pushed to innovate on our technology and our architecture.

[10:54](https://www.youtube.com/watch?v=ITbwVFZYepc&t=654s) We had just shipped our newest release just a few weeks ago when the performance we're seeing and the cost reduction is massive. Now at very large scales we are by far the cheapest solution. By cheap I don't mean, when you say cheap people feel like whatever. I don't mean to cheapen the technology but it's the most effective way to do this.

[11:14](https://www.youtube.com/watch?v=ITbwVFZYepc&t=674s) And the only way you can do that is if you have the right architecture and you optimize it over many years. We are on a journey. We're going to keep on that journey and we're going to keep making our vector database faster, bigger, more cost-effective, more performant, more feature-rich, more secure and so on, more stable.

[11:35](https://www.youtube.com/watch?v=ITbwVFZYepc&t=695s) At the same time, there's also small open-source solutions and incumbent databases like OpenSearch and others are adding vector search into their offerings. And PostgreSQL and others have other offerings. And the truth is that it works fine at small scale. You have a lot of developers that have a few thousand documents or maybe 10,000 documents and they maybe send a couple of queries a second. Yeah, maybe even one whatever.

[12:02](https://www.youtube.com/watch?v=ITbwVFZYepc&t=722s) Let's say you operate at that scale. That's not nothing, but you're definitely not operating at scale, right? And so there's a lot of that just numbers wise. There are a lot of people with small workloads and very few people with very large workloads. Not very few, but way fewer.

[12:17](https://www.youtube.com/watch?v=ITbwVFZYepc&t=737s) And so the prevailing thought if you just open Twitter or LinkedIn is like, oh, I just use this and it worked great. You know what we see at Pinecone is that people come to us because they say, "Yep, I did the POC. It worked great and now I'm ready to go to production. Now I'm ready to scale."

[12:37](https://www.youtube.com/watch?v=ITbwVFZYepc&t=757s) And I see either performance degrade, cost go up, stability starts looking a little bit shaky. Just managing this thing becomes a pain in the butt. As an engineer, I'm suddenly on the hook to maintain this thing in production. And I'm like I didn't sign up to be a database admin for my job and so on.

[13:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=780s) When people need a large vector database, when people need production grade, when people need scale and they need this to be cheap and fast and reliable and managed, they come to us. So I have no doubt that vector databases are a category and for it to be built from the ground to do that well.

[13:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=800s) Yeah, like I told you, we've evolved our architecture multiple times already, every time to unlock 10x in scale. Even with our design for only vector database, we already had to evolve our architecture multiple times and we're now very far away from what pretty much any node-based solution is offering.

[13:38](https://www.youtube.com/watch?v=ITbwVFZYepc&t=818s) I think you told me at Human X that you had to rewrite the whole architecture. Is that right? And why did you need to do that? To explain that to you, I need to sort of take you a little bit on a historical trip on the kinds of workloads that vector databases have seen.

[13:55](https://www.youtube.com/watch?v=ITbwVFZYepc&t=835s) Circa 2020 people didn't have a lot of data but they were very aspirational in terms of their high throughput. So there was very computationally intense workloads. So you'd have one or two or 10 million vectors but you'd need to query them a thousand times a second. Very heavy compute, super optimized for that requires super advanced algorithms and high performance computing and data structures.

[14:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=860s) We spent several years just optimizing that and becoming extremely good at that. Indices started becoming larger. So people got used to the idea of vector databases. They got used to the idea that search becomes better. They got more comfortable with vector embeddings and so on. And they said okay now we want to run search at large scale. And so now people started vector searching over a billion vectors, multiple billions of vectors.

[14:45](https://www.youtube.com/watch?v=ITbwVFZYepc&t=885s) Now the distribution becomes incredibly difficult. By the way it's not only the amount of data became huge. The ratio between compute and storage changed meaningfully because now those systems are memory bound, storage bound, network bound. They're very rarely CPU-bound. If you just try to take the high performance computing thing and replicate it, it will be nauseatingly expensive.

[15:07](https://www.youtube.com/watch?v=ITbwVFZYepc&t=907s) So we built our own serverless solution to be able to fan out and co-habitate thousands of users so that when you search everybody can use the same CPUs and share the same storage. And then you can actually give high performance on a massive amount of data even though specific use cases don't saturate CPU. That's the only way you could actually do this cost effectively.

[15:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=930s) Interestingly enough, the reason why we had to redo our architecture or at least change it meaningfully in the last 6 months I should say is because a third pattern is now becoming more common. And that third pattern is actually vector databases or at least data sets that are massive, even bigger than the ones that I told you before. They could be tens of billions or hundreds of billions of vectors. Sometimes we have customers that talk about trillions.

[15:58](https://www.youtube.com/watch?v=ITbwVFZYepc&t=958s) But they're not searching everything at the same time. Those 100 billion vectors are actually siloed to maybe a few tens of thousands of shards. Think about this as an email provider. When you search on inboxes, every inbox is its own little search index. Or if you're working with Rubrik and so they provide agents on top of folders. So now every folder or every set of folders or every user is now a different index.

[16:23](https://www.youtube.com/watch?v=ITbwVFZYepc&t=983s) But they would have millions of those. So now you have millions of small indices. By small I mean anything from 100,000 to a few million vectors. Now this is a big departure from the original setting because before we said oh like every index is massive. The object that you call an index can be very heavy, right?

[16:42](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1002s) You can have all sorts of bookkeeping and indices and substructures. If you spend 100 megabytes of disk and memory on each index just on the optimization for the index, it's fine. It's going to be great. When you have 10 million of those that's not going to work. It just doesn't work at all. And so you have to rewrite everything and you have to really make sure that you organize data a lot more effectively.

[17:05](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1025s) The last thing I would say is because we are a fully serverless system, we have no idea to begin with if an index like that is going to have 100 vectors or 10,000 or 10 million. We have no idea if it's going to be queried once a month or 100 times a second. We just don't know.

[17:23](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1043s) And so we also had to rebuild our own LSM structure so that every level has its own indexing based on how much usage and how deep you are in the hierarchy structure. Because we do have a lot of very small indices. And for those you really don't want to index anything. You really want to be super scrappy and really have almost no structure. And the bigger it is, the longer you have the data, the more you query it, the more you can justify spending the energy to index it better.

[17:55](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1075s) And I think a lot of the discussions in the database industry is like oh what algorithm is best, what should I use, how should I configure things. And our experience is that there is no answer. The answer is you have to use all of them.

[18:08](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1088s) If you have 10,000 users, if you're an email provider again, let's just take that as an example, if you have a million users, the top 20% never searches at all. Then there's maybe 60% in your torso that would have some normal behavior and then you have the heavy users that do something altogether different. They might have 10 times as much data. That behavior, you're going to need your database to choose the right indexing at the right level and all that stuff dynamically. Otherwise you're not going to be able to manage that. That's another big big differential and completely new thing that we have to be very dynamic with our own data structures.

[18:50](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1130s) That's super interesting as a part of infrastructure for agentic workflows, right? With so many dynamic parts and constantly rethinking and rebuilding architecture with this basically limitless amount of data, queries and all that. What are the questions about memory or infrastructure that we are not asking enough right now on a bigger scale?

[19:10](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1150s) I have my own bias because I occupy some part of the stack, so take that as a disclaimer for my answer. I am both horrified and delighted that people assume that both LLMs and knowledge agents and search and RAG and things like Pinecone and Assistant just work and they're perfect.

[19:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1170s) It's horrifying because they're not perfect yet. And just assuming that is not necessarily the best assumption sometimes. But it's also amazing because that means that the people working on it, our scientists, our engineers, and everybody in our level of the stack has a lot of work and has a lot of figuring out to do.

[19:50](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1190s) The questions that we don't ask as a technology community enough is really what does knowledge mean? What do we expect from these systems? How accurate do they need to be in what setting? What does accuracy even mean? We provide in our context API for a system for example. We always provide references and so on. We have to make sure that all the information you get back is grounded in information you gave us because you don't want to hallucinate. You really want to make sure that anything you say can be verified.

[20:25](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1225s) But is that too high a bar? I don't know. Maybe it is for some applications. How do you break out of that? Do you need to break out of that? There are also really deep questions on what do you do with contested information. So sometimes you have a point of view and they have the opposite point of view, both in the data. What do you do with that?

[20:45](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1245s) If you search for one thing you'll find it. There's biases. We know these things from social networks and so on for humans as well. If you seek some information, that's the information you'll find and it will strengthen your conviction.

[21:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1260s) You can encode, maybe unintentionally, the same behavior into models. Again, the same questions about truth come up that we struggle with as society come up with data as well. The fact that something is much more common doesn't make it more true. And models are by nature Bayesian. If something you see more, you learn it more often, you would tend to give that answer more.

[21:25](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1285s) The direct correlation in AI between how common or frequent something is versus how truthful the model thinks it is, that's a bug, that's a problem we have to fix. So there are deep questions about how do we process data, know it, understand it, make it coherent and make it accessible in a way that we as society start to trust.

[21:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1308s) I love it because there's like 20 years of research ahead of us that we're not going to be done anytime soon. If I had 50 PhDs working on this, they would all be very busy.

[22:00](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1320s) Can you give me a short description of what you mean by knowledgeable AI? So we touched on this a little bit, but I can try to give you a more concise answer. You need a system that can do the following. It can take large amounts of unstructured and unorganized information, take it in, organize it in a way such that in real time it can create insights and provide the insights and the data needed to either complete a task or answer a question or solve a problem.

[22:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1350s) That entire pipe is what I call knowledge. At the end of the day, what you want is that your agent that completes a task has all the historical context and can bring it to bear in real time in the right context to complete the task. That's it.

[22:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1368s) Like I said, you have to build multiple different components of this stack and they all have to be very well orchestrated. And some of those we have. I think as a society we've done, we're much closer to where we need to end up, and some of those we're very far away still.

[23:05](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1385s) Do you see memory and knowledgeable AI as stepping stones toward AGI? And more broadly, what's your take on AI? 100%. I don't think you can be intelligent without being knowledgeable. I just don't think that's possible.

[23:20](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1400s) When you speak to your primary care doctor, it's not enough that they have a very high IQ. You really want them to have gone to medical school and you really hope that they've actually understood what they were reading and they remember it roughly and they can actually talk about it intelligently. So their IQ means nothing. They're probably less quick on their feet just IQ-wise than they were at 20 years old, but you still trust them a lot more when they're 50 because of their knowledge, right?

[23:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1428s) If we look at the kinds of jobs and the part of the economy that benefits most from AI is all knowledge work. It's lawyers and accountants and patent editors and musicians and other kinds of artists and you name it. Those are all knowledge workers.

[24:05](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1445s) If they need to be enabled by AI, those systems better learn how to retain information and be knowledgeable. Otherwise they're, you know, we will have pegged AI like spellchecker on steroids. Edit this, tweak that, write something for me and so on. Again, which I think is a miss.

[24:22](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1462s) Thank you. I have two last questions and one is about books. I think books form people and my question is what book formed you and is there a particular book or idea you keep returning to as you build Pinecone's future?

[24:38](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1478s) Wow, that's a great question. Because I don't get to read as much as I would want as a CEO. That's not something I have a ton of time to do. That's a problem. There's a book I read many years ago that I still come back to often just thinking about it. I reread it again recently. I actually bought it for some people on the team. It's called Endurance. It's the South Pole expedition by Ernest Shackleton and his team that starts with absolute disaster, their boat being stranded obviously at the southern sea.

[25:15](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1515s) It's a well-known tale. It's an unbelievable journey. But for me as a CEO, there are so many different lessons there on leadership, on hope, on resourcefulness, on heart, just limits of the human spirit. Just imagining people going through what they're going through is all inspiring. There's just something about the human spirit there that is incredibly inspiring.

[25:40](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1540s) That's a great suggestion. I'm making a list of such books. It's always good to have different perspectives, what forms you, what helps you going as a leader, as a scientist. Thank you.

[25:52](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1552s) I'm trying to stay away from the traditional CEO books, all the how to be efficient ones. There are a lot of that, but there are a lot of really good ones too. I think fables often will give you more than self-help books or whatever.

[26:08](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1568s) Interesting. Yeah, some of it is very practical, but I think a lot of what it means to be successful, how you succeed both in business and in life has a lot to do with your morality and your character and your ethics. And at the end of the day, often times you see a lot of good companies with good technologies fail just for human reasons.

[26:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1590s) If we're getting back to AI field, when you think ahead, I don't know, let's say 5 years, what excites you or concerns you the most about the future, the world you're helping build?

[26:42](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1602s) I will say two things. I'll reiterate what I said before about truth and knowledge and so on. Those are to some extent technology challenges, but a lot of them are just human challenges. In our world, agreeing on what's true is not easy. Even if you have access to all the information. So it's not even a question of sources of intelligence, it's a political problem. It's a people problem. It's a human problem.

[27:08](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1628s) We will have to grapple with those issues. We all are grappling with those issues all day long, right? For Pinecone specifically, it's significantly easier because we work with companies with their data and so they define what is the desired outcome of the product they're building, right? And so we sort of like get a free pass a little bit, but we still have to grapple with some of those.

[27:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1650s) And I think in AI in general, this will become a big issue. In the same way that search engines had to deal with these issues in the early 2000s, in the same way that social networks have to deal with social bias and the algorithm biasing creating information silos and so on. All of those things will become AI problems too.

[27:50](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1670s) Okay, those are human problems that are not technology problems. The second thing I would say, and this doesn't worry me as much, but it is an issue that I think we'll have to deal with, there's a little bit of a race between how solid, understood, trustworthy the technology is versus what you use it for.

[28:10](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1690s) You want to see that those sort of go hand in hand. I want to see that we become good at curbing the unethical or irresponsible usage of AI when we see them as a society versus just letting them take off because they make money for somebody and they're not willing to shut it down.

[28:30](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1710s) We'll need to get ahead of that at some point. And the way that I'm dealing with this, I'm not a politician and law enforcement or whatever. I can only fight that by making the technology move faster, be more trustworthy, more understood, more manageable.

[28:48](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1728s) Well, those are two concerns. Is there anything that excites you? A ton excites me. This whole thing is incredibly exciting. We're seeing an absolute sea change in how pretty much every profession is practiced. I've never seen that in my lifetime for sure, but I don't know when that last happened.

[29:10](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1750s) I think maybe the internet had such an effect on people. I have young kids in primary school. They already view AI in the same way that 30-year-olds think about the internet. They don't even remember a time where you couldn't talk to a machine and for it to be able to just respond back and whatever, talk back to you. It sounds insane to them. Like of course.

[29:35](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1775s) I think that the world has already changed and will keep changing and the value that we'll unlock from this is massive. Companies are going to be smaller, people are going to be doing more. A lot of menial cognitive tasks, all the summarizing and putting your notes in Salesforce after the meeting, all that nonsense that people hate doing, it's just going to go away and be done better, faster, and cheaper.

[30:05](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1805s) That's just on a society and economic impact. For me as a scientist and engineer, the fact that I get the privilege to actually build this and influence how it works and have the delight of just discovering something new. It's like, hey, did you know that this actually works and it's like, oh my god, those moments, the Eureka moments are just unbelievable.

[30:28](https://www.youtube.com/watch?v=ITbwVFZYepc&t=1828s) The fact that we have the platform that serves tens of thousands of developers means that after that Eureka moment, a few weeks or maybe a month or two later you can actually give it to thousands and thousands of people and they actually use it. That's just the icing on the cake. Well, thank you very much for the conversation today.
