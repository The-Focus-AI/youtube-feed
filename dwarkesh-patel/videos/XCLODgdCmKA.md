---
video_id: XCLODgdCmKA
title: "Evolution designed us to die fast; we can change that â€” Jacob Kimmel"
channel: Dwarkesh Patel
duration: 6320
duration_formatted: "1:45:20"
view_count: 76280
upload_date: 2025-08-21
url: https://www.youtube.com/watch?v=XCLODgdCmKA
thumbnail: https://i.ytimg.com/vi_webp/XCLODgdCmKA/maxresdefault.webp
tags:
  - aging
  - longevity
  - epigenetics
  - transcription-factors
  - NewLimit
  - evolution
  - biology
  - drug-discovery
  - Erooms-Law
  - gene-therapy
  - Yamanaka-factors
  - Perturb-seq
  - single-cell-sequencing
  - immune-system
  - CAR-T
  - pharma
  - delivery-mechanisms
---

# Evolution designed us to die fast; we can change that -- Jacob Kimmel

## Summary

In this deep-dive episode of the Dwarkesh Podcast, Jacob Kimmel, co-founder and CEO of NewLimit, lays out a rigorous first-principles argument for why aging is a solvable engineering problem rather than an intractable feature of biology. The core thesis is elegant: evolution never optimized for longevity because (1) the baseline hazard rate in ancestral environments meant most humans died from external causes before aging mattered, (2) there may actually be selective pressure *against* longevity since aging functions as a "length regularizer" preventing populations from becoming demographically laden with older, less productive individuals, and (3) the genome's limited mutation rate and bandwidth were consumed fighting infectious disease rather than fine-tuning lifespan.

Kimmel then explains NewLimit's approach: epigenetic reprogramming using transcription factors. These are the "orchestra conductors" of the genome -- they don't encode proteins directly but tell cells which genes to turn on and off. As cells age, their epigenetic marks degrade, causing cells to lose their ability to function properly. NewLimit is searching for combinations of transcription factors that can reset a cell's epigenome to a younger state without changing its identity (a key distinction from Yamanaka's full reprogramming to stem cells, which causes dangerous side effects like teratomas). The search space is enormous -- with 1,000-2,000 transcription factors and combinations of 4-6, there are roughly 10^16 possibilities -- so they're using ML models trained on Perturb-seq data to predict which combinations will work, rather than testing exhaustively.

The conversation also covers fascinating tangents: why humans never evolved their own antibiotics (bacteria mutate too fast for our slow genome to keep up), the TRIM5alpha gene that shows evidence of ancient arms races with HIV-like retroviruses, Eroom's Law (the exponential decline in drug discovery productivity), and a provocative vision of the future where engineered immune cells serve as the ultimate drug delivery platform, carrying therapeutic payloads to any cell in the body.

## Highlights

### "Evolution designed us to die fast -- three reasons why"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=78s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*1:18-2:20" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-1m18s.mp4"
```
</details>

> "There are a couple of things you have to think about. One is: what's the positive selective pressure that would make one live longer? Do you have that selective pressure present? Two: are there anti-selective pressures working against longevity? And three: even if selection is there, can the genome actually execute on it given its limited mutation rate?"
> -- Jacob Kimmel, [1:18](https://www.youtube.com/watch?v=XCLODgdCmKA&t=78s)

### "Aging as a length regularizer"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=577s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*9:37-10:00" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-9m37s.mp4"
```
</details>

> "I love this idea of aging as a length regularizer. When companies are training models, they'll have a penalty: 'Think carefully, but don't make the chain of thought too long.' Is aging, over the course of your life, one such regularizer?"
> -- Dwarkesh Patel, [9:37](https://www.youtube.com/watch?v=XCLODgdCmKA&t=577s)

### "Why humans never evolved their own antibiotics"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=774s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*12:54-15:00" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-12m54s.mp4"
```
</details>

> "It feels like antibiotics should be something evolution could have figured out. Where do antibiotics come from? They're just metabolites, largely from fungi and bacteria. But the challenge is the Red Queen effect -- even if our human genome stumbled into making an antibiotic, the bacteria would have mutated around it pretty quickly."
> -- Jacob Kimmel, [12:54](https://www.youtube.com/watch?v=XCLODgdCmKA&t=774s)

### "Transcription factors are evolution's levers"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2200s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*36:40-37:40" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-36m40s.mp4"
```
</details>

> "Transcription factors are a really nice substrate for evolution to effect change. In some ways they might be evolution's levers for altering biology. By pulling on those same levers that evolution has used, maybe there are amazing things we can engender upon biology."
> -- Jacob Kimmel, [36:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2200s)

### "The immune system as the ultimate drug delivery platform"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2960s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*49:20-50:40" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-49m20s.mp4"
```
</details>

> "If I were to Rip Van Winkle into the future, I think the way we will be delivering these nucleic acid medicines is through engineered immune cells. They deliver the medicine only to the right places, only at the right times, only when your body actually dictates that you need it."
> -- Jacob Kimmel, [49:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2960s)

### "10^16 combinations -- you can't brute force this"

[![Clip](https://img.youtube.com/vi/XCLODgdCmKA/hqdefault.jpg)](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1920s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*32:00-33:00" "https://www.youtube.com/watch?v=XCLODgdCmKA" --force-keyframes-at-cuts --merge-output-format mp4 -o "XCLODgdCmKA-32m00s.mp4"
```
</details>

> "There are somewhere between 1,000 and 2,000 transcription factors. If four to six factors might be required, the number of combinations is about 10^16. In order to just screen through all of those, you would need to do more single-cell sequencing than the entire world has ever done. It's just not tractable to do exhaustively."
> -- Jacob Kimmel, [32:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1920s)

## Key Points

- **Three reasons evolution didn't optimize for longevity** ([1:18](https://www.youtube.com/watch?v=XCLODgdCmKA&t=78s)) - Weak positive selection (high baseline hazard rate meant few survived to where aging mattered), possible negative selection (aging as demographic regularizer), and genome bandwidth constraints (mutation rate and infectious disease pressure consumed optimization capacity)
- **Baseline hazard rate was extremely high** ([2:23](https://www.youtube.com/watch?v=XCLODgdCmKA&t=143s)) - Even absent aging, ancestral humans were unlikely to survive past 50-60 years due to predation, infection, and accidents -- limiting the selective pressure for longevity genes
- **Fluid intelligence peaks around 30** ([5:47](https://www.youtube.com/watch?v=XCLODgdCmKA&t=347s)) - Most revolutionary scientific discoveries happen before age 30, likely because intelligence was selected most strongly for the age of peak reproductive fitness, not later in life
- **Aging as a length regularizer** ([9:37](https://www.youtube.com/watch?v=XCLODgdCmKA&t=577s)) - A population laden with aged individuals who consume resources but contribute less may be less fit; death functions as a regularizer preventing demographic overload
- **Genome bandwidth problem** ([10:02](https://www.youtube.com/watch?v=XCLODgdCmKA&t=602s)) - Even if the genome were a universal approximator, mutation rates are fixed, population sizes are limited, and most evolutionary bandwidth goes to fighting infectious disease
- **Why humans can't make antibiotics** ([12:54](https://www.youtube.com/watch?v=XCLODgdCmKA&t=774s)) - Bacteria have trillions of copies of their genome with high mutation rates; they would evolve resistance faster than our slow genome could evolve new defenses (Red Queen effect)
- **TRIM5alpha: evidence of ancient immune arms races** ([16:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=984s)) - This gene in our genome once restricted HIV-like retroviruses; Old World monkeys can't get SIV because of it, but the target retrovirus went extinct and TRIM5alpha lost its tuning for modern HIV
- **Gene duplication as evolution's workaround** ([17:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1044s)) - Copy-paste events let evolution keep the original gene while the copy mutates freely, explaining how complex new functions emerge without breaking existing ones
- **Epigenetic reprogramming approach** ([26:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1568s)) - NewLimit uses transcription factors to reset the epigenome (marks that tell cells which genes to use) back to a younger state, without changing cell identity
- **Why Yamanaka's approach doesn't directly work for aging** ([28:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1688s)) - Yamanaka could see success (cells change shape) and success amplifies (stem cells proliferate); for aging, measuring success requires single-cell sequencing and success doesn't amplify
- **10^16 search space** ([32:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1920s)) - With 1,000-2,000 TFs and combinations of 4-6 needed, exhaustive search is impossible; ML models trained on sparse sampling predict the best combinations in silico
- **TFs as attention mechanisms** ([36:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2212s)) - Transcription factors are like queries in attention; DNA motifs are keys; genes are values -- small changes in TF sequences can cause dramatic changes in gene expression programs
- **Delivery problem and the immune system solution** ([45:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2724s)) - Current delivery methods (lipid nanoparticles, AAVs) are limited; the ultimate solution may be engineering immune cells that can reach any tissue and deliver payloads responsively
- **One tissue can benefit the whole body** ([54:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3240s)) - Young liver transplants improve outcomes beyond just liver function; tissues are endocrine organs that coordinate whole-body health -- even de-aging one tissue type could have broad benefits
- **Eroom's Law** ([1:10:13](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4213s)) - Drug discovery productivity has been declining exponentially: fewer new molecular entities approved per billion dollars invested, the inverse of Moore's Law
- **The hook problem, not the drug problem** ([1:14:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4440s)) - Pharma is great at making molecules (antibodies, small molecules) but bad at knowing what to target; 70% of risk is in target identification, not drug engineering
- **Perturb-seq as biology's foundation model** ([1:17:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4640s)) - Developed in 2016 but only now becoming scalable; uses barcoded genetic perturbations combined with single-cell sequencing to learn how gene perturbations affect cell states
- **Pay-for-performance as the business model** ([1:32:13](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5533s)) - For long-lasting anti-aging medicines, insurers could reimburse over time based on measured health outcomes, similar to how pre-existing condition frameworks already work
- **25% of Medicare spent in final year of life** ([1:37:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5820s)) - If anti-aging medicines can prevent even a couple of intensive healthcare visits, the savings dwarf the drug costs; pharmaceuticals are one of the few areas where technology actually reduces per-unit costs

## Mentions

### Companies
- **NewLimit** ([0:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=40s)) - Jacob Kimmel's company working on epigenetic reprogramming to reverse aging using transcription factors
- **Roche** ([1:40:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=6000s)) - Pharmaceutical company whose R&D is led by Aviv Regev, one of the inventors of Perturb-seq
- **Eli Lilly** ([1:35:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5700s)) - Referenced for their incretin mimetics (GLP-1 drugs) and direct-to-consumer pharmaceutical model
- **Hudson River Trading** - Sponsor, mentioned for using deep learning for global capital allocation
- **Labelbox** - Sponsor, data labeling platform

### Products & Technologies
- **Perturb-seq** ([1:17:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4640s)) - Technology combining genetic perturbations with single-cell sequencing to map gene function at scale
- **Single-cell RNA sequencing** ([30:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1800s)) - Key enabling technology that lets researchers measure the complete gene expression profile of individual cells
- **Lipid nanoparticles (LNPs)** ([45:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2724s)) - Fat bubbles that deliver RNA into cells; currently the most developed delivery mechanism, primarily targeting liver cells
- **Adeno-associated viruses (AAVs)** ([46:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2800s)) - Viral vectors that can deliver whole genes into cells; limited cargo capacity but well-established
- **CAR-T cells** ([51:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3060s)) - Engineered T cells that target cancer; discussed as a prototype for the future immune cell delivery platform
- **CRISPR** ([15:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=940s)) - Referenced in context of bacterial defense systems that maintain a record of past pathogen encounters
- **Yamanaka factors** ([28:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1688s)) - Four transcription factors (Oct4, Sox2, Klf4, c-Myc) that reprogram somatic cells into induced pluripotent stem cells
- **Tirzepatide** ([1:33:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5580s)) - GLP-1/GIP dual agonist drug with broad health benefits beyond weight loss
- **Super-SOX** ([1:07:03](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4023s)) - Mutated version of SOX2 that is more efficient at reprogramming than the natural version, evidence that natural TFs aren't fully optimized

### People
- **Jacob Kimmel** ([0:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=40s)) - CEO and co-founder of NewLimit, the guest
- **Shinya Yamanaka** ([28:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1688s)) - Won Nobel Prize in 2012 for discovering that four transcription factors can reprogram somatic cells into stem cells
- **Aviv Regev** ([1:17:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4640s)) - Co-inventor of Perturb-seq, now heads R&D at Roche; described as "a thousand times smarter than me"
- **Jonathan Weissman** ([1:17:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4640s)) - Co-inventor of Perturb-seq at UCSF
- **Jack Scannell** ([1:10:13](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4213s)) - Friend of Kimmel who named Eroom's Law
- **Alexander von Humboldt** ([7:32](https://www.youtube.com/watch?v=XCLODgdCmKA&t=452s)) - 19th-century naturalist who made revolutionary discoveries about biogeography during a single expedition to South America
- **Isaac Newton** ([7:26](https://www.youtube.com/watch?v=XCLODgdCmKA&t=446s)) - Referenced as example of greatest scientific achievements happening in concentrated bursts before age 30
- **Luke Gilbert** ([1:04:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3840s)) - Researcher at the Arc Institute who made targeted epigenetic edits that persist through 400+ cell divisions
- **Trenton Bricken** ([37:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2248s)) - Had a paper in grad school on analogies between genome information storage and LLM architectures
- **Eddie Chang** ([37:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2248s)) - Found positional encodings in the brain similar to those in transformer models
- **Don Thomas** ([54:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3240s)) - Pioneer physician in bone marrow transplantation

## Surprising Quotes

> "From the best evidence we have, the baseline hazard rate during the environment of evolutionary adaptedness was roughly 1-2% per year. Even absent aging, you're unlikely to actually make it past 50 or 60. The number of individuals who are going to make it later in that lifespan, where aging is one of the main limitations and where pushing your lifespan upward matters, is relatively limited."
> -- [2:41](https://www.youtube.com/watch?v=XCLODgdCmKA&t=161s)

> "Even if our human genome stumbled into making an antibiotic-like compound, bacteria would have mutated around it pretty quickly. In the early history of life there are millions of 'naive' antibiotics, but now basically all bacteria have resistance to everything."
> -- [14:53](https://www.youtube.com/watch?v=XCLODgdCmKA&t=893s)

> "Out of the 20,000 genes in the genome, the shocking finding was that just four genes is enough to reprogram a cell all the way back into a young embryonic stem cell. That's a shocking result. What we now know is that you can reprogram the age of a cell as well -- but it also changes a bunch of other stuff, including potentially causing tumors called teratomas."
> -- [28:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1708s)

> "25% of all Medicare spending happens in the final year of life, which is shocking given that the average person is covered by Medicare for a decade-plus. If anti-aging medicines can prevent even a couple of those intensive healthcare visits, the savings dwarf the drug costs."
> -- [1:37:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5820s)

> "70% of all drugs currently entering clinical trials were originally discovered by small biotechs rather than large pharma. Most of the dollars of R&D spend are on the balance sheets of large pharmas, but the ideas are coming from small companies."
> -- [1:40:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=6000s)

## Transcript

[0:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=40s) Today I have the pleasure of interviewing Jacob Kimmel, co-founder and CEO of NewLimit, where they're trying to epigenetically reprogram cells to reverse aging. Jacob, thanks so much for coming on the podcast. I look forward to the conversation.

[0:53](https://www.youtube.com/watch?v=XCLODgdCmKA&t=53s) What's the first principles argument for why we should expect that anti-aging medicine is possible? I know evolution cares about our kids. By making us live longer, we can have more kids, right? Or we can care for our grandkids. What's the case that anti-aging medicine would have effects which actually matter from an evolutionary standpoint?

[1:18](https://www.youtube.com/watch?v=XCLODgdCmKA&t=78s) I think there are a couple of things you need to consider. One is you have to think about what's the positive selective pressure that would make one live longer and encode for longevity in the genome. Do you have that selective pressure present? Two, are there anti-selective pressures that are working against longevity? There's a third piece of this, which is computational complexity. If we think about the genome as a set of parameters being optimized by natural selection, then you've got some constraints. You can only do so many mutations at a time. You can only update your genome in certain ways.

[1:51](https://www.youtube.com/watch?v=XCLODgdCmKA&t=111s) What would the positive possible selection be? The argument would be: "If I'm able to extend the lifespan of an adult, they can care for those children more effectively. Those genes would spread readily into the population." But you have to try to think back in a thought experiment style to the environment of evolutionary adaptedness and ask: what were the conditions under which a person would survive long enough for longevity genes to be selected for, and how often would that occur?

[2:23](https://www.youtube.com/watch?v=XCLODgdCmKA&t=143s) There are some important sub-questions here. What was the baseline hazard rate during the environment of evolutionary adaptedness? The hazard rate is simply, "What is the likelihood that you die this year from any cause?" It integrates everything. That's diseases from aging, that's falling off a cliff, that's scraping your foot on a rock and getting an infection. From the best evidence we have, the baseline hazard rate was roughly 1-2% per year. Even absent aging, you're unlikely to actually make it past 50 or 60. So the window where aging is one of the main limitations on lifespan -- the number of individuals who are going to make it later in that lifespan, where pushing your lifespan upward is relevant -- is relatively limited. The selective pressure on the genome then is not as high as you might initially think.

[3:10](https://www.youtube.com/watch?v=XCLODgdCmKA&t=190s) On that, often people who are trying to explain why evolution didn't do something will say: well, evolution tried to optimize for intelligence, and if intelligence would have prevented death from external causes, intelligence would have been selected for. So even if intelligence were a relatively simple thing to evolve, it would have taken evolution so long to optimize for it. And potentially, if intelligence were really valuable, you'd expect to see superintelligence -- Jupiter-level intelligence -- but we don't. There are physical constraints like birth canal sizes, or the fact that we had to walk upright.

[3:53](https://www.youtube.com/watch?v=XCLODgdCmKA&t=233s) But what you just hinted at is an independent constraint, which is that if you need intelligence, that would imply you can't be a kid for too long. You need to grow up pretty fast, become an adult so that you can have your kids and contribute resources back to the group. You need to get calories, go out hunting and gathering. If you're just hanging out learning stuff for 30 years, you never get to have kids yourself. Humans have bigger brains than other primates, which help us make use potentially of longer lifespans. But if you made the adolescence too long, then you never reproduce.

[4:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=276s) If that's going to happen anyways, what's the point of extreme longevity? Maybe intelligence is easier to evolve than we think, and there are a bunch of contingent reasons evolution didn't churn out super-intelligent beings. I entirely agree with that particular thesis. It's often harder to engineer a given property, be it being stronger, faster, more intelligent -- this is true even at the molecular level. Consider how hard it is to manufacture a protein at high efficiency. Did evolution spend a lot of time optimizing this? If not, potentially there's room for us to improve.

[5:14](https://www.youtube.com/watch?v=XCLODgdCmKA&t=314s) This is a good argument for why, potentially, aging is a problem we can solve. The lifespan argument plays back into the intelligence argument. You start to ask, "If I have intelligence that's only useful until a certain age -- if in some hypothetical universe, my fluid intelligence peaks at 25 -- then evolution isn't going to select for alleles that lead to longevity past that peak."

[5:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=336s) This is part of my own pet hypothesis around why most great scientific discoveries are made before age 30. There are exceptions, of course, and I'm going to get the exact age a little bit wrong, but the pattern is that the most revolutionary work happens roughly before 30. Why should that be true? You could cite a bunch of societal reasons for it. Your teachers cause you to think in certain grooves. But really, that's true across centuries? Across unique cultures around the world? Cultures from the East and cultures from the West? That seems unlikely to be purely societal. My hypothesis is that for whatever reason, our fluid intelligence is highest around the age at which group size during human evolution was maximal -- intelligence was selected most strongly for that age. That's probably about the age of the adults who were most reproductively active, which is what was selected for during most of evolution.

[6:33](https://www.youtube.com/watch?v=XCLODgdCmKA&t=393s) There's interplay between many features of biology -- lifespan, reproductive timing, brain development -- and how that dictates some of the features that we observe. In one way, this is a very interesting RL problem. There's a trajectory with some length, and then there's a scalar value of how much fitness you generate. If you've heard from your friends about the challenges of long-horizon RL, where you have very intermediate goals that last an hour, imagine trying to propagate any signal across a 20-year horizon.

[7:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=432s) It's not only the case that in many scientific fields, most discoveries happen early in careers. In many cases, if you look at the greatest scientists, their most important achievements cluster in a single year. Newton -- optics, calculus, gravity, all in his annus mirabilis. Do you know the Alexander von Humboldt story? Alexander von Humboldt is one of the most important scientists in history who is kind of forgotten now. He went on an expedition to South America where he climbed Mount Chimborazo. He was able to observe various ecological patterns that repeated across latitudes and across altitudes -- how selection was operating on plants and animals. That one expedition was the foundation of modern biogeography and ecology. When you see something named Humboldt, just assume it's usually Alexander von Humboldt. It was like this singular year in which he revolutionized our understanding of botany and selective pressure.

[8:17](https://www.youtube.com/watch?v=XCLODgdCmKA&t=497s) So those are the first two components of the evolutionary story -- weak positive selection and this third question: "Is there anything actively selecting against longevity?" Can I still make an argument that maybe evolution is working against long life?

[8:31](https://www.youtube.com/watch?v=XCLODgdCmKA&t=511s) One argument that comes up -- and I'll present both sides because you can find people using the same mathematical models to argue opposite conclusions -- is this notion of aging as a kind of demographic regularizer. If you take a selfish gene view of the world, where evolution is really optimizing for a genome's propagation rather than any individual's wellbeing, then selecting for longevity is a pretty tricky problem. If you're able to make a member of the population live longer and partially counteract the decrease in their fitness over time, but you haven't totally eliminated aging, then the marginal contribution of that individual to the genome as a function of their declining capacity may be less than if you were to allow that individual to die and free up resources for younger members that follow behind them.

[9:23](https://www.youtube.com/watch?v=XCLODgdCmKA&t=563s) A population laden demographically with many aged individuals, where death occurs at some period later in life, is actually net negative for the genome's fitness. The genome should optimize for turnover rather than indefinite persistence.

[9:37](https://www.youtube.com/watch?v=XCLODgdCmKA&t=577s) I love this idea of aging as a length regularizer. When companies are training models, they'll have a penalty: "Think carefully, but don't make the chain of thought too long." Is aging, over the course of your life, one such regularizer?

[10:02](https://www.youtube.com/watch?v=XCLODgdCmKA&t=602s) The third piece is basically computational complexity. This is where another ML analogy is helpful. A neural network is technically a universal approximator, but we can't actually find the optimal configurations in practice. People will wave their hands, but it turns out we don't really know how to optimize them perfectly, even though mathematically they are universal approximators. There are analogous challenges with our genome as the parameters being optimized.

[10:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=628s) One of those is that your mutation rate is fixed. So if you imagine that at each generation, you can select for some number of alleles, that number is set by your mutation rate. If you turn it up too high, you probably get a bunch of cancers and broken genes. If you have it too low, you can't adapt fast enough. You end up with this happy medium. Then the number of variants you can explore is basically limited by your population size.

[11:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=660s) The dominant use of that limited bandwidth in the human genome is really prevention of infectious disease. For most of the history of modern man, infectious disease is actually what kills people. There's a lot of pressure pushing for those defenses. The genome is really optimizing for protection against infectious disease above almost everything else. Even if you imagine that maybe the arguments for positive selection for longevity are there, and negative selection is absent, you could construct a reasonable argument that the genome hasn't optimized for longevity simply because it's been too busy with other things.

[11:56](https://www.youtube.com/watch?v=XCLODgdCmKA&t=716s) You have to imagine not only that positive selection is present and negative selection is absent, but that when you factor in all the other things the genome is optimizing for, there's enough bandwidth left over. Even if it's there, if you simply have to optimize infectious disease resilience more effectively, that crowds everything else out.

[12:16](https://www.youtube.com/watch?v=XCLODgdCmKA&t=736s) And so when you start to really investigate the question of "why didn't evolution solve this?" you actually find yourself in a pretty compelling scenario where both positive selection is relatively weak, there may be negative selective pressure, and most of our evolutionary pressure is going toward a completely different problem. You need all of that to construct the counterfactual where we're far from optimal in modern man. This puts aging and health really in this category of problems where we're well below what should be achievable.

[12:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=756s) Ergo, it should be, relatively speaking, easy to try and intervene and provide health benefits. The fact that existing medicines, which are incredibly simplistic -- we are targeting one gene, one pathway, everywhere at the same time -- the fact that these work at all is sort of positive evidence that we're far from optimal.

[12:54](https://www.youtube.com/watch?v=XCLODgdCmKA&t=774s) Here's something that puzzles me. It feels like antibiotics should be something evolution could have figured out. Where do antibiotics come from? They're just metabolites, largely from fungi and bacteria. You think about the story of penicillin. What happened? Alexander Fleming notices a mold growing on a dish that's killing bacteria. He says he has this light bulb moment: "Wow, this mold is making something that kills bacteria." But our genome couldn't imagine encoding an antibiotic because of the Red Queen effect.

[13:26](https://www.youtube.com/watch?v=XCLODgdCmKA&t=806s) Part of the challenge is this notion of what's called the Red Queen hypothesis. It's an allusion to the story in Lewis Carroll's Through the Looking Glass, where the Red Queen is running just to stay in place. When you look at pathogen-host interactions, everyone is trying to compete for the same niche. It's an arms race. The bacteria evolve an evasion mechanism, the host evolves a counter. Part of why there is this competitiveness between microorganisms is that they have very large population sizes in terms of number of genome copies. There are trillions of bacteria in a given environment. Trillions of copies of the genome. Massive population sizes. They can tolerate really high mutation rates because they're single-celled -- if one cell manages to mutate too much, it doesn't really compromise the population. Whereas for metazoans like you and I, if one cell mutates too much, it might turn into a cancer and kill the whole organism.

[14:34](https://www.youtube.com/watch?v=XCLODgdCmKA&t=874s) What I'm getting at is that these types of microorganisms are very well adapted to the kind of rapid evolutionary competition that would be necessary to make something like antibiotics. They have the mutation rate and population size in order to keep up with the arms race. Even if our human genome stumbled into making an antibiotic-like compound, the bacteria would have mutated around it pretty quickly. In the early history of life there are millions of "naive" antibiotics, but now basically all bacteria have evolved resistance to everything.

[15:15](https://www.youtube.com/watch?v=XCLODgdCmKA&t=915s) Do we see evidence of these historical arms races in our genome? I'm going a bit beyond my own knowledge base, but I can give you one prominent example. Bacteria that fight viruses -- bacteriophages -- have things like CRISPR systems. The individual guide sequences that tell the CRISPR system "where do you cut?" contain a record of past encounters. It seems like this bacterial genome has been fighting this particular pathogen for quite a while. You can read the history of what the warfare was like just by looking at those sequences.

[16:02](https://www.youtube.com/watch?v=XCLODgdCmKA&t=962s) We do have examples of this in the human genome too. Imagine you have some antipathogen gene A fighting virus X. The virus mutates, now you have virus X' and antipathogen gene A'. Then the virus goes extinct, but the defense gene still exists and we've lost our ability to fight the new variant. The most prominent one in the human genome is a gene called TRIM5alpha.

[16:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=984s) TRIM5alpha actually binds an endogenous retrovirus that has been resurrected by a bunch of researchers. We have this endogenous gene which basically fits like a hand in a glove and prevents this ancient retrovirus from infecting us. If you trace the history of that gene, you find that a previous iteration inhibited SIV -- simian immunodeficiency virus. Old World monkeys actually can't get SIV, whereas humans can. So it seems like what happened is there was an arms race with an HIV-like pathogen in the primate genomes. Our ancestors evolved TRIM5alpha and it was incredibly effective, becoming this massive endogenous defense. It gave our ancestors the ability to fight off these HIV-like viruses.

[17:19](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1039s) You can see the evidence because there are latent copies, like the half-buried bodies of ancient retroviruses in our genome. Then this particular retrovirus went extinct. But we didn't re-update that piece of our immune arsenal. So we're in a situation where you can actually make a couple of edits in that TRIM5alpha gene, revert it back toward the version that targeted the virus which no longer exists, and it would actually restrict HIV dramatically. You could imagine the same thing for other diseases where a particular defense mechanism went away because the original pathogen went extinct, but a new related one appeared.

[17:44](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1064s) How does evolution create new gene functions? A great explanation is that gene duplication happens a lot. If you look at most genes in the genome, most of them arose through duplication events. You have a gene performing some job, and then some new selective pressure appears. Maybe gene A, if it were to dedicate all its capacity to solving this new problem, could do it, but then you lose its original function. The genome has a workaround: copy and paste. A duplication event occurs and now you have two copies -- gene A and gene A'. I can preserve my original function with one copy, and then this new copy can actually mutate without consequence because there's no strong selective pressure on it. I've got two copies of the gene, I can afford to break one. Nothing bad really happens because the other one is doing the job.

[18:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1116s) So you can end up with drift. The per base pair mutation rate might be one in a billion per generation, but then the mutation rate on a gene you're aiming to evolve might actually be quite high when you have a spare copy. It's not that the base rate goes up. It's that having a backup means one copy is free to explore.

[19:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1148s) This is the main mechanism for how new gene functions arise, but it also makes it difficult for evolution to find multi-step paths. Somewhere along the path of edits, imagine going from a gene that restricts SIV to one that restricts HIV. Well, if one edit just breaks the gene, two edits fix it in a new way -- it's really hard for evolution to find a path where every intermediate step is tolerated. The key insight is that with duplication, those first two edits are totally tolerated because you've got your backup copy doing its job. And it turns out the number of edits needed is actually fairly small -- for instance in TRIM5alpha, for this particular conversion, it's not massive restructuring. It's a fairly small number of edits.

[19:56](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1196s) You can arrange genes in the human genome into families. What you find is even in our current genome, there are many, many genes which are clearly related through duplication. Very often you'll see something like "type one, type two, type three" in gene names. Sometimes those names arise from the fact that the sequences are actually quite similar. They went through a duplication event and then maybe diverged over millions of years. You ended up with these related genes that now have specialized functions. Evolution doesn't have to start from scratch. Most of the parameters for encoding a gene that does something useful are already there. Just do a copy paste and then tweak, as opposed to having to start ab initio.

[20:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1240s) Let me ask about selective pressure against people who get old but still consume resources. They're suboptimal from a calorie standpoint -- the food they consume versus what they can gather for the population is lower. A concern you might have about the effects of anti-aging medicine is that you will fix some part of the aging process but not all of it. It seems like you're saying that you actually don't expect a single silver bullet -- the most likely anti-aging procedure would work on some aspects but not all. We're only fixing half of the aging problem.

[21:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1288s) Sometimes I hear longevity proponents saying there's going to be a single source of aging that we fix. Whereas the evolutionary argument for why there's actually no strong selection against aging relies on the fact that aging is multi-causal. Evolution didn't bother to fix one cause of aging because there isn't a single monocausal explanation. There are changes in gene regulation that explain a lot. I've dedicated my career now to working on epigenetics, and I think that explains a lot of it. But the most likely outcome is that when we eventually develop these medicines, they're not going to fix everything at once. Rather you're going to have medicines that add back some number of years you can't otherwise get back.

[22:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1340s) Think of it as compressing the rate of decline. The first medicine gives some amount of benefit, then there's some continued decline over time, and the next generation of medicine compresses it further. Evolution hasn't been a great medicine maker for longevity because the selective pressure was never there.

[23:04](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1384s) So what is NewLimit actually doing? What's your approach? We're working on something called epigenetic reprogramming using special genes called transcription factors. Think of transcription factors as the orchestra conductors of the genome. They don't encode proteins directly themselves, but they bind specific regions of DNA and determine which genes to turn on, which genes to turn off. They place marks on DNA, on some proteins that DNA surrounds. This creates an additional layer of regulation called the epigenome.

[23:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1416s) The fundamental question is: how do all my cells have the same DNA but do different things? Your eyeball and your kidney have the same code, but they behave very differently. That may sound simplistic, but it's profound. That epigenetic code is really what differentiates them. That's what's telling them which genes to use and when.

[24:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1440s) What has now become relatively apparent is that the epigenome degrades with age. The particular marks that tell your cells how to behave start to become noisy and less precise. This means that cells aren't able to respond to signals at the right times, in the right ways. They develop less resilience to many insults that accumulate over a lifetime.

[24:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1464s) Our hope is that by remodeling the epigenome back toward the state it was in right after development, that you'll be able to restore cellular function. One of the strong contributing factors to aging is epigenetic decay, so if you can reset cells to the epigenetic state they were at an earlier point in your life, you might restore much of their lost function.

[24:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1492s) We're searching for combinations of these transcription factors that can bind to just the right places in the genome and establish the epigenetic state of a young cell. Would it be a straightforward mapping from a young cell state through these transcription factors to a rejuvenated state?

[25:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1512s) How I wish it were straightforward. No, it's very complex. These transcription factors regulate hundreds to thousands of places in the genome. You can think of the genome as the base components of cell function -- like the basis set in linear algebra. Aging doesn't necessarily correspond to changes along those natural basis vectors. It's tricky to figure out a combination of transcription factors that precisely reverses age-related changes. There are no guarantees from first principles that it's possible. It's actually a critical part of the process -- discovering medicinal combinations of transcription factors that are capable of making an aged cell revert to a younger state.

[26:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1568s) How do we measure success? One is simply measuring which genes cells use. They use different genes as they get older. We can sequence all of the mRNAs, which are really the active readout of what's being utilized in the genome at a given time. Can I revert them back to a younger state? Can I make an old cell look like a young one in terms of gene expression? More importantly, we go down to functional measures. We measure, "Can I actually make an aged cell perform the functions it needs to in the body, the same way a young cell would?"

[26:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1612s) These are the things you care about for treating diseases. Can I make a liver cell function better so it's able to clear metabolites, how it's able to process toxins more effectively? Can I make a T cell respond to pathogens and other threats more vigorously? These are the ways in which we measure age. We then check that the combination of TFs we find actually does rejuvenate the cell, but we also measure any potential safety concerns.

[27:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1640s) There are canonical examples where you can go too far. Full reprogramming, for instance, at the level of a whole cell, might be changing that cell's type or identity. Shinya Yamanaka won the Nobel Prize in 2012 for work he did in about 2007, where he showed that four transcription factors could take a somatic cell all the way back into a young embryonic stem cell. That showed that you can reprogram a cell's type and age simultaneously.

[28:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1688s) Out of the 20,000 genes in the genome, the shocking finding was that just four genes is enough. That's a shocking result. What we now know is that you can reprogram the age of a cell -- but it also changes a bunch of other stuff, as you alluded to. Full reprogramming can cause a type of tumor called a teratoma. So we need to monitor what's happening to the entire set of genes a cell is using. Are you still a hepatocyte? Are you still a T cell? We can use that same information to check for safety signals. Did I make this T cell hyperinflammatory? Did I make this liver cell potentially cancerous? Before you put these molecules in a human, you make an itemized list of the ways it might be toxic, and are we able to measure deterministically and comprehensively that it's safe?

[29:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1748s) This is a dumb question, but it will help me understand. You mentioned the Yamanaka factors. The way he identified these four transcription factors was to look at which ones have high expression in embryonic cells, and then systematically remove them to find the minimal set that still induces a cell to become a stem cell. Why can't we do the same thing for aging -- look at which transcription factors are different in younger cells as opposed to older cells, and then test those?

[29:44](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1784s) Shinya Yamanaka was able to do this with relatively few resources and achieve a remarkable result. That's exactly what you're asking -- why can't a similar procedure work for aging? There were two features of his experimental system that aren't present for aging. This is why he's such a remarkable scientist. You don't actually get better at pipetting over the years, but you do get better at picking what to do.

[30:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1808s) First, measuring his success criterion was trivial. He's starting with somatic cells -- fibroblasts -- which are defined as cells that stick to glass and grow flat. You can look at them under a microscope and see they're flat and spread out. The cells he's reprogramming to -- embryonic stem cells -- are tiny cells, they're mostly nucleus. They ball up, come off of a dish, they grow up into a 3D structure. He could set up a simple reporter system so that a gene that should only be on in a stem cell would cause the cells to actually glow. Then he ran this experiment in many, many conditions.

[30:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1852s) The second really key feature is that the stem cells he's converting into amplify. The success rate -- the number of cells in the dish that convert from a fibroblast into a stem cell -- is something like a basis point. It's vanishingly rare. If these cells were not growing and amplifying after conversion, you probably would never be able to detect that it happened. It's only because success is easy to measure and successful cells proliferate like mad that this was amenable to his particular approach.

[31:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1888s) He would test different groups of factors -- this group of 24 minus some subset. He would dump these onto a group of cells and just wait. Just a few cells in that dish would convert, but they would proliferate like mad. They form these colonies that you could actually see with your eyeballs by holding the dish up to the light. You don't need any fancy instruments. With a particular stain they would turn blue.

[32:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1920s) We look at those key features of the problem and aging is different. How difficult is it to measure whether you've achieved success for cell age? It's actually quite nuanced. An old liver cell and a young liver cell look very similar under a microscope. There isn't a simple, trivial system where you can just look and tell. You actually need a pretty sophisticated measurement system. For us, a real key enabling technology -- and I don't think this work would have been possible until it emerged -- was single-cell RNA sequencing. You now take a cell, rip it open, and measure all of its gene expression. At the level of individual cells, you can actually discriminate young and old with a complex model. But it turns out there's no one gene that tells you -- unlike in Yamanaka's case, where a single gene reporter works.

[33:04](https://www.youtube.com/watch?v=XCLODgdCmKA&t=1984s) The second feature is that success doesn't amplify. In some ways, the bar is much higher than what Yamanaka achieved. You can't just treat cells, then wait for success to multiply. You need the reprogramming to be fairly efficient. Because of this, we don't have the same luxury of just testing a small number of factors and finding a success case. We actually need to search a much broader space efficiently.

[33:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2008s) When you start playing that game, somewhere between 1,000 and 2,000 transcription factors exist in the human genome. Developmental biologists love to argue about the exact number. You want to choose some combination, and four to six factors might be required. The number of combinations is about 10^16. In order to just screen through all of those, you would need to do more single-cell sequencing than the entire world has ever done. It's just not tractable to do exhaustively.

[34:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2048s) So we need a model that can predict the effect of transcription factor combinations on cell age. If I can do a sparse sampling, I can test maybe thousands of individual factors and combinations. I can start to learn the relationship between which transcription factor is going to do what to an aged cell. Is it going to preserve the same type? I can start to learn their interaction terms. Then I can search in silico for all the combinations I haven't seen. You can actually treat that as a generative modeling problem -- which of these combinations is most likely to take my cell from old to young?

[34:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2092s) In our case, I want to take an old liver cell and make it a young liver cell. You can imagine some arbitrary mappings as well. But you don't have the same features that Shinya Yamanaka had -- you can't measure success really easily and success doesn't amplify. You're going to need to be able to search a larger space efficiently. So we can think of these transcription factors as modular components -- you can get a little bit of this thing, a little of that. And evolution has designed these to be relatively modular, self-contained units that interact with each other in predictable ways.

[35:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2136s) That would be very much my contention. That's the way development works. You and I were both just a single cell at one point. That single cell divided into cells that were all exactly alike, and then somehow differentiated into hundreds of different cell types in your body. When you look at how development works, it is through groups of these transcription factors being activated in sequence. In many cases, the groups of transcription factors that dictate different cell fates are actually pretty similar to one another. You swap one TF out of a combination and you get a totally different cell type. You have this sort of local change in sequence space leading to global change in output.

[36:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2172s) TFs are also frequently duplicated in the genome. Mutations in TFs are inherently small changes. Evolution needs a substrate where small changes in genotype give you relatively large changes in phenotype. Transcription factors have exactly that property -- they've been duplicated across evolutionary history enough times to provide the raw material.

[36:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2200s) I think we're actually in most cases in a regime where small edits in TFs need to lead to meaningful phenotypic changes, which makes them amenable to generic, gradient-like optimizers. Think of it as evolution using evolution strategies -- where you can't take a gradient on your loss function directly. Instead, you randomly modify parameters, compute the loss, and take a gradient in that perturbation space. TFs are the natural substrate for this because small perturbations lead to large effects.

[37:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2228s) It's like designing a little LoRA that goes on top of the genome. But why does the transcription factor layer exist at all? What's the point? Why not just have every cell read DNA directly? One possible explanation is that having transcription factors as an intermediate layer means that single base pair edits at the substrate of the genome can have outsized effects. If I break a transcription factor, I can change hundreds of genes at once. If I retarget a transcription factor to new DNA sequences, I can dramatically change when cells respond and have hundreds of downstream effects on their behavior.

[37:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2248s) Transcription factors are a really nice substrate for evolution to effect large-scale change. In some ways they might be evolution's levers for altering biology. By pulling on those same levers that evolution has used, maybe there are amazing things we can engender upon biology. If you wanted to analogize it to some code base -- are there commented out sections of the genome that say "de-aging"?

[37:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2272s) I don't know about that, but I can give you a better analogy. You can think about it like an attention mechanism. In the transformer architecture with queries, keys, values -- TFs are like the queries. DNA motifs are the keys. Genes are like the values. It turns out that you can very efficiently, in terms of editing space, change the query, which changes how it matches different keys, and get dramatically different output.

[38:16](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2296s) So I do think it's interesting how these information storage mechanisms parallel one another. Trenton Bricken had a paper in grad school about analogies between genome information storage and LLM architectures. Eddie Chang has found positional encodings in the brain similar to those in transformer models. These are fascinating papers. Chang implants electrodes into individuals and then talks to them. What he finds is that there seem to be neural signals that function as a positional encoding across sentences -- activity increases as the sentence goes on and then resets. Very similar to how we train large language models.

[39:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2348s) If you're right that transcription factors are evolution's levers for effecting large phenotypic changes, then pathogens, which have a strong interest in hijacking cellular machinery, should also have utilized transcription factors as their point of attack. And two, we've been trying to drug biology for decades -- why aren't all the big drugs targeting transcription factors?

[39:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2376s) I'll try and take those in stride. There absolutely are pathogens that utilize transcription factors as a lever. A famous example is HIV. HIV uses a protein called Tat that actually activates NF-kB, a master transcription factor in the immune system. HIV starts out as RNA, turns itself into DNA, integrates into your genome. It needs this ornate machinery to persist. When HIV goes latent -- which is why it's so pernicious -- you can suppress actively replicating HIV with really good drugs, but those cells that have hunkered down can just turn back on later. Similar to Hep B. One way it does it is through NF-kB, which typically increases the activity of immune cells. HIV turns on NF-kB activity and then hijacks the cell to produce more copies of itself.

[40:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2452s) Unfortunately, I don't have quite as clean an example for every pathogen, but they will interface with transcription factors and signaling pathways that control factor translocation to the nucleus. This actually segues to the question of why there aren't more medicines targeting TFs directly.

[41:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2480s) A lot of the drugs we have that work -- receptor blockers, signaling pathway modulators -- are ultimately exerting their effects through transcription factors downstream. We're taking bank shots because we can't hit the TFs directly. Why can't you just go after the TF directly? Most of our drugs are small molecule drugs. The reason they have to be small is they need to get across the membrane of a cell and get inside.

[41:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2512s) If you want to actually stick a small molecule onto a transcription factor, TFs have very large protein-protein interaction interfaces -- big swaths on their surface that form synapses with DNA and with each other. You would need to block that entire surface. It turns out that TF's binding interfaces are too large for small molecules. Small molecules can get all the way into the cell, but they can't do much once they're there against TFs.

[42:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2544s) Our other modalities are recombinant proteins -- we grow them in Chinese hamster ovary cells. This is how human insulin is produced. Or you make antibodies. But these are too big to get inside cells. They can find proteins on the surface of a cell, but they can't actually get to transcription factors inside.

[42:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2572s) So we take these bank shots through surface receptors. What I think is pretty exciting is we now have new delivery modalities. We can, for instance, deliver RNAs to a cell that can get inside. You wrap them in a fat bubble -- a lipid nanoparticle. It can fuse with a cell, release its contents inside. You can make a copy of a transcription factor as RNA, and then it translocates to the nucleus the same way a natural TF would. We've only very recently actually gotten the technology to treat transcription factors as first-class targets rather than some third-order thing.

[43:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2616s) So your claim is that a lot of existing drugs are actually TF modulators by proxy -- they're hitting upstream targets and the effects propagate down to TFs. Yes, exactly. This brings us to questions about delivery. You mentioned lipid nanoparticles. The ultimate question is: if we figure out the right transcription factor to de-age a cell, and even figure out the right one for every single cell type, how do you deliver it?

[44:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2652s) How do you deliver stuff? There are many ways one could imagine solving it. Delivering nucleic acid is the key challenge. Ultimately, the genome is nucleic acids, the readout of the genome is nucleic acids. If you can get nucleic acid into any cell efficiently, you can do basically anything in the genome effectively.

[44:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2680s) Today, there are two main modalities. The first one is lipid nanoparticles -- fat bubbles. By default, they get taken up by the liver. They can be used like trojan horses to deliver nucleic acid -- usually RNA, maybe encoding your transcription factors -- into the cell types of interest. You can also tie things onto the outside of the fat to make it go to different cell types in the body. We've been able to target various different tissues. Even if nothing else worked for the next decade, we'd have more than enough problems to solve just with LNPs.

[45:24](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2724s) Another prominent way people deliver genes is through viruses. Viruses have evolved over billions of years to deliver genetic material into cells with high efficiency. Maybe we can learn something from them. One type of virus people use a lot is called an adeno-associated virus -- AAV. They've been engineered extensively. Think of it like a very small delivery truck, so it can only carry a small payload. They can go to certain cell types as well. Importantly, since you're delivering nucleic acid to begin with, you can engineer specificity -- you can add a NOT gate. You can target certain cell types but never express in others.

[46:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2780s) You can start broad with your delivery vector and then get more specific with the genetic circuit, but not the other way around. If nothing else emerged for decades, we'd have plenty of therapeutic development work to keep the community busy with LNPs and AAVs.

[46:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2812s) I have one very controversial opinion about where delivery is going. Just one? I have many controversial opinions. One of my favorites is that neither LNPs nor AAVs at their limit will be the way that we're ultimately delivering these medicines. If you think about viral vectors, no matter what, they're always going to be seen as foreign by the immune system. There's always going to be some immune response, some toxicity risk. They also don't go everywhere. There's no viral species that infects every cell type in the body. We would have to also engineer the virus to avoid limitations. LNPs likewise have physical constraints. They have to get from your bloodstream out of the vasculature, and they have to not fuse into any cell they encounter along the way. There's a whole gamut they have to run.

[47:44](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2864s) I think we will ultimately solve delivery the way that evolution solved a very similar problem. We have the same challenge as the immune system: How do I patrol the body, find specific threats, and then deliver some important cargo to exactly the right location? How do I find a specific place and only deliver there? The problem was solved by the immune system.

[48:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2892s) T cells and B cells are effectively living delivery vehicles. They can invaginate whatever tissues they need to. There's nowhere they can't get access to, almost. They've got a very ornate circuitry for detection, complex logic gates, and they can release a specified payload. Currently the payload they release is largely either antibodies that do some targeting or killing of pathogens, or some signaling molecule. But the system itself -- the delivery infrastructure, the surveillance, the targeting -- is already there. Evolution has already gifted us this system.

[49:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=2960s) If I were to Rip Van Winkle into the future, I think the way we will be delivering these nucleic acid medicines is through engineered immune cells. They deliver the medicine only to the right places, only at the right times, only when your body actually dictates that you need it. Every delivery event is wrapped in a responsive circuit. A key advantage of immune cells is that they're big and they have big genomes. They can carry complex infrastructure and complex circuitry. You're not limited to the small cargo capacity of a virus. You've got billions of base pairs to play with.

[50:12](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3012s) So I think that's ultimately where things are going. We've got many stepping stones before we get there. But if I could clone myself and work on an even longer-term problem, that's what I'd work on. In a way, we already treat cancer this way with CAR-T cells. We take T cells out and then we tell them to go kill cancer. Is the reason that works that the cancer is relatively easy to detect -- proteins floating on the surface?

[50:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3052s) T cells can access almost literally every single cell in the body, with some asterisks. There are what we call immune-privileged compartments in your body -- your joints, your shoulders, your eyeball, and your brain. The ear probably falls into that category. But aside from those, virtually every cell is surveilled by the immune system. Interestingly, the immune-privileged compartments are exactly where the gene-therapy people using viruses want to go, because their drugs are immunogenic. So in a way, the shadow of all the places the immune system can't reach is what viral vectors address. Between the two, you can probably cover the entire body.

[51:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3096s) The analogy to the CAR-T work is very apt. In a natural immune response, I've got some detection mechanism for threats, I perform some function, and then I have some payload delivery. CAR-Ts engineer the first of those -- go recognize this other thing, some protein on the surface of a cancer cell. Then they deliver the same payload a T cell would normally deliver if it was infected by a virus -- it kills the cell. Whereas cancer cells usually look very similar to normal cells. Most of their genes are the same. It's genuinely hard for the immune system to surveil for cancer.

[52:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3128s) It's funny -- whenever we're trying to cure infectious disease, we say "Viruses have been evolving for billions of years to evade immunity, they know exactly what they're doing, it's so hard." But when we're trying to deliver drugs using viruses, we say "The immune system has been evolving for billions of years to stop exactly what we're doing, how do we get past it?" If you want to just throw a new modality at the problem and get around one side of that equation, engineered immune cells are the way. It may seem impossible and very far away but it's necessary.

[53:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3180s) In the short run, in the next few decades, we'll develop amazing therapies using LNPs and AAVs for the tissues we can reach. You mentioned hepatocytes -- liver cells -- which are some of the easiest to target. So the question becomes: even if I can only de-age my liver, is that going to be meaningful for whole-body health?

[53:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3208s) The fact that delivery seems to be lagging behind the science raises the question of whether targeting even a subset of tissues would have meaningful benefits. Just to give the delivery folks their due -- there are currently no reprogramming medicines that deliver nucleic acids for aging. This is what we're trying to build. But to your point, if you were able to only target some subsets of tissues, could you get a Frankensteinian benefit in health?

[54:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3240s) What we've found across the history of medicine is that the body is an incredibly interconnected, complex system. If you intervene on one cell type in one tissue, you often see benefits in other tissues that you didn't initially anticipate. The best evidence for this is through transplant experiments. For example, we have fairly common liver transplants. We can compare old humans who get livers from young donors versus old donors. The question is: what's the effect of just having a young liver? The latter seems to be true -- recipients of young livers have better outcomes for several other diseases and overall better health. Having a young liver is better for your whole body.

[55:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3300s) The reason is that organs are so interconnected. Many of your tissues, like your adipose tissue, are endocrine organs. They secrete hormones and signaling molecules that reach places all over your body, helping coordinate whole-body health. Even just one tissue can benefit other tissues. Another example from bone marrow transplantation -- there are many circumstances where patients who received bone marrow transplants for blood cancers were cured of another disease they had as a result. The replacement of this one special cell type, HSCs, had knock-on effects. There were symptoms of these diseases that seemed unrelated to the immune system, but ultimately the root cause was connected.

[55:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3352s) Is this related to why Ozempic has so many seemingly unrelated benefits? I think it's one example. GLP-1 is a hormone, and it's one instance of the complex interplay between your tissues. Nobody fully understands exactly why GLP-1 and GIP-1 receptor agonists broadly have so many knock-on benefits. If someone told you, "I'm going to find a hormone and it's not only going to have benefits for obesity but also possibly for addictive behavior, cardiovascular disease, and more," you would have told them they were crazy. But the cells in your body which are receiving this signal have such intricate connections that benefits cascade.

[56:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3388s) It's just one existence proof that intervening on one part of the body can have health benefits everywhere. Even if delivery remains limited, as I imagine it will for some time, I still think that we can add potentially decades of healthy life to individuals by targeting only a handful of cell types and individual tissues.

[57:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3420s) How many transcription factors? Some of those that we've found today that have efficacy are in the range of one to four. That's a small enough number that you can encode and deliver them. Already in the clinic today, there are medicines delivering multiple genes in a single treatment. There are medicines delivering 20 different mRNA payloads at once. When you think about that as a precedent, the idea of delivering just a few transcription factors is well within reach. Thankfully, I don't think we'll be limited by the number of factors we need.

[57:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3456s) One other really cool thing about transcription factors that is very favorable for drug development: TFs are very highly expressed in your genome relative to most genes. If you look at the rank-ordered list of what's most expressed in the genome by the count of how many mRNAs are present, TFs are way up there. That means you don't actually need to get a huge number of additional copies of a TF into a cell in order to have benefits. The dose shouldn't be limiting either.

[58:16](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3496s) Could this be a one-time dose? I think that would be an overstatement for today. But let me connect first principles back to the reality. Epigenetic reprogramming is basically how the body tells cells to adopt the identities that they have. The reason these reprogramming events can last decades is that my liver cells remain liver cells for my whole life. These epigenetic marks can persist for decades -- thousands of years if you want to take the example of certain organisms.

[58:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3532s) We also know that with very targeted edits, researchers like Luke Gilbert at the Arc Institute have been able to make targeted epigenetic edits that persist through 400-plus cell divisions over many years. You could potentially have one dose and it lasts for as long as it took you to age the first time -- maybe. But I don't want to overstate it. We do have data that these positive effects can persist. You could imagine, even without many leaps of faith, just from the data we have, that treatments might need refreshing every few months rather than needing an IV every day.

[59:40](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3580s) We've got 1,600 transcription factors. Is it worth looking at non-human TFs, or are they unlikely to be the right search space? I think evolution has given you a reasonable basis set for the cell states that human cells might want to occupy. The young cell state we're trying to access is encoded within our own developmental program. It does arise in development obviously. It should not look like some Frankenstein organism.

[1:00:16](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3616s) That said, we don't have any guarantees that the natural basis set of these transcription factor programs spans all the states we might want. I don't think it's unreasonable to ask, "Would the optimal aging medicine necessarily be a composition of natural TFs, or could it benefit from genes from other organisms, or even entirely synthetic ones?"

[1:00:48](https://www.youtube.com/watch?v=XCLODgdCmKA&t=3648s) There's a great example called Super-SOX. This is a paper by Velychko where they mutated the SOX2 gene and found that the mutant version was dramatically more efficient at reprogramming than the natural version. They could take somatic cells and turn them into stem cells much faster than with just the canonical Yamanaka factors. Since iPSC reprogramming never happens in nature, this suggests that the natural TFs aren't necessarily optimal for our engineering goals. Just mutagenizing one of the four Yamanaka factors or swapping some domains between a few TFs already gives better results. I think that's a pretty good signal that we're not at the optimal point and that potentially for us, the end-state medicines might use synthetic genes that have never existed.

[1:07:03](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4023s) What about the physical effects of aging? Effects of gravity over the course of decades? Is that something epigenetic therapy could deal with? That's probably not cellular. There's a protein in your skin called elastin, which does exactly what it sounds like -- it keeps your skin elastic. You have these big polymerized strands of elastin. As far as we understand it, you only polymerize these long cords of elastin during development. Then the rest of your life, you make individual subunits of elastin, but for reasons no one can fully explain, you can't make new long cords to replace the ones that break down.

[1:07:48](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4068s) So the eventual solution for something like skin aging might require engineering cells to states that are extra-physiological. It's not just like making a young skin cell from a 25-year-old -- you might need to reinvigorate the polymerization process that only happens during development. Maybe there's even a developmental transcription factor program that could achieve this. But that's something we'd have to engineer de novo, even if our genome has the raw components.

[1:10:13](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4213s) Okay, what is Eroom's Law? It was named by a friend of mine, Jack Scannell. It's Moore's Law spelled backwards. Moore's Law is the doubling of compute density over time -- it has graciously given us exponentially increasing performance over several decades. In biopharma, what we're actually seeing is an exponential decline in the number of new molecular entities -- new drugs approved -- per billion dollars invested. This trend goes back to the 1950s and persists through many decades. It seems to be an incredibly consistent exponential decay.

[1:11:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4260s) In a weird way, Eroom's Law is actually analogous to the scaling laws we have in ML, where you have this very consistent relationship between inputs and outputs. You throw in more inputs and you get predictable returns. The difference, of course, is that in ML this trend is good -- it drives more investment and more hype toward AI. In pharma, it has driven down valuations and dampened enthusiasm.

[1:11:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4488s) With AI at least you can internalize the extra investment -- you're always building one general purpose model. This year $500 million, next year $1 billion, but it's one general purpose model. Unlike, "We spent a billion dollars on drug discovery and that money went to 10 different narrow projects that may or may not work."

[1:12:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4320s) So what would a general purpose model for biology look like? Let me slightly dodge your question and highlight something interesting. There are probably two key features that distinguish ML scaling from drug discovery scaling. One is that the returns to scaled investment in ML are expected to increase super-exponentially -- each new capability level opens up larger value than just a few capability levels back. Whereas in life sciences, the diseases we're now targeting are getting further and further out on the long tail. They haven't necessarily scaled in their potential value. You're seeing increased costs for diminishing-value targets.

[1:12:48](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4368s) The other piece is that in ML, by making larger investments, you can build a more general model. You're moving from solving very narrow tasks to capturing broad fractions of white collar intelligence. In pharma, being better at developing a medicine for disease X doesn't necessarily help you develop one for disease Y. Typically these biotech firms specialize in making molecules to target particular genes. Being faster at making molecules more rapidly isn't actually the bottleneck.

[1:13:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4408s) This means that the ability to go from succeeding on one drug to the next is much more limited. So what would the general model be in biology? How do you get to a place where you imbue those two properties that create the ML scaling magic -- broader applicability and higher-value outcomes?

[1:14:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4440s) There are two dimensions. First, how do you expand the market? Currently we go after fairly narrow indications -- small patient populations with specific genetic variants. That's actually increased in terms of narrowness as we've gone forward in time. We've gone from addressing pretty broad diseases to narrower and narrower genetically-defined subpopulations. Because these only affect a few people, the total value of any individual drug is bounded. You need to find medicines that address everybody. All of us will one day get sick and die. The addressable market for anti-aging medicine could be everybody on planet Earth.

[1:14:48](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4488s) The second piece is: how do we get the success in one medicine to increase the probability of success on the next medicine? Maybe you're better at making an antibody for gene X. But it turns out making an antibody isn't the hard part. Figuring out what to make an antibody *to* is the hard part. What gene do I intervene upon in order to treat this disease? Most of the time, we just don't know. So a company that becomes very good at making antibodies to target gene X, when they then go to treat disease Y, they're starting from scratch on the most important question. Most of the risk is not in how to make an antibody but in figuring out what to target in the first place.

[1:15:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4528s) So the claim is that we know how to engage with a target once we've found it, but we don't actually know what to target. The "hook" problem is the hard problem. If you were to write down the list of targets that many folks would agree are the correct genes to modulate in order to treat a given set of diseases -- and then cross-reference that against the targets that we can't figure out a trick to drug -- it would probably fit on a single page. The list of diseases one could go after is much, much larger than the number of druggable targets.

[1:16:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4580s) If the only problem was that we didn't have the right therapeutics to put in humans, we wouldn't have the problem of Eroom's Law, because we can create elegant tools in animal models. You can engineer mice to express or delete any gene, in any subset of cells, at any time. But for the majority of pathologies, we simply don't know what to target.

[1:17:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4640s) What is the answer to what is the general purpose model for biology? The approach most people are trying to build is often described as a "virtual cell." Concretely, what most people are trying to do is to measure cell state -- turn some genes on, turn some genes off, and measure the outcome. The notion is that there's a lot of information in measuring all the mRNAs in a cell, which you can get by RNA sequencing. Then you try to learn: given that my diseased cells use these genes differently from healthy cells, are there any interventions I can find that shift one toward the other?

[1:18:04](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4684s) You're never going to be able to scan combinatorially all 20,000 genes and all possible combinations. That's what transcription factors help with -- they control which genes are active, so the search space is reduced. The hope is that by doing some sparse sampling -- here's what the cell looked like before I perturbed it, here's what it looked like after, here's which genes I perturbed -- you build a predictive model. Once I've trained a model to predict perturbation effects, I can search all possible combinations in silico to discover targets that take my diseased cell toward a healthy state.

[1:18:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4732s) That's one version of the general model. We actually do both -- we use cell age as one objective, but we also build broader models. We have representations of what a cell looked like at different ages, and representations of what different transcription factors do, derived from protein foundation models trained on protein sequences. These give us a really good base-level understanding of biology.

[1:19:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4768s) Then you can predict a number of different targets -- you could have multiple heads on a language model. One head predicts every gene the cell is expressing. You can guess what effect these transcription factors will have on a cell. Think about that as an objective where I'm not asking whether the outcome is good or bad -- I'm just asking what it will look like. It's prediction without value judgments. Then you add the value layer: does this predicted transcriptome look like a younger cell?

[1:20:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4800s) But you could do that for arbitrary objectives. What are some other states you might want? You might want to reverse an inflammatory state in somebody with autoimmune disease. Do I want to make liver cells more functional for types of metabolic syndrome? Do I want to go in and change the way a neuron functions for a particular type of neurodegenerative disease? They're not the ones we're going after, but the model architecture supports them.

[1:20:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4828s) This is so similar to LLMs. You first have unsupervised pre-training where you learn a general-purpose representation of the world. Then you fine-tune with RLHF for math or coding or whatever you care about. You're describing the same procedure -- first you just learn the broad effects of perturbations on cells, just learning how cells work. Then you add a layer of value judgments: "How would I want this cell to change?" That's like RLHF for biology.

[1:21:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4860s) I think the conceptual analogy is very apt. There are lots of technical differences so I don't want to overstate the similarity. But the general problem structure is the same. You might have a base model that learns "How are these perturbations affecting which genes are turned on and off?" Then you add the value function: which genes do you want to turn on and off?

[1:21:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4888s) Our lens on that is that across many, many diseases, one of the strongest predictors of how cells are going to misbehave is their age. If I could make the cell younger, maybe that would dramatically benefit not only patients with a specific disease but help all of us stay healthier longer. That's a very general value function.

[1:22:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4920s) In drug discovery, you would then need specific RLHF environments for each disease. You'd need labelers -- "What cell state am I engineering for?" -- and those labelers would be developmental biologists locked in a room evaluating outcomes. When was Perturb-seq first developed? Simultaneously in 2016 by several groups. We're still waiting for the scaling to catch up.

[1:22:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=4956s) Why has this taken so long? Good question. The technology was created by brilliant folks at the Weizmann Institute, Aviv Regev's lab at the Broad, and Jonathan Weissman's lab at UCSF. They all constructed this idea of combining a genetic perturbation with single-cell readout. You deliver some genetic element that turns a gene on or off, and each perturbation has a unique barcode. When you rip the cells open, you sequence both the transcriptome and the barcodes. You can then ask: "When I turned on gene X, what did it do to the rest of the cell?"

[1:23:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5008s) The actual readout -- single-cell sequencing -- used to be really expensive. The cost has come down dramatically, from dollars per cell to fractions of cents. But the real bottleneck was technical: when we started with this technology, the error rate was so high that only about 50% of cells would be correctly labeled with the right perturbation barcode. You'd have to throw half your data away. If you're doing one perturbation at a time, 50% is okay. But imagine you need to test five genes simultaneously. The probability that all five barcodes are correctly labeled is like (1/2)^5. Very quickly more of your data is noise than signal.

[1:24:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5060s) Only now are we really able to scale up where two scientists in our labs can process millions of cells in just a single day at high accuracy. There was a point even six or seven years ago when the people developing these reagents were publishing the very first proof of concept and only they could do it. Now it's becoming routine.

[1:24:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5092s) If this actually is the foundation model approach for biology, then once the technology is mature, what you'd expect is big well-funded companies doing cheap, massive Perturb-seq-like experiments and then leasing out the data. It seems like what's happening right now is different -- companies like NewLimit are saying, "We know the end use case we're going after." Rather than building a general foundation model for all of biology, we're vertically integrating. We're generating our own data in a way that's proprietary, focused on our specific question -- what combinations of transcription factors reverse the age of specific cell types?

[1:25:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5136s) That enables us to build what we think is the best model for our particular problem. Unlike in the ML world where much of the training data was a common good -- Internet text is pretty common across all foundation models -- biological data is still in its infancy. There isn't this Internet-like equivalent of data that everyone can build on. We're going after and generating some of our own data, building the high-quality corpus, and then building the first products based on it. We think that's necessary because the data infrastructure simply doesn't exist yet.

[1:26:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5180s) This is more a question about the economics. In the future, how are people going to make money from anti-aging treatments? Presumably with future AI models, someone could find an isomorphic molecule or alternative pathway. If you do come up with these crazy treatments, will you be able to make money? That's IP enforcement at a geostrategic level.

[1:27:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5220s) It comes down to IP enforcement effectively. The traditional pharmaceutical industry will still work because most of the payment in the United States goes through payers -- insurance companies. If you have the opportunity to get a medicine from some company in Shenzhen, or you can go through your insurance with a relatively low co-pay for the FDA-approved version, most people will choose the insured option. You and I probably live in a milieu of people who might be more adventurous, but that's not the general concern.

[1:27:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5256s) The more interesting challenge is: if you have medicines with very long-term benefits, how do you pay for them? The US system is that the average person changes their insurer every 3-5 years. That means that if you had a medicine that prevents all healthcare incidents for 20 years, no single insurer is technically incentivized to pay for it because the benefits accrue to the next insurer.

[1:28:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5288s) I think there are a couple of approaches. One is something called pay-for-performance where, rather than paying the full price of the drug upfront, you reimburse it over time. If the patient is generically healthier -- you can measure the reduction in rates of obesity, cardiovascular events, and various other things -- you pay something like a tenth of the cost each year. Each year you validate that the drug is still working. This is a big challenge: how do you measure that these medicines are still working for the patient? For gene therapies, you can just test for the presence of the gene -- "Okay, the drug is still there."

[1:29:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5340s) We already have a framework for this in the US system. Since the ACA, pre-existing conditions no longer really exist in insurance. You could treat the presence of an anti-aging therapy as something the next insurer inherits. If this patient's overall healthcare costs are lower because of the therapy, the insurer benefits from continuing to cover them.

[1:29:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5376s) What I'm saying here is one hypothesis about how payment could work, but there are alternative clever approaches. I think over time we're going to move toward a model where you pay for the outcomes, not just the drug. You're seeing some of the early moves from companies like Lilly around the incretin mimetics. For the first time, rather than going to your doctor's office, patients can go straight to Lilly, the source of the drug, and get it directly. That model where consumer demand drives the market -- because you feel the benefits in your daily life -- will start to dominate.

[1:30:16](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5416s) Some of these long-term benefits might be able to bypass the traditional insurance system. You could finance anti-aging treatments the way you finance other large purchases. The reason I'm interested in this is that healthcare spending as a fraction of GDP has been growing notable percentages. A huge fraction goes towards administering treatments. That's necessary, but nowhere near as productive as spending towards coming up with new treatments.

[1:31:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5460s) If we're going to spend 20% of GDP on healthcare, more should go towards coming up with new treatments rather than administering stuff that kind of works now. From the perspective of the payer, the cost of the drug itself is often a tiny fraction -- you go to the doctor, the doctor examines you, runs tests, writes a prescription, and the actual therapy might cost tens of dollars per patient while the visit costs tens of thousands. That's orders of magnitude of difference.

[1:32:13](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5533s) Even if we invent de-aging technology, how should we think about the way healthcare spending evolves? Will costs go up because now everyone needs to show up at the doctor's office to get a prescription? Or will they decrease because the downstream costs are avoided? I think the latter is much more likely. One reason is something like Baumol's cost disease. The total amount of healthcare spending going up is driven not just by pharmaceutical discoveries but by something broader -- the disintermediation of the healthcare system.

[1:33:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5580s) If you have more of these medicines for everyone, medicines that prevent disease rather than just fix problems once you're already sick, you'll eliminate a lot of the administration costs. Not the hospitals themselves, but the cost of administering existing treatments.

[1:37:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5820s) One stat on why I think that's true: 25% of all Medicare spending happens in the final year of life, which is shocking given that the average person is covered by Medicare for a decade-plus. Most of those expenses come once someone is already terribly sick and entering the intensive healthcare system. Something like an incretin mimetic, or a reprogramming medicine, that prevents even just a couple of those visits over a long period could actually start to drive healthcare costs down by shifting that burden from the administration of crisis care.

[1:37:48](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5868s) The pharmaceutical system is actually one of the few sectors where technology has made us more efficient. A given unit of healthcare through pharmaceuticals is going down in cost, especially because drugs eventually go generic. So if you got the question of "When would I want to be born to maximize my healthy lifespan?" -- the answer is as close to today as possible. For a given dollar unit of spending, you get more healthcare technology today than has ever been possible before. But costs everywhere else in the system have shot up.

[1:38:28](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5908s) Because of the mechanism of things going generic, the benefits of pharmaceutical innovation continue to work and persist over time, getting cheaper for everyone.

[1:38:52](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5932s) Final question. Pharma is spending billions on R&D. Surely they have noticed that the lack of a general model has made it more and more expensive to discover drugs. You say Perturb-seq has existed since 2016. What is the traditional pharma response? Do they think they have some other path, or are they all in on building these models?

[1:39:20](https://www.youtube.com/watch?v=XCLODgdCmKA&t=5960s) Let me correct one thing: we have way more data for the limited problem we're focused on -- overexpressing TFs in combinations. We're very confident we have more data than anyone else in the world for that specific question. That's where we're differentiated. For general single-cell perturbation data, there are other groups which have done a lot. We're still differentiated because we work with normal human cells with the right number of chromosomes, whereas it's very common to work with cell lines that have 200 chromosomes. Is that human? I don't know.

[1:40:00](https://www.youtube.com/watch?v=XCLODgdCmKA&t=6000s) If you're going to ask the leaders of pharma R&D about building general models, there are innovation teams working on this. But as a general trend, modern pharmas are a bit like venture capital firms. They have divisions of external innovation -- the corp dev version of venture capital. They let a number of smaller, nimble firms explore the risky early-stage work, and then partner with them when something promising emerges.

[1:40:36](https://www.youtube.com/watch?v=XCLODgdCmKA&t=6036s) The industry has bifurcated into small biotechs that take on most of the early discovery, and large pharma that runs the trials. Something like 70% of all drugs currently entering clinical trials were originally discovered by small biotechs rather than large pharma. Most of the dollars of R&D spend are on the balance sheets of large pharmas, but the ideas are coming from small companies. Another level of disintermediation. The big pharma R&D cost is running the trials, where a lot of the costs are incurred.

[1:41:08](https://www.youtube.com/watch?v=XCLODgdCmKA&t=6068s) You can think of the market structure like a handful of large buyers in your ecosystem, and then smaller firms are working on early-stage assets. It's a limited number of buyers for a very specific product -- a therapeutic asset that is ready for clinical trials. There's a liquid market for these phase transitions. By contrast, for instance, Roche's R&D is currently run by Aviv Regev, one of the co-inventors of Perturb-seq, who's a thousand times smarter than me. She's building the technology and has a big group working on it. So it's not like every pharma takes the hands-off approach -- some are very much investing in the next generation of tools. Full disclosure, I am a small investor in NewLimit, but that did not influence the decision to have Jacob on the podcast. Jacob, thanks so much for coming on.
