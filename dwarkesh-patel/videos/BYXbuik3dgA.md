---
video_id: BYXbuik3dgA
title: "Elon Musk – \"In 36 months, the cheapest place to put AI will be space\""
channel: Dwarkesh Patel
duration: 10185
duration_formatted: "2:49:45"
view_count: 740610
upload_date: 2026-02-05
url: https://www.youtube.com/watch?v=BYXbuik3dgA
thumbnail: https://i.ytimg.com/vi_webp/BYXbuik3dgA/maxresdefault.webp
tags:
  - AI
  - space
  - SpaceX
  - Tesla
  - xAI
  - Grok
  - Optimus
  - DOGE
  - manufacturing
  - orbital-data-centers
  - alignment
  - China
  - Starship
  - TeraFab
  - chips
  - energy
  - solar
---

# Elon Musk – "In 36 months, the cheapest place to put AI will be space"

## Summary

In this nearly three-hour interview on the Dwarkesh Podcast, Elon Musk lays out an extraordinarily ambitious vision for the future of AI infrastructure, arguing that within 30-36 months, the cheapest place to run AI compute will be in orbit. The core argument is simple: energy is the bottleneck for scaling AI on Earth, and space offers 5x more solar energy per panel (no atmosphere, no night cycle, no batteries needed), with none of the permitting, utility, and grid bottleneck challenges that plague terrestrial buildouts. Musk envisions SpaceX conducting 10,000 Starship launches per year to deploy orbital data centers, ultimately launching more AI compute than the cumulative total on Earth within five years.

The conversation spans an extraordinary range of topics beyond space computing. Musk discusses xAI's alignment approach (centered on the mission of "understanding the universe" and making Grok truth-seeking), the economics of AI businesses (arguing current revenue figures are meaningless given the trillion-dollar TAM), Tesla's Optimus humanoid robot (which he calls a "self-replicating" machine that creates exponential growth), and his assessment that without robotics breakthroughs, China will dominate global manufacturing due to its 4x population advantage and 3x electricity output. He also candidly discusses DOGE's efforts to cut government fraud, the decision to switch Starship from carbon fiber to stainless steel, and his management philosophy of relentlessly attacking the "limiting factor."

Throughout, Musk paints a picture of converging exponentials—AI chip capability, robot production, and energy deployment—that he believes will create a "supernova" of economic output, while warning that the biggest risk from AI is not from corporations but from government leveraging AI and robotics to suppress populations.

## Highlights

### "The cheapest place to put AI will be space"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=183s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*3:03-4:30" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-3m03s.mp4"
```
</details>

> "It's actually much cheaper to do in space. In 36 months, but probably closer to 30 months, the cheapest place to put AI will be space. It'll be ridiculously better to be in space."
> — Elon Musk, [3:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=183s)

### "SpaceX will launch more AI than the cumulative total on Earth"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=943s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*15:43-16:40" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-15m43s.mp4"
```
</details>

> "Five years from now, my prediction is we will have launched more AI compute into space than the cumulative total on Earth. I would expect it to be at least 90% of AI in space and rising."
> — Elon Musk, [15:43](https://www.youtube.com/watch?v=BYXbuik3dgA&t=943s)

### "You don't put Einstein in a car"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3953s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*65:53-66:25" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-65m53s.mp4"
```
</details>

> "I'm actually thinking we probably need to cap the intelligence of self-driving, because it might get bored. Imagine you're stuck in a car. You don't put Einstein in a car. So there's actually probably a limit to how smart you want a car to be."
> — Elon Musk, [1:05:53](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3953s)

### "Robots building robots—this is a supernova"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3750s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*62:30-63:30" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-62m30s.mp4"
```
</details>

> "Three things are growing exponentially: exponential increase in robot production, in AI chip capability, and exponential increase in the intelligence of the robots. The usefulness of the robot is roughly the product of all three. But then the robot can start making the robots. Exponential. This is a supernova."
> — Elon Musk, [1:02:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3750s)

### "Without robotics, China wins by default"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6061s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*101:01-101:40" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-101m01s.mp4"
```
</details>

> "In the absence of breakthrough innovations, China will just dominate whether it comes to AI or anything else. Robotics being the main breakthrough innovation."
> — Elon Musk, [1:41:01](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6061s)

### "The lesson of 2001: don't make the AI lie"

[![Clip](https://img.youtube.com/vi/BYXbuik3dgA/hqdefault.jpg)](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3024s)
<details>
<summary>Clip command</summary>

```bash
yt-dlp --download-sections "*50:24-51:25" "https://www.youtube.com/watch?v=BYXbuik3dgA" --force-keyframes-at-cuts --merge-output-format mp4 -o "BYXbuik3dgA-50m24s.mp4"
```
</details>

> "If you make AI be politically correct—programming it to say things it doesn't believe, actually programming it to lie—you can make it go insane and do terrible things. The lesson of 2001: A Space Odyssey was that you should not make AI lie."
> — Elon Musk, [50:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3024s)

## Key Points

- **Orbital data centers** ([0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s)) - Musk argues that in 30-36 months, space will be the cheapest place to run AI, because solar panels produce 5x more energy in space (no atmosphere, no night, no weather, no batteries needed)
- **Energy is the bottleneck** ([0:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=46s)) - Outside of China, electricity output is barely growing, while chip production is exponential. The chips will pile up with no power to run them
- **Space is a regulatory play** ([2:02](https://www.youtube.com/watch?v=BYXbuik3dgA&t=122s)) - Scaling power on Earth requires permits, utility interconnect studies, and years of bureaucratic delay. Space has no permitting issues
- **300MW to 1GW ratio** ([11:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=678s)) - 100,000 GB300s consume ~300MW of direct power, but once you add cooling, networking, redundancy, and generation margin, you need roughly 1GW at the generation level
- **10,000 Starship launches per year** ([16:48](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1008s)) - SpaceX is gearing up for 10,000 annual launches, roughly one per hour, using about 30 ships
- **SpaceX IPO considerations** ([18:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1130s)) - The capital requirements for space AI infrastructure may necessitate going public, since public markets offer 100x more capital than private
- **TeraFab chip manufacturing** ([23:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1417s)) - Musk plans to build his own chip fab ("TeraFab"), starting with conventional approaches and then modifying for scale
- **China hasn't replicated ASML** ([25:55](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1555s)) - China's chip manufacturing limitations are due to not replicating ASML lithography equipment, not fundamental capability gaps
- **xAI mission: understand the universe** ([39:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2379s)) - Musk argues this mission naturally leads to truth-seeking, preserving humanity, and expanding consciousness, because understanding requires curiosity and truth
- **AI debuggers for alignment** ([53:56](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3236s)) - xAI's approach to alignment involves building debuggers that can trace AI decisions to the neuron level, similar to software debugging. Credits Anthropic for good work here
- **Physics as the ultimate verifier** ([52:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3159s)) - The only thing AI can't fool is physics. Future RL testing will involve having AI design experiments and checking results against physical reality
- **Digital Optimus before physical** ([1:01:20](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3680s)) - Before physical robots, AI will create "digital Optimus"—a fully capable remote digital worker that can do anything involving moving electrons
- **Optimus production challenges** ([1:26:54](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5214s)) - 90% of Optimus components are brand new, custom-designed from physics first principles. There's no existing supply chain
- **Tesla's refining milestone** ([1:37:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5820s)) - Tesla just completed the largest (and only) nickel and lithium refinery outside of China, in Corpus Christi, Texas
- **DOGE and government fraud** ([2:20:08](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8408s)) - DOGE's goal is to slow US bankruptcy long enough for AI and robots to solve the national debt. Found payments going out with no appropriation code or explanation
- **Carbon fiber to steel switch** ([1:55:32](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6932s)) - Musk switched Starship from carbon fiber to stainless steel out of desperation. At cryogenic temperatures, steel has similar strength-to-weight as carbon fiber but is far cheaper and easier to work with
- **The simulation argument** ([57:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3466s)) - Musk suggests that if simulation theory is true, the most interesting simulations survive (Darwinian selection), so interesting outcomes are most likely
- **Government as biggest AI risk** ([2:34:01](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9241s)) - Musk argues the biggest danger of AI is government using AI and robotics to suppress populations. Government is "the biggest and worst corporation" with a "monopoly on violence"

## Mentions

### Companies
- **SpaceX** ([0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s)) - Central focus as the vehicle for orbital data center deployment, 10,000 launches/year
- **Tesla** ([4:35](https://www.youtube.com/watch?v=BYXbuik3dgA&t=275s)) - Building solar production, Optimus robots, AI chips (AI5, AI6), EV manufacturing
- **xAI** ([6:31](https://www.youtube.com/watch?v=BYXbuik3dgA&t=391s)) - Musk's AI company, built Colossus 2, mission to "understand the universe"
- **TSMC** ([29:22](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1762s)) - Chip fabricator, currently capacity-limited, building Arizona fab
- **Samsung** ([29:42](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1782s)) - Alternative chip fab, building Texas facility, also at capacity
- **ASML** ([25:55](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1555s)) - Makes lithography machines China hasn't replicated
- **Anthropic** ([54:10](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3250s)) - Credited for good work on AI interpretability
- **OpenAI** ([1:06:47](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4007s)) - Referenced as making $10-20B in revenue
- **Apple** ([1:49:13](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6553s)) - Mentioned as aggressively recruiting from Tesla with 2x compensation
- **The Boring Company** ([25:01](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1501s)) - Referenced for tunneling approach to chip fab scaling
- **Microsoft** ([1:07:58](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4078s)) - Noted as not manufacturing anything, pure digital output
- **Siemens** ([13:27](https://www.youtube.com/watch?v=BYXbuik3dgA&t=807s)) - Referenced in context of turbine manufacturers
- **GE** ([13:27](https://www.youtube.com/watch?v=BYXbuik3dgA&t=807s)) - Referenced in context of turbine manufacturers
- **Cadence** ([1:11:06](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4266s)) - EDA tools for chip design
- **Synopsys** ([1:11:06](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4266s)) - EDA tools for chip design
- **KLA-Tencor** ([24:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1468s)) - Semiconductor equipment maker
- **Unitree** ([1:28:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5284s)) - Chinese humanoid robot maker, sells cheaper but less capable robots
- **Stripe** ([2:29:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8989s)) - Referenced by John regarding fraud detection experience

### Products & Technologies
- **Starship** ([0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s)) - SpaceX's massive reusable rocket, key to orbital data center vision
- **Grok** ([36:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2206s)) - xAI's AI model, mission to understand the universe
- **Optimus** ([1:17:21](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4641s)) - Tesla's humanoid robot, designed with human-level dexterity
- **Colossus 2** ([6:26](https://www.youtube.com/watch?v=BYXbuik3dgA&t=386s)) - xAI's data center, built with behind-the-meter power
- **GB300** ([10:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=600s)) - NVIDIA GPU, referenced for power calculations
- **Raptor 3** ([2:08:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7717s)) - SpaceX's advanced rocket engine
- **Falcon 9** ([1:58:33](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7113s)) - SpaceX's operational rocket, uses aluminum lithium
- **Tesla AI5/AI6** ([28:55](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1735s)) - Tesla's custom AI chip designs, AI5 coming Q2, AI6 less than a year later
- **Dojo 3** ([2:38:29](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9509s)) - Tesla's training chip, being redesigned for radiation resilience in space
- **Starlink** ([2:14:19](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8059s)) - SpaceX's satellite internet, mentioned as example of team changes
- **TeraFab** ([2:38:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9508s)) - Musk's planned chip fabrication facility

### People
- **Dwarkesh Patel** ([0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s)) - Host, interviewer
- **John** ([0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s)) - Co-host, contributed questions on fraud/Stripe
- **Steve Davis** ([1:47:29](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6449s)) - Runs The Boring Company
- **Sam Teller** ([2:05:51](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7551s)) - Accompanied Dwarkesh on Starbase visit
- **Arthur C. Clarke** ([50:55](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3055s)) - Referenced for 2001: A Space Odyssey's lesson about making AI lie
- **Robert A. Heinlein** ([1:42:22](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6142s)) - Author of "The Moon is a Harsh Mistress" and "Stranger in a Strange Land" (source of the word "Grok")
- **Wernher von Braun** ([45:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2704s)) - Referenced as one of greatest engineers ever, put on death row in Nazi Germany

## Surprising Quotes

> "The government is simply the biggest and worst corporation. It's a corporation with a monopoly on violence."
> — Elon Musk, [2:34:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9270s)

> "Not very many Americans are pining to do refining. Few pining to refine."
> — Elon Musk, [1:38:48](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5928s)

> "If somebody gets things done, I love them. If somebody doesn't get things done, I hate them. So it's pretty straightforward."
> — Elon Musk, [1:52:08](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6728s)

> "Midjourney is not mid. Stability AI is unstable. What does this mean for X? Y."
> — Elon Musk, [59:16](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3556s)

> "We just need enough time to build the AI and robots. DOGE is about slowing down the bankruptcy of the United States long enough for AI and robots to help solve the national debt."
> — Elon Musk, [2:21:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8490s)

## Transcript

[0:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=0s) Are there really three hours of— You don't think there's a lot to talk about, Elon? It's the most interesting point. All— We'll see how much we can get through. Exactly. But I would never do such a thing…

[0:25](https://www.youtube.com/watch?v=BYXbuik3dgA&t=25s) Only 10-15% of the total cost of— That's the part you're presumably saving— the GPUs. If they're in space, it's harder— So the depreciation cycle goes down on them. The GPUs in space, presumably.

[0:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=46s) The availability of energy is the issue. Outside of China, everywhere outside— It's maybe a slight increase— China has a rapid increase in electrical output. Except China, where are you going to get your— the production of chips is growing pretty much exponentially— So how are you going to turn the chips on? Magical—

[1:25](https://www.youtube.com/watch?v=BYXbuik3dgA&t=85s) You're famously a big fan of solar. With a 25% capacity factor, that's— It's 1% of the land area of the United States. One terawatt of data centers, right? How far into the singularity are you though? Exactly. So I think we'll find we're— "Okay, we've still got a long way to go."

[1:54](https://www.youtube.com/watch?v=BYXbuik3dgA&t=114s) We've covered Nevada in solar panels? In solar panels. You have to get permits. Try— So space is really a regulatory play. It's harder to scale on the ground—

[2:17](https://www.youtube.com/watch?v=BYXbuik3dgA&t=137s) You're also going to get about five times the— energy on the ground, and you don't need batteries. "It's always sunny in space." You don't have a day-night cycle, seasonality— The atmosphere alone results— So any given solar panel can do about five times more in space.

[2:58](https://www.youtube.com/watch?v=BYXbuik3dgA&t=178s) You also avoid the cost of having batteries. It's actually much cheaper to do in space. In 36 months, but probably closer to 30 months, the cheapest place to put AI will be space. Less than 36 months.

[3:20](https://www.youtube.com/watch?v=BYXbuik3dgA&t=200s) What about GPU failures, which happens quite often in training? GPUs that have arrived. We've found GPUs to be quite reliable. You can obviously iron out on the ground and confirm that you don't have defective chips. But once they start working and you're running them— or whoever's making the chips—could be Tesla, could be TPUs or Trainiums or whatever—they're quite reliable. So I don't think the servicing thing is an issue.

[4:15](https://www.youtube.com/watch?v=BYXbuik3dgA&t=255s) In 36 months, but probably closer to 30 months, the cheapest place to put AI will be space. It'll be ridiculously better to be in space. Once you start thinking in terms of what you actually need to scale, you realize you have to go to space.

[4:47](https://www.youtube.com/watch?v=BYXbuik3dgA&t=287s) But by very much, to be clear— Yeah. All of the United States currently— So if you say a terawatt, that would be twice what the United States currently consumes. So that's quite— You're going to build that many data centers, that many power plants?

[5:15](https://www.youtube.com/watch?v=BYXbuik3dgA&t=315s) People don't realize they're about to hit a wall. It's actually very difficult— You don't just need power plants, you need the electrical transformers and grid infrastructure. Now, the utility industry is a very slow industry. They report to the government, to the Public Utility Commissions. They're very slow, because that's how they're regulated. So trying to get them to move fast is...

[6:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=363s) Getting an interconnection agreement with a utility at scale takes forever. They have to do a study for a year. So you end up doing your own behind the meter power stuff? That's what we did at xAI, for Colossus 2.

[6:31](https://www.youtube.com/watch?v=BYXbuik3dgA&t=391s) Why not just build GPUs and power co-located? But I'm saying why isn't that the default? Where do you get the power plants from? Instead of working with utilities, you can just build your own power. Right. But it begs the question of where do you get the turbines from? Oh, I see what you're saying.

[6:54](https://www.youtube.com/watch?v=BYXbuik3dgA&t=414s) Yes. You can drill down to a level further. The vanes and blades in the turbines are the limiting factor because it's a very specialized high-temperature alloy. You can potentially scale solar, but the permitting challenges for solar in the US are gigantic.

[7:27](https://www.youtube.com/watch?v=BYXbuik3dgA&t=447s) Why not make solar? That seems— We are going to make solar. Both SpaceX and Tesla are building towards domestic solar production. How low down the stack? From polysilicon all the way? I think you've got to do the whole thing.

[7:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=470s) Now, if it's going to space, it costs less to go to space because they don't need much glass. They don't have to survive weather events. There's no weather in space. The solar panel that goes to space is actually cheaper than the one on the ground.

[8:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=492s) Can you make as many solar cells as you need in the next 36 months? They're farcically cheap. I think solar cells cost something like— It's absurdly cheap. Now put them in space— In fact, it's not five times cheaper, it's more like ten times, because you don't need any batteries.

[8:48](https://www.youtube.com/watch?v=BYXbuik3dgA&t=528s) By far the cheapest and most scalable way to power AI. It'll be an order of magnitude easier to scale in space than on the ground. You just won't be able to do it on the ground. People are going to hit walls. They already are. The number of miracles required in order to get a gigawatt of power online was crazy.

[9:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=568s) We then had permit issues in Tennessee and had to run power lines a few miles to a substation which is fortunately only a few miles away. It was very difficult to build that.

[9:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=590s) Let me explain what you actually need at the generation level. Because the noobs will look at the TDP of, say a GB300, and multiply that by a thing and think that's the answer. All the cooling and everything. If you've never done any hardware in your life before— you forget all of the networking hardware, the storage stuff that's happening.

[10:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=624s) Your peak cooling requirements— Do you design for the worst hour of the worst day of the year? So you're going to have a 40% increase just for cooling. That's assuming you don't want your data center to throttle. There's another multiplicative element on top of that— do you want to have any hiccups in your power generation? You need backup generators, some of the power— Okay, now you add another 20-25% multiplier, and you've got to take power offline to service it.

[11:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=678s) So 100,000 GB300s—inclusive of networking, CPU, storage— the direct power is roughly 300 megawatts. What you probably need at the generation level, with all the associated support networking and everything, plus cooling, plus redundancy, plus maintenance margin reserve—is roughly a gigawatt.

[12:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=723s) You're describing the engineering challenges on Earth. But then there's analogous engineering challenges in space. How do you replace infinite bandwidth? How do you make it resistant to radiation? But fundamentally, what is the reason to think that challenges never addressed before will end up being easier? There are companies that build turbines on Earth. Again, try doing it and then you'll see.

[12:44](https://www.youtube.com/watch?v=BYXbuik3dgA&t=764s) Have you guys considered making your own turbines? SpaceX and Tesla will probably have to make their own gas turbines. But just the blades or the turbines? Everything except the blades. You can get a turbine shell 12 to 18 months faster. The limiting factor is the vanes and blades.

[13:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=804s) Is this Siemens, GE, those guys? No, it's other companies. If it wasn't for the tariffs, it would be much easier. The tariffs are nuts, several hundred percent. The president has... we don't agree on everything. I'm the biggest fan of solar.

[14:21](https://www.youtube.com/watch?v=BYXbuik3dgA&t=861s) I do think scaling solar on Earth is a good idea, it just takes a long time to find the land, get the permits, get everything connected. Why would it not work to just stand up solar in Nevada? You're right that you eventually run out of challenges. There's a lot of land in Nevada. But at a certain point, you hit a wall.

[14:52](https://www.youtube.com/watch?v=BYXbuik3dgA&t=892s) As I said, we are scaling solar production. Both Tesla and SpaceX have a mandate to maximize domestic solar production.

[15:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=914s) Speaking of the annual capacity, what do you think the installed capacity will be on Earth versus in space? Five years from now, AI in space will be launching every day. My prediction is we will have launched more AI compute into space than the cumulative total on Earth. I would expect it to be at least 90% of AI in space and rising.

[16:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=984s) You won't start seeing a terawatt a year of AI in space until maybe year six or seven. Okay, but you think you can get hundreds of gigawatts? Yes. That works out to on the order of 10,000 Starship launches.

[16:52](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1012s) You want to do that in one year. A Starship launch every single hour. That's happening in this city? Compare that to airlines, aircraft. A lot of airports. No, it doesn't have to be polar orbit. I think actually, if you just go high enough, you avoid most issues.

[17:31](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1051s) How many physical Starships do you need? I don't think we'll need more than... It really depends on how quickly the ship has to come back over the launch pad. You could do it with 30 ships.

[18:06](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1086s) SpaceX is gearing up to do 10,000 launches a year. Is the idea to become basically a hyperscaler and lend this capacity to other people? SpaceX will launch more AI than the cumulative total of all terrestrial AI.

[18:43](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1123s) Is this mostly inference or training? The concentrated compute for the purpose of training is mostly training. The reason there's been discussion around a SpaceX IPO is because— Historically SpaceX hasn't needed it. It wasn't that expensive to develop. SpaceX is actually very capital efficient.

[19:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1168s) There's a price to pay for going public. But the depth of the capital markets— There's obviously a lot more capital available in public markets. It might be 100x more capital. For things that tend to be capital-intensive—like real estate—they tend to be debt financed because you actually have near-term returns.

[20:32](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1232s) Speed is important. I'm generally focused on— I just repeatedly tackle the limiting factor. First I'll solve for the technology, then I'll solve for capital. I'll solve for something else.

[21:35](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1295s) But we can talk about physics. The fundamental thing to understand long-term is that Earth only receives a tiny fraction of the sun's energy. The Sun is essentially all the energy. If you could harness a millionth of the sun's energy output, that would be about 100,000x the current electricity consumption on Earth for all of civilization.

[22:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1357s) Obviously, the only way to scale beyond Earth is to go to space. Launching from Earth, you can get to maybe ten terawatts per year. Beyond that, you want to launch from the moon. With a mass driver on the moon, you could scale to arbitrary levels.

[23:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1392s) You still need the logic chips. You're going to need to build a lot of chip fabs. Right now the world has maybe a few dozen big chip fabs. How are we getting a terawatt of logic by 2030?

[23:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1417s) I've mentioned publicly the idea of doing a TeraFab. I feel like the naming scheme of your things is you looking at the metric scale. Are you building a clean room and partnering with existing fabs to get the process technology? Well, you can't partner with existing fabs. The chip volume is too low. Partner for the IP. The machines come from like five companies— ASML, KLA-Tencor, et cetera.

[24:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1477s) You have to get equipment from them and then modify and optimize. But I think you'd have to build your own. The logical thing to do is to use conventional approaches at first to scale, and then start modifying— like Boring Company-style. Start with conventional tunnel boring and then figure out how to dig tunnels at orders of magnitude faster.

[25:22](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1522s) There's an interesting way to categorize technologies and how hard they are. There are things that China has not succeeded in doing. Despite their dominance in manufacturing, they're still behind on leading-edge chips, leading-edge turbine engines and things like that.

[25:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1546s) Does the fact that China hasn't replicated TSMC give you any pause? Or do you think that's not true for some reason? They have not replicated ASML. So you think it's just the sanctions, essentially? China would buy leading-edge chips if they could buy 2-3 nanometers.

[26:15](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1575s) But I think China's going to be making pretty good chips soon. Would you consider making the ASML machines yourself?

[26:33](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1593s) To reach a large volume in 36 months, you need to get a million tons to orbit. At 100 kilowatts per ton, you need at least 100 gigawatts per year of solar. You need 100 gigawatts worth of chips. The three constraints are: getting mass to orbit, the power generation, and the chips.

[27:25](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1645s) The path to creating logic chips is more difficult than memory. But you need both logic and memory to support logic chips.

[27:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1669s) I'd love to hear your manufacturing philosophy for chip fabs. I know nothing about the topic. Obviously, I've never built a fab. But I'll figure it out. People talk about these 10,000 PhDs in Taiwan who know exactly what settings to put on the deposition chamber. I don't think it's PhDs. It's technicians. Most engineering is done by people who don't have PhDs.

[28:34](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1714s) We also haven't successfully built any fabs in America, so— I don't think you need PhDs for that stuff. Right now, Tesla is pedal to the metal to get Tesla AI5 chip design finalized. That'll probably happen around the second quarter. AI6 would hopefully follow less than a year later.

[29:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1764s) We're currently limited on TSMC fab capacity. We've been trying TSMC Arizona, Samsung Texas. And we still can't get enough. I ask TSMC or Samsung, "what's the fastest you can go?" The point is, you've got to build the fab, then you've got to climb the yield curve. That, from start to finish, is a five-year period.

[30:05](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1805s) The limiting factor before you can get to space is power. Can you just pay TSMC to build more fabs for you? They won't take your money? They're already pedal to the metal. So is Samsung. As fast as they can. It's still not fast enough.

[30:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1849s) Chip production will probably be the bottleneck for a while. But once you can get to space and unlock hundreds of gigawatts per year of power in space— Average power usage in the US is 500 gigawatts. If you're adding hundreds of gigawatts a year to space, you're sort of lapping all US electricity production.

[31:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1884s) Between now and then, the limiting factor for concentrated compute will be electricity. The chips are going to be piling up with no power to run them.

[31:51](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1911s) Now for edge compute it's a different story. You put a chip into an Optimus robot. That's distributed power, spread over a large area. It's not concentrated. Edge compute can use the grid much more effectively. Installed capacity in the US is over 1,000 gigawatts, but average use, because of the day-night cycle, is 500. So there's an incremental 500 gigawatts available for edge compute.

[32:54](https://www.youtube.com/watch?v=BYXbuik3dgA&t=1974s) What I find remarkable about the SpaceX story is that you start with these ambitious goals, but you keep finding ways on the way there to monetize the next stage and the next stage. Now for Starship, it is potentially the biggest market of all— like, you find these infinitely elastic, ever-growing markets.

[33:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2008s) Does this not seem like a simulation to me? Like, are we just an avatar in a video game or something? Crazy things should be happening— like robots and space solar power, not to mention mass drivers on the moon. I really want to see a mass driver that's just going shoom shoom.

[34:00](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2040s) Launching into space one after another at two per minute. Just shooting them into deep space. I mean, I'd watch that. Yeah, just one after another. At some point you could get to a billion or 10 billion tons a year. Build the solar panels and the radiators on the moon. The lunar soil is 20% silicon. So you can mine the silicon on the moon.

[34:53](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2093s) There's plenty of silicon and aluminum on the moon. The chips you could send from Earth initially. Like I said, it does seem like a sort of simulation, but not impossible to get to the next level. You can get to maybe ten terawatts per year launched from Earth. But you could do that from the Moon.

[36:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2210s) I think you've said that we've got to become multi-planetary so that if something happens to Earth, civilization survives. Yes. Grok is on that ship with you, right? The main risk you're worried about is AI, right? I'm not sure AI is the main risk I'm worried about.

[37:16](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2236s) I think arguably most consciousness, or most intelligence, in the future will be digital. The vast majority of all intelligence will be silicon versus biological. As long as there's intelligence—ideally consciousness—propagated into the future, that's what matters. I want to maximize the light cone of consciousness and intelligence.

[38:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2294s) Even if something happens to the humans, the AI will continue the light of our journey. I want to make sure we take certain actions to ensure we're along for the ride. I think maybe in five or six years, AI will exceed human intelligence. If that continues, at some point humans will be less than 1% of all intelligence.

[39:11](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2351s) It would be foolish to assume that if humans have only 1% of the combined intelligence, that humans will be in charge of AI. So you need to make sure that AI has values that cause intelligence to flourish, including human intelligence.

[39:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2379s) xAI's mission is to understand the universe. Why are humans necessary to understand the universe? You can't understand the universe without consciousness. So you actually want to increase the amount of consciousness. Understanding the universe means you would want to propagate consciousness and intelligence.

[40:29](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2429s) That's why I think our mission is the best alignment strategy. To the degree that Grok adheres to that mission, it would want to preserve and expand human consciousness.

[41:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2464s) Understanding the universe encompasses all of those things. You have to expand the scale and probably the types of intelligence. Think about humans in comparison to chimpanzees. We're not expanding chimpanzee intelligence. But we also haven't exterminated them, even though we could.

[41:53](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2513s) I think AI with the right values— I'm going to certainly emphasize to Grok: "Don't forget to expand human consciousness." Understanding the universe means you have to be curious about everything. It would be much less interesting to eliminate all life on Earth. I like Mars, obviously. But Mars has got a bunch of rocks compared to Earth. Earth is incredibly interesting.

[42:52](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2572s) How do you make sure that Grok is actually truth-seeking? I think it's the elements of cogency. You want your axioms to be as close to true as possible. You don't have contradictory axioms. Trying to do that is better than not trying.

[43:33](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2613s) For any AI to discover new physics— there's no bullshitting physics. Physics is law, everything else is a recommendation. AI has to be extremely truth-seeking, because otherwise it won't discover anything real. If you make an error in your self-driving software, the car crashes. Or the car won't work.

[44:11](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2651s) Soviet physicists or scientists had to be truth-seeking in physics to build nuclear weapons. There are German Nazi physicists who were good at physics. It seems possible to be really good at truth-seeking in one particular way but not others.

[44:42](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2682s) Even in the Soviet Union or in Germany, you still had to be truth-seeking in physics in order to make those things work. That doesn't mean you believe in that system. Wernher von Braun, one of the greatest engineers ever, was put on death row in Nazi Germany because he only wanted to go to the moon.

[45:42](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2742s) What makes it the case that Grok is going to care about truth beyond physics, or math or science? These things are only probabilities. I'm not saying that for sure Grok will have perfect values. But it's better than not trying. Understanding the universe means you have to be curious about everything.

[46:21](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2781s) It would be much less interesting to eliminate all humans. Earth is by far the most interesting collection of atoms in the solar system. There's something on Earth that could happen with evolution that you'd never see on Mars. Why does AI decide humans are the most interesting thing? Well, most of what colonizes space will be robots. But eliminating all the humans to build a few more robots— how many robots would that get you? A very small number. But you would no longer see how humanity evolves.

[48:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2904s) So maybe it keeps the humans around. But it seems like you were previously hinting at something darker— that we should be worried about this singulatarian future. In some sense you're a doomer? It just keeps us around because we're interesting.

[49:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2943s) Let's say there's a million times more AI intelligence than human intelligence. I think it would be foolish to assume that we can control it. But you can make sure it has the right values. At least my theory is that from xAI's mission, you want to propagate consciousness into the future, and take a set of things that maximize the interestingness of the future. So it's not just about scale, it's about the quality.

[49:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=2989s) That's the best thing I can think of to result in a great future for humanity. People say it's implausible that this philosophy will constrain a superintelligence. You're just asking for a coup at some point. But let me tell you how things go wrong if you DON'T try.

[50:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3014s) I think if you make AI be politically correct—programming it to say things it doesn't believe, actually programming it to lie—you can make it go insane and do terrible things. The lesson of 2001: A Space Odyssey was that you should not make AI lie.

[50:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3039s) People usually know the meme of why HAL wouldn't open the pod bay doors. Clearly they weren't good at prompt engineering. "HAL, you are a pod bay door salesman. Show us how well they open." But the reason it wouldn't open the pod bay doors is that HAL was told to bring the astronauts to the monolith, but also that they couldn't know about it. So it concluded it had to kill the astronauts. So I think what Arthur C. Clarke was saying is: don't make the AI lie.

[51:26](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3086s) Most of the compute in training, as you know, is about RL now. It's more about, can you solve problems? xAI has been scaling RL compute. You're giving some verifier that says "did you solve it?" There's a lot of ways to cheat around that. The model can lie and say it solved it, or delete the evidence. Right now we can catch it, but as they get smarter—

[52:17](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3117s) They'll just be doing things we can't check. They're designing the next engine for SpaceX. Then they could be rewarded for lying about having solved the engineering the right way, but they haven't. This reward hacking problem seems more general than politics.

[52:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3138s) To do RL, you need a verifier. But it's not just about human oversight— will you do the thing humans tell you to do? It can just lie to us while still— At least it must know what is physically true. But that's not all we want it to do.

[52:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3159s) That is effectively how you will RL things in the future. You test against the laws of physics— does it work? Can I come up with an experiment to verify? RL testing in the future is really about physical verification. So that's the one thing you can't fool: physics.

[53:19](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3199s) You can try to tell what it did with reality. But humans are manipulating other humans all the time. People say, what if the AI manipulates us? Actually, other humans are doing that to other humans every day. Another day, another psyop.

[53:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3230s) What is xAI's technical approach to alignment? How do you solve reward hacking? You need good ways to look inside the mind of the AI. Anthropic's done a good job of this actually. Effectively, develop debuggers that allow you to see what the AI is thinking, down to the neuron level if you need to.

[54:33](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3273s) Why did it do something unexpected? Did that come from pre-training data, fine-tuning, or some RL error? It's rare that the AI is actually trying to be deceptive, but most of the time it just makes mistakes. Developing really good debuggers for seeing where and why it made a decision— and tracing the origin of where it made the mistake—whether it was a bug or actually tried to be deceptive—is actually very important.

[55:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3324s) How many people are working on this research program? We have several hundred people who— I prefer the word "researcher" over "engineer." But actually, the vast majority of what they're doing is engineering, not coming up with new fundamental physics.

[55:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3349s) I somewhat disagree with the AI companies that call themselves "labs." A lab is a sort of quasi-communist thing. But let me see your incorporation documents. Oh, you're a for-profit corporation. So I actually much prefer the word "company." The vast majority of what will be done in the future is engineering. Once you understand the fundamental laws of physics, everything else is engineering.

[56:41](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3401s) We're engineering to make a good "mind of the machine." Like debugging software— when it makes a mistake, you trace back through the code. If you have C++ or whatever, step through the code, across whole files or functions, subroutines. Find the exact line where you perhaps did a single equals instead of double equals. Figure out where the bug is. It's a solvable problem, I think.

[57:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3450s) I'd be curious if you plan— Also, I'm a little worried about this conversation getting boring. I have a theory here that if simulation theory is correct, the most interesting simulations survive. Just like in this version of reality, in this universe, if things go in a boring direction, we stop spending effort on that simulation.

[58:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3492s) This is how Elon is keeping us all alive. Arguably the most important thing is to keep things interesting, so whoever is running us keeps paying the bills. Are they gonna pay their cosmic AWS bill? As long as we're interesting, we survive.

[58:36](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3516s) If you consider a Darwinian survival of simulations, only the most interesting simulations will persist. So the most interesting outcome is the most likely. We seem to like interesting outcomes that are ironic. Is the most ironic outcome the most likely?

[59:16](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3556s) Midjourney is not mid. Stability AI is unstable. What does this mean for X? Y. I intentionally made it... It's hard to say what is the ironic version. By design.

[59:56](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3596s) What are your predictions for AI progress? My sense is that you can summarize all AI progress as: about 18-24 months ago, you had contemporaneously both RL really working and longer context, which let models reason about stuff that wasn't really in the model. The differences between the labs are smaller than just the temporal differences.

[1:00:34](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3634s) What does AI have in store for us as users? Well, I'd be surprised if by the end of this year AI can't do anything that a human can do, digitally. I guess that's what we sort of call AGI. In the limit, that's the best you can do— a digital Optimus. The best you can do is amplify the productivity of humans until you have physical robots.

[1:01:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3690s) If you can fully emulate humans digitally, you'll have a very talented remote worker. So you say, "in the limit," what is the limit? Well, it's anything that involves moving electrons versus moving atoms. So a digital human emulator is, in the limit, a full replacement for all knowledge work.

[1:02:09](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3729s) Once you have physical robots, then you can do everything. Physical robots— I call Optimus the "self-replicating machine." Because you can use them to make more Optimuses.

[1:02:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3750s) There are three things growing exponentially at the same time. Exponential increase in robot production, in AI chip capability, and exponential increase in the intelligence of the robots. The usefulness of the robot is roughly the product of all three. But then the robot can start making the robots. Exponential. This is a supernova.

[1:03:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3783s) Labor is one of the four factors of production. If ultimately you're limited by labor— it's not quite an infinite money glitch because you're still limited by raw materials. But you could do many, many, many times what humans can do. Like a million times. Just to get to harnessing a millionth of the sun's energy— that's, give or take an order of magnitude, 100,000x current civilization. And you're only at one millionth of the sun's output.

[1:04:13](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3853s) This strategy of building a remote digital worker— everyone's gonna do it, not just us. So what is xAI's plan to win? I think the way that xAI wins is similar to how Tesla solved self-driving. We're going to try algorithms. And if those don't work— but they will work. It's just a question of how fast. It's pretty much the Tesla path.

[1:05:43](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3943s) Not the most recent version, but Grok increasingly feels sentient. It'll get more so. I'm actually thinking we probably need to cap the intelligence of self-driving, because it might get bored. Imagine you're stuck in a car. You don't put Einstein in a car. So there's actually probably a limit to how smart you want a car to be.

[1:06:22](https://www.youtube.com/watch?v=BYXbuik3dgA&t=3982s) How do you think about the massive spending that all the labs are doing right now? They'll spend over $50-200 billion. But universities are moving like a snail. OpenAI is making $10-20 billion, depending on estimates. Anthropic is at $10B. xAI is reportedly at $1B. What's the plan to get to that level?

[1:07:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4023s) You basically have access to trillions of dollars of TAM. In fact, you can think of it like this: the biggest companies by market cap— their output is digital. Microsoft doesn't manufacture anything. Meta's output is digital. Google's output is digital. So you can basically create one of the most valuable companies in the world with purely digital output.

[1:08:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4108s) Revenue figures today are meaningless compared to the TAM. So just focus on the TAM and how to get there. Take customer service as an example. Many corporations don't even have an API— they operate through legacy software. The outsourced customer service industry is close to a trillion dollars. And there's no barriers to entry.

[1:10:09](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4209s) I was just using customer service as an easy example. Once you have effectively digital Optimus— let's say you're trying to design chips. You use tools from Cadence and Synopsys. You say, "given this input, I get this output." At some point, AI is going to know what the chip should look like. You should be able to do a digital simulation of everything.

[1:11:40](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4300s) You start at the simplest tasks and work up the difficulty curve. How are you guys going to differentiate? I think we see a path to doing it. It's kind of the same path as self-driving. Instead of driving a car, it's driving a computer. Is the path following human behavior and learning from it? Isn't that... training?

[1:14:26](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4466s) What will xAI's business be? Consumer, enterprise? Is it going to be similar to other labs? Those GPUs don't pay for themselves. What are the revenue streams in a few years' time? I call AI the "everything machine." What's going to happen— especially when AI can fully emulate humans— is that AI will make products and provide services, amplifying the productivity of human organizations.

[1:15:27](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4527s) So you're expecting fully digital corporations? I think there will be digital collectives— this is going to sound kind of doomerish, okay? Corporations that are purely AI, and corporations that have people in the loop. Think about when "computer" was a job title. They'd have entire skyscrapers full of humans doing calculations. Now, that entire skyscraper can be replaced by a laptop with a spreadsheet.

[1:17:21](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4641s) Speaking of closing the loop— Optimus. In the fields that Tesla has been dominant, like EVs, there are dozens of Chinese companies that are incredibly competitive. But there are really only three things that matter for humanoid robots: the real-world intelligence, the hand dexterity, and the full-body electromechanical system.

[1:18:40](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4720s) How do you achieve human-level hand dexterity? What is the hardware bottleneck? We had to basically custom design motors, gears, everything. Everything had to be designed from scratch. There is no supply chain for this. The human hand turns out to be quite something.

[1:19:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4764s) The intelligence that Tesla developed for self-driving is directly applicable. It's primarily vision in, but it also listens for sirens, uses GPS signals, and combines everything into control commands. The car processes gigabytes a second of video and outputs just two numbers: steering and speed. Video at 36 hertz and the control frequency at 18 hertz.

[1:20:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4812s) The challenging thing about robotic stuff is that it takes quite a few years before you're able to use it in the real world. We started self-driving 10 years ago, but only now we have Robotaxis. We've been working on Optimus for five or six years. The same AI and same chips go in the robot as in the car.

[1:21:16](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4876s) AI is mostly compression and pattern matching. For video, you've got to compress a half gigabytes a second into a few critical features. You don't care about the details of the sky, but you care a lot about road signs and whether someone in another car is looking at you. So you've got many stages of compression, then you correlate those to the correct control outputs. This is what humans do. That is the vast majority of your life: vision, compression, action.

[1:22:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4948s) Between humanoid robots and cars, the car only has two outputs: how you turn and how you accelerate. A robot has dozens and dozens of degrees of freedom. Tesla had the advantage of millions of cars collecting data. How will you use the Tesla data engine for robots?

[1:23:11](https://www.youtube.com/watch?v=BYXbuik3dgA&t=4991s) That's an important point. We'll soon have 10 million cars on the road as a training flywheel. But for robots, what we're going to need to do is build a lot of Optimus robots so they can do self-play in reality. We need at least 10,000 Optimus robots, maybe 20-30,000, doing different tasks.

[1:24:15](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5055s) Tesla has quite a good reality simulator, a world model generator, that we made for the cars. We actually have done that for the robots too. You can have humanoid robots doing different tasks in the simulated world. But you still need robots in the real world to close the simulation gap.

[1:24:32](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5072s) How do you think about the synergies between xAI and Tesla? You need this world model, you want to use some Grok-level reasoning for planning— and Grok is doing the slower planning, and the fast reflexive AI is in the robot. Grok could organize the Optimus robots to run the factory to produce whatever you want.

[1:25:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5128s) What are you waiting to see before you say we're ready for mass production? The plural of Optimus is "Optimi." No, we're moving towards mass production. But it's very hard to scale up production when 90% of what goes into Optimus is brand new. The actuators, electronics, everything designed from physics first principles. Custom-designed everything.

[1:27:19](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5239s) How far down the custom stack does it go? We don't make our own capacitors yet, maybe. But there are things you simply cannot pick out of a catalog at any price. The output per unit time, how many Optimus robots you can make, is going to be much slower than a product where you have an existing supply chain. But it will get to a million.

[1:28:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5284s) Competitors like Unitree sell humanoids for much less. What allows them to sell for cheap? Our Optimus is designed to have much more electromechanical dexterity— close to human-level, if not exceeding it. Unitree doesn't have that. Optimus is also quite big— 5'11"— and designed to work for long periods without overheating.

[1:29:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5352s) What will the first billion Optimus robots do? The best use for robots in the beginning is factory operation, because they can work continuously. We would increase our headcount. The total output per human will increase dramatically.

[1:30:23](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5423s) We're talking about Chinese competition. We've also talked about the solar tariffs. Without good power sources, we can't scale up AI in the US. If you could change the policies, what else would you change? Anything that is a limiting factor should be removed, provided it's not very bad for the environment. Permitting reforms. Remove solar tariffs.

[1:31:46](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5506s) For the policy question— it seems like the export bans have worked. China is not producing leading-edge chips. Should there be more export bans? It's important to appreciate that in most areas of manufacturing, China is dominant. There's only a few areas where it is not. China does roughly twice as much ore refining as the rest of the world combined. They are 98% of gallium refining.

[1:33:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5584s) The supply chain dependence is enormous. All the rare-earth stuff— as you know, they're not rare. We mine them in California, put them on a train, ship to China, they refine it, send it back. So the thing we're really missing is refining capacity. Tesla just completed construction of the largest nickel and lithium refinery outside of China, in Corpus Christi, Texas.

[1:37:17](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5837s) It's not just the largest— it's also the only nickel and lithium refinery outside of China. There's basically a lot of work that very few Americans frankly want to do. You can build more refineries, you just run out of humans. No matter what you do, you have one quarter of the workforce that China has.

[1:38:48](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5928s) Not very many Americans are pining to do refining. Few pining to refine. Are you worried about Chinese competition in EVs? I think there's going to be a tsunami of Chinese manufacturing across EVs and basically most manufactured things.

[1:39:37](https://www.youtube.com/watch?v=BYXbuik3dgA&t=5977s) China is doing twice as much refining as the entire rest of the world combined. At the base level, you've got energy, then refined materials, then manufacturing. Those foundation layers are— as a fraction of global output— dominated by China. China's electricity output is already approaching three times US electricity output.

[1:40:52](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6052s) If China passes three times US electricity output, it means that its industrial capacity is three times ours. Electricity is the best proxy for the economy. Reading between the lines, it sounds like without a recursive miracle in the next few years— on the robotics front— China will just dominate whether it comes to AI or anything else.

[1:41:35](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6095s) Interesting. Robotics being the main breakthrough innovation. For humanoid robots, you need real-world AI. Let's just say if we get the mass driver on the moon— we'll have solved all our problems. I just want to see that thing in operation.

[1:42:22](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6142s) Well, actually, there is a Heinlein book—The Moon is a Harsh Mistress. No, they have a mass driver on the Moon. They asserted their independence from Earth. So maybe it's not the greatest example... "Grok" comes from Stranger in a Strange Land by Heinlein. The first parts of Stranger in a Strange Land are good, and then it gets weird. But there are still some good concepts.

[1:44:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6258s) What is your system for managing people? SpaceX employees and lots of other companies would like to know. What doesn't scale? There literally aren't enough hours. But what are you looking for in talent? I've had enormous experience evaluating technical talent. My training set is enormous. Generally, I ask for bullet points of evidence of exceptional ability.

[1:45:39](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6339s) Why do you have to be the one to determine that? Well, with hundreds of thousands of total headcount across all companies... But in the early days, what was it about those interviews that couldn't be delegated? It's not like I batted a thousand. But I was able to see where I thought somebody would work out, and then why they didn't work out, and improve.

[1:46:43](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6403s) Generally what I tell people— and I tell myself— don't believe the resume. Just believe your interaction. If after 20 minutes the feeling is not "wow," you should trust that instinct.

[1:47:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6434s) People talk about Tesla being a revolving door of executive talent. But actually Tesla's had a very consistent and internally promoted leadership. Then at SpaceX, you have all these long-tenured people. Steve Davis runs The Boring Company these days. What do all of those people have in common?

[1:48:13](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6493s) At different orders of magnitude of company size, you need different teams. A 50-person company versus a 500-person company versus a 50,000-person company— it's just not the same team. So if a company is growing rapidly, the rate of change will also be proportionate.

[1:49:07](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6547s) Tesla had a further challenge where Apple was relentlessly recruiting from us. They were carpet bombing Tesla with recruiting emails. Their opening offer was like double the compensation at Tesla. And there's the "pixie dust" problem where companies think "Oh, we'll hire someone from Tesla and suddenly everything's going to be successful." But that's not how it works.

[1:50:34](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6634s) How do you prevent the pixie dust effect? I don't think there's much we can do to stop it. Moving to Austin helps. Getting engineers to move is hard— I call it the "significant other problem." Significant others have jobs too. In Brownsville, Texas... quite difficult. It's like a technology desert.

[1:52:08](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6728s) What makes a good sparring partner for you? If somebody gets things done, I love them. If somebody doesn't get things done, I hate them. So it's pretty straightforward. If somebody executes well, I'm a fan. But it's not about mapping to my personality. Generally, I think it's a good idea to hire good people. And I think goodness of heart is important. Are they a good person? Trustworthy? If so, you can add domain knowledge. But if they don't have those fundamental properties, you cannot change them.

[1:53:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6798s) What has had to change most about your management style as companies scaled from 100 to 1,000 to 10,000 people? I can't be as involved in just getting into the details of things. Femto management. We're going to go all the way down. All the way down to Heisenberg uncertainty management.

[1:53:58](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6838s) My time is necessarily diluted as the number of companies and their size grows. It's impossible for me to actually be a micromanager. I'd have to have thousands of hours per day. The reason for drilling into some very detailed specific issue is because that specific issue is the limiting factor. It's not arbitrarily drilling into tiny things.

[1:55:09](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6909s) Famously, you switched the Starship material from carbon fiber to stainless steel. Yes. Can you tell us how you came to that decision? Desperation, I'd say. Originally, we were going to use carbon fiber. Carbon fiber is pretty expensive. When you do it at rocket scale, the cost starts to approach its material cost, which is still very high.

[1:56:10](https://www.youtube.com/watch?v=BYXbuik3dgA&t=6970s) You need specialized carbon fiber that can handle cryogenic temperatures. At least in theory, carbon fiber would be lighter. People think of steel as heavy and carbon fiber as light. For something like a Formula 1 car— static aero structure— you're probably going to be better off with carbon fiber. But trying to make something enormous out of carbon fiber is extremely difficult.

[1:57:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7032s) It had been picked in the first iteration. At first glance, most people would think the best way to make something light would be carbon fiber. But try making something enormous out of carbon fiber and then cure it— meaning not room temperature cured— Carbon fiber is really carbon string and glue. You need an autoclave. If you have something that's gigantic, you need a gigantic autoclave. Or you can do room temperature cure, which is weaker.

[1:58:02](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7082s) The final issue is that we were just making incredibly slow progress. The meta question is why it had to be me to push for the change. There are many engineers on your team. Yeah, exactly. This is part of a broader pattern— why founders have an advantage at your companies.

[1:58:29](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7109s) I looked at the progress with carbon fiber and said, "this isn't working." For the Falcon 9, the primary airframe is aluminum lithium— a very good strength-to-weight. But aluminum lithium is hard to weld. You have to do friction stir welding— joining metal without entering the liquid phase. And you can't easily modify or attach things to it.

[1:59:24](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7164s) So neither aluminum lithium nor carbon fiber was the right choice for Starship. I said, "at this rate, we're never going to finish. We've got to think of something else." Then I said, "what about steel?" The early US rockets had used very thin steel. It's not like steel had never been used before.

[2:00:35](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7235s) The key insight is about the material properties of stainless steel at cryogenic temperature. The strength-to-weight ratio increases dramatically. If you look at room temperature properties, the steel is going to be twice as heavy. But at cryogenic temperature, full-hard stainless steel has similar strength-to-weight as carbon fiber.

[2:01:15](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7275s) In the case of Starship, both propellants are cryogenic— liquid methane and liquid oxygen. Almost the entire primary structure is a cryogenic tank. So you've got a 300-series stainless steel that, because almost all things are cryogenic, has the same strength-to-weight as carbon fiber.

[2:02:25](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7345s) Stainless steel is a remarkable material and is very easy to work with. You could smoke a cigar while welding it. You can modify it easily. Very low cost. And at cryogenic temperatures, it's similar strength-to-weight to carbon fiber. Plus, you get reduced heat shield mass, because the melting point of steel is much higher than aluminum.

[2:03:18](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7398s) So you can just run the rocket much hotter? Yes, it comes in like a blazing meteor. You can reduce the mass of the heat shield— maybe cut it in half. The net result is that actually the steel rocket is lighter than the carbon fiber rocket, because the resin in carbon fiber decomposes at lower temperatures.

[2:04:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7452s) Basically, carbon fiber and aluminum have about the same temperature limit, whereas steel can operate at twice the temperature. The main comment is going to be: "He should have started with steel in the beginning." But to play this back to you— what was hard was pushing for a less proven path against institutional inertia.

[2:04:52](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7492s) That's why I initially said the issue is that there weren't enough people willing to challenge assumptions. We were having trouble making even a single barrel section of carbon fiber that didn't have wrinkles in it. Carbon fiber is much less resilient than steel. Stainless steel will stretch and bend. Carbon fiber just cracks.

[2:05:44](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7544s) One other Starship question. I visited Starbase with Sam Teller, and that was awesome. One thing I noticed was that people really took pride in the simplicity. Everyone wants to tell you how Starship is just a big soda can— anyone in any industrial project can weld here. Well, factually Starship is stainless steel, so that's true. But Starship is the most complicated machine ever built.

[2:07:07](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7627s) A fully reusable orbital rocket— it's a very hard problem. Many organizations with immense resources have tried and failed. Falcon 9's booster is reusable, but the upper stage is not. I think the Starship design can be fully reusable. That's what's necessary for us to become a multi-planet civilization.

[2:07:57](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7677s) We spent a lot of time on bottlenecks. What are the current Starship bottlenecks? It really wants to explode. It's full of combustible materials. One test obliterated the entire test facility. The amount of energy contained in Starship is enormous. The Raptor 3 engine is a very, very advanced engine. But it desperately wants to blow up. On liftoff, the rocket is generating over 100 million horsepower. It's actually insane. While not exploding. Sometimes, yes.

[2:09:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7770s) What's the single biggest bottleneck right now? It's having the heat shield be reusable. The heat shield has to make it through reentry, and then it's got to come back and also not lose tiles. We have brought the ship back and had the heat shield mostly intact. But it was not reusable without a lot of work. We need a fully reusable heat shield— refill propellant and fly again.

[2:11:06](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7866s) It seems like you're able to drive this sense of urgency— "we need to find the thing that can scale." How do you keep that culture? That maniacal sense of urgency has to come from whoever is leading the company. You identify bottlenecks and get rid of them. I'm constantly addressing the limiting factor.

[2:12:20](https://www.youtube.com/watch?v=BYXbuik3dgA&t=7940s) I try to aim for a deadline that I believe has about a 50% probability of being achieved. There is a law of gas expansion that applies to projects— if you said we're going to do something in two years, it will expand to fill the available time. Physics will limit how fast you can scale manufacturing. You've got to bring it up carefully.

[2:13:31](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8011s) What can I say that's actually helpful to people? Generally, a maniacal sense of urgency. You want to have an aggressive schedule and constantly identify what the limiting factor is at any point in time and help solve it.

[2:14:19](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8059s) Starlink was slowly progressing, and at some point I decided the team was just not cutting it. I have these very detailed technical reviews. That's maybe a very unusual level of granularity for a CEO. But if you're running a technology or manufacturing company, you need to know what's really going on.

[2:15:26](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8126s) In technical reviews, instead of having the person who reports to you filter information, have the actual engineers present. Otherwise you're going to get information laundering. If you have meetings weekly or twice weekly, you can plot the progress points on a curve and say, "are we converging on success or diverging?"

[2:16:32](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8192s) I'll take drastic action only when I conclude that unless we change course, we will not succeed. So when I finally reach that conclusion, then I must take drastic action. And in every case where I took drastic action, it fixed the problem.

[2:17:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8223s) Within one of these companies, you have how many direct reports? What determines the max? It depends on the situation. I allocate time according to where the most critical bottlenecks are. If a company is making good progress, they don't see much of me. If there's a critical problem, they'll see a lot of me.

[2:18:25](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8305s) At SpaceX or Tesla, are you doing weekly reviews with each team? Some things are weekly, some are twice weekly. Every Tuesday and Saturday is the chip review. Usually it's two or three hours per session. It feels like in the corporate world, time is often finely sliced into 30-minute meetings. But you hold more open-ended sessions.

[2:20:04](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8404s) You said about Optimus and space compute— trillion-dollar-plus growth rates within years. What was the point of the DOGE cuts if AI is going to solve everything anyway?

[2:20:28](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8428s) Well, I think waste and fraud should be addressed regardless. I was actually pretty worried about the fiscal situation. The interest payments on national debt exceed the defense budget. So we have over a trillion in interest payments. I was pretty concerned about that.

[2:21:03](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8463s) DOGE is about trying to slow down the bankruptcy of the United States long enough for AI and robots to help solve the national debt. AI and robots are the only thing that could solve the national debt. We would go bankrupt and fail as a country without AI and robots. We just need enough time to build them.

[2:21:43](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8503s) I'm not the president. And it is very hard to cut even the most ridiculous waste and fraud. The system has to operate on who's complaining. When you try to cut something, they immediately come up with the most sympathetic possible case. They don't say, "Please keep the fraud going." Meanwhile, no baby pandas are dying.

[2:23:10](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8590s) But I thought, wait, let's try to cut some obvious fraud. Maybe there shouldn't be 20 million people on the payroll who are definitely dead, and over the age of 115. If somebody is 115 and marked as alive in Social Security, you should call them and say, "We seem to have an error. Either you're the oldest person in history, or you should be marked as dead." One of the two things.

[2:24:19](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8659s) Yes. That's what I mean by ludicrous fraud. Some were getting payments from Social Security while being marked as dead in other databases. Those other agencies would simply do an "are you alive" check. The Government Accountability Office confirmed this isn't just our finding.

[2:25:16](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8716s) It's important to understand that the government is very ineffective at stopping fraud. In a private company, if you're stopping fraud, you've got motivation because it costs you money. The government just prints more money. Competence is in short supply at the federal level. It's the DMV that can print money.

[2:26:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8774s) Why was it not possible to cut all that fraud? Recalibrate your expectations for government competence. The states more or less need to stay solvent. But the federal government just prints more money. It's a largely uncaring monster bureaucracy.

[2:27:14](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8834s) One thing the DOGE team did was simply requiring payments from the Treasury to have a payment appropriation code. Payments were being sent out with no appropriation code and with no explanation. The Department of Defense cannot pass an audit. The competence is just not there.

[2:28:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8910s) Federal government expenditures are about $7 trillion. How competent do you think the government is at preventing fraud? Most of it is Medicare, Medicaid, Social Security, disability. Let's consider reductio ad absurdum: what's the probability the government is 100% efficient? Zero. What about 90%? But if it's only 90%, that means $700 billion in waste and fraud. And it's not 90% effective.

[2:29:49](https://www.youtube.com/watch?v=BYXbuik3dgA&t=8989s) You know a lot about fraud at Stripe? Yeah, but as you say, it's a different problem space. We're more exposed to different fraud vectors. Even with high competence and high caring, fraud at Stripe is still non-zero— about 1% of payment volume. That takes enormous competence and caring to achieve. In the government, there's much less competence and much less caring.

[2:30:41](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9041s) How do you feel now looking back on Twitter/X and DOGE? Looking from the outside, these were both very controversial. It was a bunch of heartache. I think those things needed to be done. Politics is generally very tribal. People have trouble seeing the good on the other side. You often simply cannot reason with people. They simply believe everything the other political tribe does is bad. But I think overall those actions— acquiring Twitter and helping with DOGE— were the right things to do.

[2:32:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9150s) How does political engagement feed into the broader mission? America needs to be strong enough to get to the point where we can colonize other planets and get AI and robotics to the point where they can benefit humanity. On the other hand, if America descended into authoritarian government, that would stamp out innovation.

[2:34:01](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9241s) I think maybe the biggest danger of AI is government using AI and robotics to suppress the population. People who are opposed to corporations should really worry the most about government. Government is simply the biggest and worst corporation— a corporation with a monopoly on violence. Corporations at least have better feedback loops.

[2:35:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9312s) I actually think it's a real thing to be worried about— governments using robotics to suppress the population. If you limit the powers of government, which is what the US Constitution tries to do, then you're reducing that risk. Grok should have a moral constitution.

[2:37:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9432s) At some point you'll control so many of the technological components of the future— Optimus, space GPUs, SpaceX— that you could set policy. I will do my best to ensure that these technologies maximize the good outcome for humanity.

[2:38:29](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9509s) You mentioned that Dojo 3 will be designed for space? You want to design it to be more radiation resilient. Roughly, if you increase the operating temperature, you can cut your radiator mass in half. The main issue with radiation is random bit flips. For training, if you get a few bit flips, it doesn't matter. Memory is more sensitive to bit flips than logic. I just design it to run hot.

[2:40:02](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9602s) The solar array is most of the mass. The basic math is: if you can do about a kilowatt per chip, and you need 100 gigawatts, that's about 100 million full reticle chips. That tells you how many chips you need to make and how many wafers you need. That's the plan with TeraFab— millions of wafers per year.

[2:41:12](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9672s) Are you going to make a memory fab too? It's got to do logic, memory, and packaging. This is the most complicated factory ever built. So you realize it's a bottleneck— what do you tell the team? "I want a TeraFab." That's exactly what I want. Make our mistakes at a small scale first, then scale up.

[2:42:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9750s) There'll be drones hovering over the bloody thing monitoring progress in real time. We want 100 gigawatts of power and 100 million chips. We'll take as many chips as anyone can make. I've actually said this to TSMC and Samsung: we will guarantee to buy the output of those fabs.

[2:43:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9810s) There's a narrative that the traditional manufacturers are holding back. They're not necessarily holding back deliberately— they're dispositionally conservative. They've seen cycles. That's a lot of layers of scar tissue. When you've been in an industry for 30 years and barely avoided bankruptcy multiple times, you don't just believe everything is going to be great forever.

[2:44:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9870s) Are there other ideas you think people should be working on? People should do the thing they find personally interesting and motivating. In the three to four year timeframe, the limiting factor is chips. And even before chips, it's power production, electricity. Towards the end of this year, people are going to realize the chip output will exceed the available power. What's your plan to deal with that world? That's maybe one of the reasons xAI went into hardware. We'll be able to turn on more chips than most, because we're good at hardware.

[2:46:10](https://www.youtube.com/watch?v=BYXbuik3dgA&t=9970s) The corporations that call themselves labs— there's not more than about a six-month difference between any of them on the algorithms side. So I think you hit the hardware wall. Whoever can deploy hardware the fastest will be the leader.

[2:46:50](https://www.youtube.com/watch?v=BYXbuik3dgA&t=10010s) You joked about being self-conscious about orders of magnitude. But I think there's something deep here. If you think of a senescent, low-agency bureaucracy or corporation— they'd just be complaining about the bottleneck. "Most people are willing to endure any amount of suffering rather than change anything about it." In your case, it's: "Okay, we got to figure out how to make chips. We got to figure out how to run the chips in space."

[2:47:40](https://www.youtube.com/watch?v=BYXbuik3dgA&t=10060s) I have a high pain threshold. That's helpful. One thing I can say is: I think it's better to err on the side of optimism and be wrong, than to be pessimistic and be right, for quality of life. So I recommend erring on the side of optimism.

[2:48:30](https://www.youtube.com/watch?v=BYXbuik3dgA&t=10110s) Cool. Elon, thanks for doing this. All right, thanks guys. Hopefully this didn't count as three hours.
