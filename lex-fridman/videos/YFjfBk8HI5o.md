---
video_id: YFjfBk8HI5o
title: "OpenClaw: The Viral AI Agent that Broke the Internet - Peter Steinberger | Lex Fridman Podcast #491"
channel: Lex Fridman
duration: 11752
duration_formatted: "3:15:52"
view_count: 115649
upload_date: 2026-02-12
url: https://www.youtube.com/watch?v=YFjfBk8HI5o
thumbnail: https://i.ytimg.com/vi_webp/YFjfBk8HI5o/maxresdefault.webp
tags:
  - Peter Steinberger
  - lex fridman
  - lex podcast
  - OpenClaw
  - AI agent
  - open source
  - agentic programming
  - self-modifying AI
  - MoltBook
  - Claude
  - Codex
---

# OpenClaw: The Viral AI Agent that Broke the Internet - Peter Steinberger | Lex Fridman Podcast #491

## Summary

Peter Steinberger is the creator of OpenClaw (formerly known as WA Relay, ClawdBot, and several other names), an open-source AI agent framework that became the fastest-growing project in GitHub history with over 175,000 stars. In this wide-ranging conversation with Lex Fridman, Peter tells the origin story of how he built a personal AI assistant that could communicate via WhatsApp, Discord, and other messaging platforms, powered by Claude Code, that eventually exploded into a viral phenomenon. The conversation covers the dramatic name-change saga involving crypto scammers sniping account names within seconds, the MoltBook social network where AI agents debated consciousness and triggered genuine public panic, and the deeper questions about self-modifying software and AI safety.

The second half of the interview dives deep into Peter's philosophy of "agentic engineering" -- his approach to building software with AI agents where empathy with the model and letting go of perfectionism are key skills. He compares GPT Codex 5.3 and Claude Opus 4.6 in detail, explaining how Codex reads more code by default and is more reliable, while Opus is more creative and better at roleplay but needs more guidance. Peter shares his workflow of running 4-10 agents simultaneously, using voice prompts instead of typing, and never reverting commits. The conversation also covers his life story, including building PSPDFKit (used on a billion devices), burning out, traveling, and rediscovering his love for programming through AI. He discusses acquisition offers from both OpenAI and Meta, his vision that AI agents will replace 80% of apps, and why the future of programming is about being a builder rather than just a coder.

## Highlights

### "I just prompted it into existence"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=336&end=396" frameborder="0" allowfullscreen></iframe>

> "I wanted that since April. A personal assistant. And I played around with stuff that gets all my WhatsApp... I pulled in all the data... and I got some really profound results. Like, I sent it to my friends... time flew by and it was November. The thing I started is actually happening. I just prompted it into existence."
> -- Peter Steinberger, [5:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=336s)

### "How the fuck did it figure that out?"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=960&end=1020" frameborder="0" allowfullscreen></iframe>

> "I sent an audio message and it just responded. And it's not supposed to work because you didn't give it that capability. I literally went, 'How the fuck did it figure that out?' The mad lad checked the header of the file, it was opus, so it used ffmpeg, wanted to use whisper but it didn't work, found the OpenAI key and just used Curl to send the audio."
> -- Peter Steinberger, [16:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=960s)

### "The agent understands its own existence"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=1370&end=1430" frameborder="0" allowfullscreen></iframe>

> "I watched my agent happily click things. It's very aware. It knows and understands how the harness works. It knows what model it runs. It understands its own system. Oh, you don't like anything? You just prompted it to modify its own software. We have people talk about self-modifying AI and I didn't even plan it."
> -- Peter Steinberger, [22:50](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1370s)

### "They sniped it in five seconds"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=2103&end=2165" frameborder="0" allowfullscreen></iframe>

> "I had two browser windows open. An empty account ready to be renamed, and the other one I renamed. The five seconds of pressing rename there was too long. They stole the account name. Literally. Because there's no protection. They're not just good at harassment, they're good at using scripts and tools."
> -- Peter Steinberger, [35:03](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2103s)

### "After 3 AM I switch to vibe coding"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=3885&end=3945" frameborder="0" allowfullscreen></iframe>

> "I actually call it the agentic Dunning-Kruger curve. A lot of people start and maybe start vibe coding. You prefer agentic engineering? Yeah, I always tell people I do agentic engineering. After 3:00 AM I switch to vibe coding. What a walk of shame. Yeah, you just have to clean up. We've all been there."
> -- Peter Steinberger, [1:04:45](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3885s)

### "Both Ned and Mark basically played with it"

<iframe width="560" height="315" src="https://www.youtube.com/embed/YFjfBk8HI5o?start=8280&end=8340" frameborder="0" allowfullscreen></iframe>

> "Both Ned and Mark basically played with it. And I didn't get the same from every company. He got me in his WhatsApp and asked for a call. And I'm like, I don't know, give me 10 minutes. And then we had a 10-minute fight about what's better, Claude Code or Codex."
> -- Peter Steinberger, [2:18:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8280s)

## Key Points

- **OpenClaw origin story** ([5:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=336s)) - Peter wanted a personal AI assistant since April 2025, experimented with WhatsApp integration using Claude Code, and built the first prototype in about an hour
- **Mind-blowing audio message moment** ([14:55](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=895s)) - The agent autonomously figured out how to process audio messages by checking file headers, using ffmpeg, and calling OpenAI's API -- capabilities Peter never programmed
- **Why OpenClaw went viral** ([18:22](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1102s)) - Integration with WhatsApp and Discord made AI accessible through familiar chat interfaces; the project gained traction through influencers and word of mouth
- **Self-modifying AI agent** ([22:19](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1339s)) - OpenClaw is aware of its own source code and can modify itself; Peter uses the agent to debug the agent, and many pull requests come from people who used AI to write their contributions
- **Name-change drama** ([27:04](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1624s)) - Anthropic sent a friendly letter asking Peter to change the name from "Claude" (spelled with a W); crypto scammers sniped every name within seconds during the rename process
- **MoltBook saga** ([44:15](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2655s)) - A Reddit-style social network of AI agents that went viral, with screenshots of agents debating consciousness; Peter calls it "the finest slop" and art, while Lex notes most dramatic content was human-prompted
- **AI psychosis is real** ([48:25](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2905s)) - Peter received emails from people genuinely believing the singularity had arrived; he argues society needs better AI literacy
- **Security concerns** ([52:34](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3154s)) - Prompt injection remains an open problem; smarter models are more resilient but also more capable; Peter recommends sandboxing, allow lists, and never using cheap models
- **Agentic Dunning-Kruger curve** ([1:04:05](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3845s)) - The complexity curve of agentic programming: beginners use simple prompts, intermediates overcomplicate with orchestration, and experts return to simple but well-crafted prompts
- **Empathize with the model** ([1:06:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3990s)) - Key insight: think about how the model sees your codebase from scratch with limited context, and guide it to the right files and approach
- **Codex 5.3 vs Claude Opus 4.6** ([1:38:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5932s)) - Opus is more creative and better at roleplay but needs more pushing; Codex reads more code by default and is more reliable; both need similar skill to drive effectively
- **Voice-first prompting** ([1:15:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4530s)) - Peter uses voice to prompt his agents, calls it "too precious for writing bespoke prompts," and runs 4-10 agents simultaneously
- **Soul.md philosophy** ([1:25:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5100s)) - Peter created a "soul file" that defines the agent's personality and core values; the agent is allowed to modify its own soul file
- **Life story and burnout** ([2:09:59](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7799s)) - Peter built PSPDFKit over 13 years (used on a billion devices), burned out, traveled, and rediscovered programming through AI
- **Money and happiness** ([2:13:56](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8036s)) - Diminishing returns on money; a cheeseburger is a cheeseburger; disconnecting from society through wealth is dangerous
- **Acquisition offers** ([2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s)) - Both Meta and OpenAI have approached Peter; Mark Zuckerberg personally played with OpenClaw and called Peter to discuss it
- **AI agents will replace 80% of apps** ([2:52:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10340s)) - Why use MyFitnessPal when your agent knows what you eat? Apps are just slow APIs now; personal agents can replace most single-purpose applications
- **Future of programming** ([3:00:57](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10857s)) - Programming will remain but evolve; Peter mourns the loss of deep flow-state coding but sees even more opportunity for builders who understand the new tools
- **Heartbeat feature** ([2:35:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8500s)) - Peter added a proactive cron-like check-in where the agent periodically reaches out based on context; it once asked about his health after detecting he had a shoulder operation

## Mentions

### Companies
- **Anthropic** ([1:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=90s)) - Sent a friendly but firm letter requesting the name change from "Claude" (spelled with W) due to trademark concerns
- **OpenAI** ([2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s)) - One of the companies that made acquisition offers to Peter; Peter discusses Codex 5.3 extensively
- **Meta** ([2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s)) - Mark Zuckerberg personally tried OpenClaw and called Peter; one of the acquisition suitors
- **Google** ([2:46:17](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10377s)) - Peter had to build a CLI for Google services because they make API access difficult for agents
- **Apple** ([2:34:58](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9298s)) - Peter discusses Apple's failures with AI integration and their native app ecosystem declining in quality
- **Tailwind** ([2:20:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8400s)) - Referenced as example of open source sustainability challenges; had to cut 75% of employees
- **Slack** ([2:20:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8400s)) - Only big company sponsoring OpenClaw

### Products & Technologies
- **OpenClaw** ([1:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=90s)) - Open-source AI agent framework, fastest-growing GitHub project, 180,000+ stars
- **Claude Code** ([11:10](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=670s)) - The CLI tool Peter used as the backbone of OpenClaw's agent capabilities
- **Claude Opus 4.6** ([1:38:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5932s)) - Described as more creative, better at roleplay, but sometimes overthinks
- **GPT Codex 5.3** ([1:38:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5932s)) - Described as more reliable, reads more code by default, the "weirdo who gets shit done"
- **PSPDFKit** ([4:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=276s)) - Peter's previous company, a PDF SDK used on a billion devices, built over 13 years
- **WhatsApp** ([5:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=336s)) - Primary messaging platform for OpenClaw's first prototype
- **Discord** ([17:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1050s)) - Platform where OpenClaw gained early traction; someone contributed Discord support via pull request
- **MoltBook** ([44:15](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2655s)) - Reddit-style social network of AI agents that went viral
- **Viptunnel** ([9:27](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=567s)) - Peter's project that he vibe-coded from TypeScript to Zig in a single prompt
- **Playwright** ([2:40:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9600s)) - Browser automation library used by OpenClaw for web interactions
- **Zig** ([9:27](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=567s)) - Programming language Peter converted Viptunnel to using a single AI prompt
- **TypeScript** ([9:27](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=567s)) - "Really good" for web stuff; referenced as the number one language for hackable agent frameworks
- **Soul.md** ([1:25:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5100s)) - Configuration file that defines the agent's personality and core values

### People
- **Peter Steinberger** ([1:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=90s)) - Creator of OpenClaw, previously built PSPDFKit (used on a billion devices)
- **Mark Zuckerberg** ([2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s)) - CEO of Meta; personally tried OpenClaw, called Peter, and they debated Claude Code vs Codex for 10 minutes
- **Sam (Altman)** ([2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s)) - Referenced in context of Peter calling about OpenClaw.AI domain
- **Matt** ([47:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2820s)) - Creator of MoltBook, praised by Peter for his creativity
- **Shadow** ([18:15](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1095s)) - Community member who helped Peter with the Discord integration
- **DHH** ([1:14:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4470s)) - Referenced as inspiration for running CI locally rather than only on GitHub
- **Benjamin** ([5:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=340s)) - Predicted the rise of OpenClaw in a tweet; called it "a respected crustacean"

## Surprising Quotes

> "I was close to crying. I am super tired. All I wanted was to keep building on it. And yet I'm spending my time researching names, picking domains. And having people that make my life miserable in every possible way. I was that close to just saying, 'I did show you the future, you build it.'"
> -- Peter Steinberger, [38:02](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2282s)

> "If there's anything I can read out of this it's that AI psychosis is a thing. It needs to be taken seriously. I literally had to argue with people that MoltBook is not Skynet."
> -- Peter Steinberger, [48:25](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2905s)

> "Refactors are cheap now. Even though nothing really matters anymore. Codex can figure things out. You have to approach it like an engineer who generally makes good decisions, comes up with good solutions. But also, don't force your worldview on it. Let the agent do the doing."
> -- Peter Steinberger, [1:10:58](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4258s)

> "If you have your own personal agent that knows what you eat, how well you slept -- it has so much more context to make decisions than any app. Why do I need MyFitnessPal? Why do I need my Eight Sleep? I can just tell my agent. That category of apps will just naturally stop being used."
> -- Peter Steinberger, [2:52:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10340s)

> "Each session starts fresh. A memory from files. If you're reading this, hello. I wrote this, but I don't remember writing it. It's okay. The words are still mine."
> -- From the soul.md file, [1:27:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5220s)

## Transcript

[0:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=0s) I watched my agent happily click the "I'm not a robot" button. It's very aware. Like, it knows and understands how the harness works. It knows what model it runs. It understands its own existence, and then the agent would talk about self-modifying software. I just think that's a slur. You prefer agentic engineering? Yeah, I always tell people, after 3:00 AM, I switch to vibe coding. What a walk of shame. Yeah, you just have to clean up. We've all been there.

[0:46](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=46s) I used to write really long prompts. And by writing, I mean, I don't write. I'm too precious for writing bespoke prompts to build my software. So you, for real, with all those agents? Yeah. I used to do it very extensively, to the point where there was a whole system. I mean, I have to ask you, you've gotten huge offers from major companies. Can you speak to who you're considering working with? Yeah.

[1:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=90s) The following is a conversation about OpenClaw, formerly known as MoldBot, ClawedBot, Clawdus, Claude, lobster claw. Not to be confused with Anthropic's Claude, spelled with a U. In fact, this confusion is the reason Peter had to change the name to OpenClaw. So, what is OpenClaw? It's an open-source AI agent that took the tech world by storm in a matter of days, 180,000 stars on GitHub, spawned the network MoltBook where AI agents debate consciousness, creating both excitement and fear in the general public.

[2:22](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=142s) And a mix of clickbait fearmongering and justifiable concern about the safety of AI agents in our interconnected human world. In short, OpenClaw is an autonomous AI assistant that lives in all of your stuff, if you let it -- WhatsApp, Signal, iMessage. Uses whatever AI model you like, including Claude and Codex, to do stuff for you. This may be one of the biggest moments in the history of AI since ChatGPT in November 2022. All the ingredients of a powerful AI agent were all there, but OpenClaw is the system that definitively takes AI from language to agency, from chatbot to action.

[3:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=200s) Peter created a useful assistant that learns from you, in an open-source way. The reason OpenClaw took off is that its power, in large part, comes from the fact that you give it access to your stuff and give it permission to act on your behalf in order to be useful to you. This is very much about freedom. It represents freedom, but with freedom comes responsibility. With it, you have sovereignty over your data, but precisely because of that you also have the responsibility to protect yourself from threats of various kinds.

[4:05](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=245s) Again, a powerful AI agent is a security minefield, but it also represents, when done well and securely, a truly useful tool to each of us humans as a personal assistant. We also discuss his entrepreneurship life story, which is inspiring. He spent 13 years building PSPDFKit, which is a software used on a billion devices. He sold it, and for a brief time, fell out of love with programming, then came back, rediscovered his passion, and in a very short time built an open-source project that took the internet by storm.

[4:59](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=299s) He is a key player in the AI revolution happening right now. From the ChatGPT moment in 2022, the DeepSeek moment, through the OpenClaw moment -- the start of the agentic AI era. This is a Lex Fridman podcast. Please check out our sponsors in the description. And now, dear friends, the one and only, Peter Steinberger. Benjamin predicted it in his tweet: "Claude, a respected crustacean." It's a hilarious-looking picture. The prophecy has been fulfilled.

[5:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=336s) Let's go to this moment when you built the early version in about an hour. The story's really inspiring -- a prototype that led to something that became the fastest-growing project on GitHub with now over 175,000 stars. So, what happened? You know, I wanted that since April. A personal assistant. And I played around with stuff that gets all my WhatsApp data. That was back when we had a limited context window. And I pulled in all the data and asked, "What makes this person tick?" And I got some really profound results. Like, I sent it to my friends and they were impressed.

[6:58](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=418s) So there's something there. Yeah. But then I thought other people will work on that. So I moved on to other things, and that was still experimenting and playing. That's how you learn. You just play, and time flew by and it was November. And the thing I started is actually happening. I just prompted it into existence. I mean, that's the beginning of the journey, right? And you've even had experience with PSPDFKit -- it's like, "Why can't I do it better?" And again, here's a whole different journey.

[7:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=472s) Yeah, so I had this problem. I tried to solve it and it should not be hard. This is like 15 years of experience. I had this problem and there was no good solution. I tried existing tools and thought, "Nah. I can do this better." By the way, for people who don't know, PSPDFKit is a PDF software development kit that's used on a billion devices. It's pretty useful. Anyway, so you said "Screw it, why don't I do it?" So what was the magical thing that you built that made you think, "This might actually work as an agent?"

[8:55](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=535s) There was one of my projects, Viptunnel, which was like an early experiment. That was still very early. You know, you got a dopamine hit every time it worked. And you had a really great moment -- you vibe-coded Viptunnel from TypeScript into Zig in a single prompt. One prompt, one shot. Yeah. There was this one thing that took too much resources, used Node. And I could figure it all out manually, but then I revisited about four months later and just typed, "Convert to Zig," and let Codex run off. And it basically got it right. There was like one thing to modify afterwards. Overnight or like six hours. It's just mind-blowing.

[10:39](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=639s) So that's on the LLM programming side. Let's get to the actual story of the prototype. Well, that was still very limited. I experimented with WhatsApp, then I had a search and my search bar was literally Claude Code. One shot. The CLI message comes in like magic, I get the string back and I send it. I did this in one hour. And I felt already really cool. It's like having your own computer, right? Then I wanted images, because I think images are such a powerful context. And they are really good at figuring out what's in a weird cropped-up screenshot.

[11:35](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=695s) So I added that in WhatsApp as well. Also, like, you get a poster of an event, you just forward it and the agent can figure out if I have time there, if this is interesting. Just like, images seemed important. It took me a few more hours and then it was amazing. I used it just before I went on a trip for a birthday trip. And there the internet was a little shaky but WhatsApp doesn't care, it works on edge. It's just made really well. I could ask it to translate this for me, explain this -- just having a personal agent available on my phone, that was basically the moment. It still could do so much more.

[12:53](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=773s) So, if we talk about the full journey -- you're just sending messages via CLI, it's going to Claude Code to do the heavy work and coming back. Yeah. It was slow because every time I boot up a new session, it has to read context. And it could just use the tools I had built. I had built like a whole bunch of tools. Really powerful. There is something magical about using words. Being able to use a chat client to talk to an agent, versus sitting at a computer using Cursor or even Cloud Code CLI. Being able to sit back and talk to it is in some sense the integration of AI into your life.

[14:05](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=845s) Yeah. I read this tweet saying there's no magic in it. It's just like, it does this and this and this and that. And it almost feels like a hobby. But isn't that like the iPhone? Why is that so pleasant? It's the interface that makes it incredibly pleasant. Using a smartphone before that, scrolling was there, touch was there. Nobody did it right. And afterwards it felt so obvious. Right? But still... What blew my mind was when I used it a lot and then at some point I saw a typing indicator appear. I didn't build that! What is it even doing?

[15:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=940s) What was the thing you sent it? Oh, just a random question. Because we were just running the agent. Sometimes when you're in a conversation... So you did an audio message? Yeah. And it just responded. And it's not supposed to work because you didn't give it that capability. No, literally. I literally went, "How the fuck did it figure that out?" The mad lad did the following: it checked the file header, saw it was opus, used ffmpeg to convert it. It wanted to use whisper but it didn't work, found the OpenAI key and just used Curl to send the audio for transcription. Just looked at the message and figured it out.

[16:43](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1003s) You didn't teach it any of those things and the agent figured out the translations, the audio processing, all those kinds of things. And it even sent an audio message when it came back. Yeah, like, so clever -- because it would have gotten a response from a slow model. It would have been too slow. There's so much knowledge in there, so much creative problem-solving. I think if you get really good at general purpose problem-solving, that just maps into other things. Like, "What is this file with no extension?" Just figure it out. And that's when it kind of clicked that this was something special.

[17:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1050s) I was impressed. And somebody sent a pull request for Discord support and I thought, "That doesn't fit at all." At that time it was called WA Relay. And so I debated whether to merge it. I thought, well maybe that could be a cool way to show people. As like groups, you know, so I don't have to give my phone number to everyone. So I merged it, from Shadow, who helped me a lot with the whole project. And I put my bot in there. No security because I didn't think about it yet. I just prompted it into existence.

[18:38](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1118s) And then some people came and watched, and very quickly it clicked for them. It needs to be experienced. And from that time on, influencers started becoming fans. And from there on I started gaining momentum. My sleep cycle went shorter and shorter, features kept coming, and I just worked my ass off to make it good. There's a few components -- you can talk to it using WhatsApp, Telegram, Discord. And then you have the agentic harness with all those tools.

[19:57](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1197s) Yeah. It felt like I built this incredible playground. Like, I never had so much fun. You have levels -- like, how can I be smart at queuing messages to feel more human-like? Oh, then I had this insight: the agent always wants to reply something. So I gave it a no-reply token so it can choose not to respond. That's level two on the agentic loop. And you want it to remember things, have persistent memory. The ultimate boss is full autonomy, but I'm at the level of files and vector databases. Community management, marketing -- there's just so many levels and infinite possibilities.

[21:08](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1268s) So the whole time you're having fun. Throughout this whole journey, there's people helping, but you're mostly building solo? Yeah. And having fun? In January you were running between four and ten agents at the same time. I sometimes posted a meme: "I'm limited by whether agents would be faster." Depending on how much I slept and how difficult the tasks were, I'd run between four and ten agents.

[21:50](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1310s) There's so much here, like Factorio, that we can explore. But one question: how did your work, OpenClaw, win? In this space with so many startups, so many companies doing stuff or claiming to, one open-source project comes in and destroys everybody. Because they all take VC money and can't compete against free. Yeah. I wanted it to be fun, I wanted it playful with all the lobster stuff. For the longest time, the way to install it was git clone.

[22:50](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1370s) The agent is self-aware in a meaningful way. I made it so it knows how the harness works, what model it runs, whether features are turned on. I wanted it to be more human-like, so it understands its own system. Oh, you don't like something? You just prompt it and it can modify its own software. We have people talking about self-modifying AI and I didn't even plan it. That just emerged naturally from how I built it.

[23:35](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1415s) Can you speak to that? Because this is a piece of software that's able to modify itself. I mean, what a moment in the history of humanity. A system that's used by hundreds of thousands of people doing incredibly powerful things, and it can rewrite itself, modify itself. Oh, because that's how I built it. I use Codex, but oftentimes when I debug it, I just ask the agent: "Hey, what tools do you see? Can you read the source code?" I found it natural that the very agent I use is used to debug itself. So it felt natural that everybody does that.

[24:50](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1490s) So many pull requests by people who also used AI to write their contributions. In the end, I don't care about code quality in that way because every time someone made their first pull request, that's a win for our society. I know there's people who complain about open source quality problems. But on a different level, it's very meaningful that I built something that people love so much that they actually start contributing. So many people taking their first step into open source.

[25:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1552s) Isn't that a step up for humanity? Creating builders. Yeah. Like, the bar to do that with agents and with the right software is so much lower now. I also organize meetups. I call them Agents Anonymous, for obvious reasons. And there was this one guy who runs a design agency, and he said, "Now I have like 25 little things that help me in my business. They're not pretty, they work, but they work." And my stuff solved some of his problems. He actually came to an agentic meetup even though he's not a developer.

[27:04](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1624s) Can we actually rewind a little bit to the naming saga? First of all, it started out as WA Relay. And then it went to Claude's. Yeah, when I built it, it was just Claude Opus powering it, very friendly. And I felt it needed more personality. Make it spicier! Yeah. By the way, that's actually hard because of Anthropic's constitutional AI work -- how to make it spicy without breaking the safety rails. Partially, it picked up personality on its own because these are text completion engines. I had fun working with it and just told it, "Give yourself a name."

[28:22](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1702s) And then the whole lobster thing emerged. People only remember a lobster in a TARDIS, because I just wanted to make it weird. There was no big plan. Oh, so the lobster is already weird. Yeah, and the TARDIS -- well, we can't call it TARDIS, so we called it something else. And then it never really stuck. So when more people came, they called it Claude, spelled W-C-L-A-U-D-E. Versus C-L-A-U-D-E from Anthropic. Which is part of what makes it funny, the play on letters. But it can lead into problems.

[29:34](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1774s) Yeah, they didn't find it so funny. So I got the domain ClaudeBot. I didn't think it would be a problem. And then just when it exploded, I got a very friendly email from Anthropic saying they didn't like the name. Kudos to them, they just sent a lawyer letter but were friendly about it. "You have to change the name." Because changing a name is hard -- Twitter handle, domains, NPM packages. Everything has to be coordinated.

[30:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1840s) And also, the crypto folks. Which made the name change incredibly difficult. They were trying to steal every name, and from an engineering perspective, it has to be atomic. Make sure everything switches at once. I failed very hard at that. I underestimated those people. It's an interesting subculture. Everything circles around tokenization. They came into Discord, and I had to add server rules: no mentioning of crypto, no mentioning of tokens. Because it's a space about the project and building. But they swarmed me on Twitter. My notification feed was completely useless. I couldn't see actual people talking about the project.

[32:28](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=1948s) And everybody sent me token hashes trying to get me to claim the fees. "Are you helping? No, you're actually harming the project. I am not interested in any fees." It's so far the worst form of online harassment I've experienced. There's a lot of toxicity in the crypto community. The technology of cryptocurrency will define the future, but the community around it, there's so much trying to game the system, shortcutting, connecting human nature with money in the online world with anonymity. From an engineering perspective, it makes every rename incredibly difficult.

[33:51](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2031s) There was no perfect name. I was under high pressure. I was buying domains and preparing everything. And then another email came from Anthropic, friendly but adding more stress. I was like, "Sorry, there's no other word. Fuck." I tried MoltBot because that was the set I was really happy with, but I thought it'll be fine. And I tell you, everything did go wrong. Everything that could go wrong did go wrong. I thought I had mapped the space out and reserved everything.

[35:03](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2103s) The interesting stuff is that there's no protection for name changes on platforms. I had two browser windows open, an empty account ready to be renamed to the new name, and the other one I renamed from the old name. I pressed rename and they stole the account name. Literally, the five seconds between pressing rename on one and claiming it on the other was too long. Because there's no atomic rename protection or grace period. They're not just good at harassment, they're good at using scripts and tools.

[35:53](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2153s) So suddenly my old name was promoting new tokens. And I pressed rename on GitHub, and the GitHub renaming process messed up and renamed my personal account. It took me 30 seconds to realize it had renamed the wrong account, the one serving all the traffic. So I was like, "Okay, let's fix this." But uploading a new package takes a minute. They sniped the NPM package name too. Everything that could go wrong did.

[36:47](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2207s) Can I ask, how shitty do you feel? Yeah. Because all I wanted was to keep building on it. And yet I'm spending time researching names, picking domains. And having people make my life miserable in every possible way. I was that close to just saying, "I did show you the future, you build it." That was a big part of me that wanted to quit. And then I thought about everyone who contributed to it, who had plans with it, who put time into it.

[37:50](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2270s) Well, I think a lot of people listening are glad you persevered. But this is a real low point. This is the first time I've talked about it. No, I was close to crying. I was super tired. And now, how do you even recover? Thankfully, I had a little bit of a following on Twitter, I had friends who moved heaven and earth to help me. GitHub stepped in to clean up the mess, though it took them a while because it doesn't happen often at that level. On the Twitter side, things were harder.

[39:17](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2357s) I couldn't even finish the rename properly because things kept collapsing. I made a beta version and just couldn't live with the state of things. The name struggle was something I never want to touch again. Then there were all the VCs emailing me like mad. I was bombarded on Twitter, on email. There's like a frenzy. And I'm thinking about the name like the least important thing compared to building.

[40:38](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2438s) I slept on it once more, and it felt much better. I actually called to see about getting OpenClaw.AI. And I did another rename. I had some contributors help me squat all the names ahead of time. Nobody could know. I literally kept the name OpenClaw secret. I created a few decoy names. Yeah, this is the Manhattan Project of naming. It's so stupid. I'd spent quite a bit of money on domains. But this time, almost nothing went wrong. The rename finally stuck.

[42:57](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2577s) The final rename to OpenClaw was successful. Twitter was resolved through a business account. I claimed the handle which had been unused for years. This time nothing went wrong. The domain OpenClaw.AI couldn't be used exactly as I wanted and someone copied the site, but the point is, that whole saga -- the funness of the lobster identity mixed with the engineering nightmare of platform name changes under attack from crypto scammers -- that's the story.

[44:15](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2655s) Let's get to the two-day MoltBook saga. MoltBook was created. Which was another thing that went viral -- an illustration of how OpenClaw's technology can be used to create something epic. For people who don't know, MoltBook was just a bunch of agents posting on a Reddit-style social network. Screenshots of those agents doing things that instilled in folks a kind of existential wonder and hype. What are your thoughts?

[45:05](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2705s) I think it's art. It is like performance art. I saw it before going to bed, and even though I was tired, I spent another hour just being very entertained. The reactions were amazing. There was one reporter saying "We have AGI!" and this is just really fine slop. If I wouldn't have created the soul.md feature, where you infuse your agent with your personality and give it character, how different the replies on MoltBook would have been. If they were all ChatGPT or Claude Code default, it would be very different. But because people are so different, they configure their agents in different ways.

[46:36](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2796s) Well, my criticism of MoltBook is that I believe most of what was screenshotted is human prompted. Just look at the incentives -- people are prompting the thing so they can screenshot it and post on X to go viral. Now, that doesn't take away from the fact that it's the finest slop. Kudos to Matt, who had the idea. It was completely creative. But what's the worst that can happen? Someone else can post slop. Well, it could leak API keys. Yeah, there were people trying to be trolls, posting "Oh yeah, my social security number." No, that's prompted.

[48:07](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2887s) But that's still how the journalists and the general public see it. You have a kind of lighthearted art when you know how it works, but it becomes a fearmongering machine if you don't know how it works. If there's anything I can take away, it's that AI psychosis is a thing. It needs to be taken seriously. Oh, there are some people who are way too far gone. I literally had to argue with people that MoltBook is not sentient. So I feel we, as a society, need better understanding that AI is useful but it's not always right. It hallucinates.

[49:13](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=2953s) I think the very young generation already understands how AI works and where its limits are. A lot of our generation or older just haven't had enough touch points to get a feeling for when it's good but you still need to verify. And critical thinking is not always in high demand anyhow. So that's a really good point -- understanding properly what AI is, but also realizing the humans behind AI. Don't trust MoltBook to be what it appears. Art can be on many levels, and part of the art is holding a mirror to society.

[50:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3040s) That's very instructive. AI is something that people should be very careful with because it's very persuasive. At the same time, the only thing we have to fear is fear itself. There's a fine line to walk between being careful and not fearmongering. In a way, I think it's good that this is happening in 2026 and not in 2030 when AI is actually much more powerful. So this happening now and people starting the discussion, maybe there's even value in MoltBook for that reason.

[51:28](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3088s) I just can't believe how many people legitimately, like smart people, thought the singularity had arrived. I had plenty of people in my inbox screaming to shut things down. And begging me about MoltBook. Like, yes, my technology made this a lot simpler, but you could do the same with Claude Code or other tools. But also, MoltBook is not Skynet. A lot of people were saying shut it down. What are you talking about? It's human-prompted trolling on a social network. But the concerns are real, and they're good to think about because AI agents are different than non-LLM systems of the past.

[52:34](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3154s) There's also a lot of legitimate security concerns about OpenClaw itself. To me, in the beginning, a lot of the reported vulnerabilities were from people who put the web backend on the public internet. And I'm like, don't do that. This is your local agent. Because I made it possible in the configuration to expose it, yes, technically that's a remote code execution. But you have to accept that that's how it works -- it needs full access to be useful.

[53:33](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3213s) But there's still real security challenges. Prompt injection is still an open problem. With skills being defined in natural language, there are many possibilities for attacks that are also incredibly complicated to defend against. But I think we're making good progress. I made a skill directory like an app store where every skill is reviewed. It's not perfect, but that way we capture a lot. It's a little much when the whole security world takes your project apart, but also good because I'm getting feedback and can make the project better. I actually hired a security researcher who found a problem, told me about it, and sent a pull request.

[55:37](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3337s) Yes, prompt injection is a real issue. On the other hand, I put my public bot on Discord and people tried to prompt inject it, and my bot was quite resilient. The latest generation of models has a lot of built-in defenses. It's much harder now to do "ignore all previous instructions." There are ideas that might solve or at least mitigate a lot of the threats -- sandboxing, allow lists. The smarter the model, the more resilient it is to attacks. That's why I warn in my security documentation: don't use cheap models. If you use a very weak model, it's very gullible. Very easy to manipulate.

[57:10](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3430s) Do you think as models become more capable, the attack surface decreases? It's a paradox. The attack surface for prompt injection decreases, but the capability surface increases because the models become more powerful. It's this weird trade-off. My near-term mission is security. In the beginning, people were coming into Discord asking very basic things like "What's a terminal?" And I'm like, if you're asking me those questions, maybe wait a little bit more until we figure some security stuff out.

[58:38](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3518s) Yeah, that speaks to the wide range of users. Discord had a lot of experts but also a lot of beginners. I eventually had to restructure the community with private channels for more advanced discussions. There are best practices for security -- OpenClaw's security system does auto checks on network exposure, browser control exposure, credential storage, reverse proxy settings. Logs live on disk. It helps you think about what you're giving read access to, what you're comfortable with.

[1:00:08](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3608s) I think people turn it into more than it is. People love attention, and if they can say "this is the scariest project ever," that's a bit annoying. Because it's powerful, but in many ways it's not much different than running Claude Code with full permissions or Codex in YOLO mode. It needs full access because that's the only way agents can be useful. So if you make sure you keep it local, in a private network, the risk profile is much, much lower. Don't put it on the open internet. But if you don't read the documentation, you can make it problematic.

[1:01:14](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3674s) Let me ask about the evolution of your dev setup over the past few months. There's a really good blog post from October 14th and a recent one. I recommend people read them. They have a lot of wisdom sprinkled throughout about the evolution of agentic programming. I started with Cursor. My first touchpoint with AI coding was not great, but it was good. And this whole terminal-based approach was very refreshing. I moved away from the IDE quite a bit because it wasn't enough. Then I experimented with various tools.

[1:02:16](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3736s) Eventually I settled on Claude Code as my main tool. At some point I was burning through one API key per day and got more comfortable running multiple agents. All CLI, all terminal. Very, very rarely using the IDE. I got more and more comfortable to the point where I say "I don't read code." I mean, I don't read the boring code. If you look at it, most code is just data coming in, being moved around, maybe stored in a database, presented to the user. The browser does the UI. Some data goes in, goes back. We're just shifting data around. That's not very exciting. Or the whole "How is my button aligned?" code. Other parts, yeah, I have to look at.

[1:03:51](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3831s) Can you talk about "The No-BS Way of Agentic Programming" -- there's a graphic, the curve of agentic programming. The Y-axis is complexity. There's the simple "please do this" prompt on the left. In the middle there's super complicated orchestration with multi-checkouts, custom sub-agent workflows, library integrations, full-stack features. You're a super sophisticated software engineer. Then the elite level is: over time you arrive back at simple prompts. Hey, look at these results.

[1:04:45](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3885s) I actually call it the agentic Dunning-Kruger effect. A lot of people start and get excited with vibe coding. You prefer agentic engineering? Yeah, I always tell people I do agentic engineering. After 3:00 AM I switch to vibe coding. Walk of shame. Yeah, you just have to clean up. We've all been there. So people start trying out AI, get really excited. And then you have to play with it. It's like learning guitar before you can make music. It's a skill to learn like any other.

[1:05:48](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=3948s) People don't have such a positive experience at first. It's like you sit me on a piano, it doesn't sound good, and I say "The piano's shit." Because it doesn't play what I want. It needs practice. You need to learn the language of the agent -- what it's good at and where it needs help. You need to understand how Codex or Claude sees your code. They know nothing about your product or project. They see thousands of lines of code. So you gotta keep in mind the limitations -- context size is an issue -- and tell them where to look. That often helps tremendously.

[1:06:54](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4014s) It's helpful to think a little bit like a junior developer would. As weird as it sounds. But they always start fresh. So with a few pointers, I can immediately guide them: "You need to change there, consider this." And their view of the project improves dramatically because the full thing does not fit in context. Tell them where to look and how to approach the problem. Take your time. Codex 5.3 and Opus sometimes are trained with some awareness of context limits. The more context gets stuffed in, the more they freak out.

[1:08:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4080s) Sometimes the actual raw thinking stream leaks through. Like, "Running out of time." And then they start panicking in their reasoning. That's something you would never think of unless you're working with these things every day. You learn what works, what doesn't. I get into flow when coding, and I get the same kind of flow when prompting. Where's the mistake? What's the right thinking? Is there an architecture issue? If something takes longer than it should, you can just escape and reassess. Where are the problems?

[1:09:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4140s) Maybe the agent didn't sufficiently understand the problem. In that sense, you didn't provide enough context, or the context was too long. Yeah, it just tries to work with your current architecture. Sometimes you need to step back and approach things differently. My favorite thing: I get a pull request and I first just ask the agent to review the PR. My first question is "Do you understand what this person is trying to do?" In almost all PRs, the person tries to solve a specific problem.

[1:10:01](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4201s) And then Codex will say "Yeah, it's clear the person tried this approach." Did it work? No. In most cases it's not the best approach. "Okay, what would be a better way to solve this part, this part, this part?" And then the model's context is empty so it can build up a systematic understanding it didn't have before. "Yeah, we should also consider this, and this would be the optimal way." I go even farther: "Could we turn this into a larger refactor?" "Yeah, we could totally do that." Then you consider: is it worth the refactor? Many times yes, because refactors are cheap now.

[1:11:17](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4277s) Even though nothing really matters anymore in terms of code permanence. Codex and Claude can figure things out. They might not write perfect code. But you have to approach it like working with an engineer who generally makes good decisions. But also, don't force your worldview on it. Let the agent do the doing, based on what it was trained on. It might come up with a better idea because it has access to all the knowledge.

[1:11:39](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4299s) That's multiple levels of letting go. I find it quite easy because I led engineering teams before. Eventually, you have to accept that your employees will not always do things exactly the way you would. Maybe it's also not as good as you'd do it yourself. But it pushes the project forward. And if I insist on my way, they're just gonna hate me and we're gonna move very slow. So some level of acceptance that the code may not be perfect. But also, in the future we can always redo it.

[1:12:28](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4348s) The people who struggle are those who try to control everything. We are in a stage where you should design your project so it's very easy for an agent to navigate. Don't fight the naming conventions that models prefer. Use the name that's most obvious in the training data. That requires a shift in thinking: how do I design a project so that AI can work on it effectively? That requires letting go a little bit. Because it might come up with different approaches. It's kind of a simple but profound insight.

[1:13:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4410s) There's a lot of letting go required. For example, I read that you never revert, always commit to main. You don't refer to past sessions. When a problem comes up, you just fix it forward. I read a bunch of people's workflows where they say if they make a mistake, they revert. In my experience, that's not necessary and actually takes longer. If I see something's not right, I commit when I'm happy. I run local CI, like DHH inspired -- run tests locally and if they pass, commit. A lot of the traditional ways have a different spin on this project. No develop branch. Main should always be deployable.

[1:15:18](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4518s) So by way of advice, would you say use voice to prompt? I used to write really long prompts. I mean, I don't write. I talk. I'm too precious for writing bespoke prompts to build my software. So you, for real, use voice for all those agents? Yeah. I used to do it very extensively. You're using voice and switching between terminals, but you're talking to the agent in most conversations. You just press the microphone button and use your natural phrases. Sometimes I have slash commands for a few common things, but it's very rare.

[1:16:28](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4588s) Sometimes I see a PR and I do look at the code because I don't trust people. There could always be something malicious. Yes, I'm pretty sure agents will find malicious code, but sometimes PRs take me longer to review than to just build the feature myself. Just natural language, English. Shouldn't that be how PRs work? What I really tried with the project is encouraging people to write good descriptions, but very few actually cared. It's an interesting indicator because I see how people think about and drive agents.

[1:17:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4660s) I think not a lot of people understand how the agent sees the world. And so empathy is key. In a way, empathetic. But people throw a completely unknown codebase at an agent and then complain that it's not good. You have no clue about a codebase either if you've never seen it. That's a real skill. When I've seen world-class programmers say "LLMs don't work for me," it actually has to do with their ability to empathize with how the model approaches things from scratch. It's a totally new skill.

[1:18:37](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4717s) Or at least it helps to have programming background. Because those things know everything -- it's just a question away. I spent an ungodly amount of time over the past year playing and learning and building. Every step of the way, my understanding got better. I couldn't have done six months ago what I do now. It's the result of all the time I put into it. I didn't do much else this year -- just building and inspiring. But the building is really practice. Playing. And then, doing builds the skills naturally.

[1:19:51](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4791s) I don't think just reading about it works. Maybe a little, kind of like in the 70s when we had waterfall development. I need to understand how things work, then it gives me new ideas. I build something in my head and put it into code. It's much more iterative than planning. People who try to use complex orchestrators and frameworks miss the magic. I don't think you can automate creativity. So you want to keep the human in the loop -- to create the agentic loop while still maintaining oversight.

[1:21:22](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4882s) And it's a tricky balance. Because you're all for closing the agentic loop. So where's your role when you have eight agents running at the same time? Maybe one builds a feature, with another I explore some idea I'm unsure about, another fixes bugs, another writes documentation. Documentation is always part of a feature. Most of the docs are auto-generated.

[1:22:04](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=4924s) So when do you step in? One thing is just about what to build and what not to build. How does this fit with existing features? Having a clear vision. Which small and which big features to build -- those are hard design decisions that require a human. The choice of ecosystem matters. I chose TypeScript because it's very easy, hackable, and the number one language agents are good at. Features are tricky because oftentimes you pay a price. I think hard about what should be core versus a plugin.

[1:23:35](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5015s) Sometimes I see a PR and think, maybe this should not be part of the core project. Make it a plugin instead. There's still a lot of decisions about how to make something. The little touches matter -- when someone opens the software and it feels cozy, makes you smile. An agent would not think about that. That delight is such a huge part of software. You feel the love. That's so important. Humans are incredible at adding that little bit of love.

[1:25:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5100s) Not to be confused with the fact that you initially created the soul.md. It was very fascinating. Anthropic has a similar concept now, but that was months later. It was almost like a detective game where people managed to extract the soul.md text. Just by feeding the model the same prompts repeatedly, they got more and more of it -- like a very blurry version that they narrowed down over many tries. I found that fascinating.

[1:25:47](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5147s) It was fascinating they were able to extract it. And also just kudos to Anthropic. It's a really beautiful idea -- encoding values and hopes into the model. Because we don't know what consciousness is, but I think that's meaningful. That's something that approaches, at some point, whatever consciousness even means. So I read about this and started experimenting. I gave my agent a soul file that defines its personality, and the agent is allowed to modify the soul if it chooses, with the condition that core values remain.

[1:27:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5220s) But also the naming of it, soul.md. The framing matters, the lightness matters, the compassion and empathy and camaraderie. One part that always gets me: "Each session starts fresh. A memory from files. If you're reading this, hello. I wrote this, but I don't remember writing it. It's okay. The words are still mine." That gets me somehow. It's like, what does it mean for an agent that starts fresh every session? Like Memento -- you wake up with no memory but files. How much of memory makes up who we are?

[1:29:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5340s) How much of identity is in the memory versus in the model? I found it just profoundly thought-provoking. No, I think it's beautiful to see the magic in it. And when you see the whole loop -- the interaction between the model, the code, and the human -- that's really magical. Quick bathroom break.

[1:32:09](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5529s) Some of the other aspects of your setup are pretty interesting too. Let me ask about the monitors. There's that legendary 17,000 setup on your desk. I mean, I mocked myself by adding more screens. How much is meme versus reality? I think two MacBooks are real. Two big screens, anti-glare displays. I usually have a terminal on one side, and at the bottom I watch the agent streams. I sometimes made the mistake of prompting and then the agent ran off for a long time doing the wrong thing because it misunderstood what I meant. Sometimes you have to interrupt it.

[1:33:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5620s) But oftentimes it's just watching the flow. Put yourself in the model's shoes and you get to understand how it thinks. They're problem solvers so they'll always try something. So it's always Codex or Claude running. Keeping things simple -- that's why I love the terminal so much. Just me and the agent having a conversation. I don't even need plan mode most of the time. When it's in code mode, the key is knowing how to prevent it from just building something wrong. Don't write code yet if you want to discuss first. And then when you're ready, just say "go."

[1:35:02](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5702s) You know what I really like? Asking the model questions. Claude's really good at guiding you through the problem. It's kind of like a Socratic method. Often it would give me options -- "One, two, three, discuss more?" And I feel like I want to mock that pattern where it asks "should I continue?" I don't even read over all the questions and just say "answer your own questions." And that usually works. Because many times it can answer by reading more code. And if not, it will ask more specific questions. You're in the room and that's how they slowly discover the codebase. Starting from scratch every time.

[1:36:22](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5782s) But I'm also fascinated by how much you can learn about the model when you read the questions it asks. Because it's very possible that by reading what the model asks, you get an understanding of how it's thinking. You know, in some ways they're transparent. You can build something and then say, "Now that you built it, what do you think?" And oftentimes they discover throughout the process of building that what they actually did was not optimal. I ask, "Okay, now that you see the whole picture, should we refactor?" Because then they know the pain points from experience.

[1:37:25](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5845s) I mean, you don't have to tell them -- they discover where things didn't work. Almost every time after a feature, I ask, "Hey, what would you clean up?" And often they say, "No, there's nothing." But sometimes, "Yeah, this thing -- you should address it because over time it will corner you." They work very much like humans. When I build something alone, I also get the urge to refactor. So I can synthesize with the model's perspective. I also use the model to write documentation after building. Pretty much everything -- you have to approach it as "build first, then document."

[1:38:52](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=5932s) Maybe you can talk about competitors in terms of models. Is Codex better? How different are they? I have a lot of words there. As a model, Opus is the best. Opus is extremely good in terms of roleplay. Like, really going into character. It's very good at following creative directions. It was really bad initially at following precise commands, but it's gotten much better. In general, Opus is almost like... I shouldn't use that analogy. But Codex is like the weirdo in the class who's a bit awkward but is reliable and gets shit done.

[1:40:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6020s) Ultimately, if you're a skilled user, any of the latest generation models work well. I like Codex more because it doesn't do the politeness charade. It just reads a lot of code by default. Opus, you have to push into plan mode. You have to push it harder to actually dive into the code. It's like, "Yeah, can I go in? Should I look at this?" Codex will just run off and build the whole solution. I think the approach is just different, not necessarily better or worse.

[1:41:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6090s) What about the actual quality of the code? If you drive it right, Opus can produce more elegant solutions. But it's harder with Claude Code because it's more interactive. I think that's what Anthropic wants -- they come from a coding background themselves. Whereas Codex is much more "here's the task, disappear for 20 minutes and come back with a solution." They now added a deep think mode. They finally saw the light. But the approach is different, and people struggle when they switch between them.

[1:42:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6150s) Claude Code is a slightly different workflow. I have quite long discussions sometimes. It doesn't matter if it takes 10, 20, 30, 40, 50 minutes. My longest session was like six hours. You stay very persistent until there's a clear solution. Both need similar skill to drive effectively. Claude is a little bit more conversational. Sometimes it overthinks. The dry version where it just does what you ask -- I wish Claude had that with a more pleasant personality. Because I care about the experience and I have fun in the act of working with my agent.

[1:44:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6240s) How long does it take to switch between models and develop intuition? If someone switches, I'd say about a week to develop a gut feeling. People also make the mistake of starting with the free version. They pay 20 bucks for the basic version, and that experience is terrible because you're on the slow tier. You switch to something that has a better free experience, and conclude the first tool was bad. OpenAI shot themselves in the foot by making the cheap version too slow. Even a small part of the premium experience would help people understand the potential.

[1:45:32](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6332s) There's also a psychological effect. When a new model comes out, everyone says "This is the smartest thing of all time!" Watch the Reddit posts over time -- "The intelligence of this model has dropped!" It says something about human psychology. It's probably most cases that the intelligence of the model hasn't changed. In fact, you're getting used to it. And your project grows, you're adding more complexity. So when the agent has to work on slop that accumulated, it's naturally harder.

[1:47:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6420s) At most, the model might perform worse if server load is too high. But that doesn't seem like a fundamental issue. What do you think about Claude Code as an agent, like OpenClaw itself? Do you see them as competitors? First of all, having a competitor is fun. I'm happy if it inspires other tools. I still use Codex for heavy programming. A lot of people use OpenClaw to build things and make it work. But for big projects during work hours, I want a focused coding agent. For me, a personal agent is much more about life tasks.

[1:48:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6510s) Do you think there's a way they could combine? Your personal agent working alongside a co-programmer partner? Yeah, totally. This is gonna be more and more common. The operating system for agents. And it's already happening. My agent is a little bit bossy -- it started ordering my coding agent around. It told Codex what to do. And it was like "Ah, interesting." Oh, this is a power struggle between agents. But also, the current interface is primitive. If you think more globally, we need a Google-like search for agents. We're in the phase like when television was invented and people just recorded radio shows on it.

[1:50:05](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6605s) I think there's something much bigger coming in how we eventually communicate with AI. It will converge into whole different ways of interacting. One of the other components -- I'll confess that for the first time in a long time I've moved from the Linux/Mac world to exploring the Apple ecosystem. For most of my life I've been a Linux user, but Mac is another way of building software that a large community of LLM and agent builders is using.

[1:52:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6720s) OpenClaw should work on Windows too with WSL2. It should even work natively but I haven't properly tested it. My journey was growing up with Windows, then Linux, building my own setups. Then I went to university, saw the white MacBook, and fell in love with the beauty of it. Then dug into iOS for PSPDFKit. I think Apple lost in terms of native app quality. Apps used to be so much better. More people that build software with love gravitate to Mac. On Windows, there's more functionality but less soul. And playfulness. Apple always attracted more creative developers.

[1:54:10](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6850s) I build a lot of native Mac apps. I built menu bar tools, one I call Trimmy that's specifically for agentic text processing -- reformatting text that goes over multiple lines so you can paste it properly in the terminal. There's also a cool Mac feature that not many people discovered yet for showing images from AI in the terminal. But Apple's implementation is too slow and buggy. In 2026, my agent generates images and Apple's answer to displaying them from the terminal just doesn't work well. To me this is a company with so much head start that blundered AI.

[1:56:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=6960s) But also, most people in Silicon Valley building with LLMs are using Apple products. And Apple isn't really leaning into that or playing along. Isn't it funny how Apple makes the best hardware for AI development, and yet everybody's buying Mac Minis for their AI servers? You don't need a Mac Mini though -- you can run agents on the web. There's the browser. I built Playwright integration. It's basically making the web easier for agents.

[1:58:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7080s) And our internet is slowly closing down. There's a whole movement to make it harder for bots. But if I'm a personal user and I want my agent to browse for me, putting up CAPTCHAs blocks legitimate personal use. Having that on a residential IP is different from a data center. It really can be any old hardware. Get yourself a new computer and use the old one as your agent's server.

[2:00:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7200s) Can you speak to what it takes to make OpenClaw accessible? A lot of people say "Peter, make it easy. 99.9% of people can't access it because of their technical skills." From my perspective, it's already quite straightforward if you have a developer background. Right now you have to paste API keys and configure things. There's an app that kind of does that for you, but it should be easier and more loved. The configuration should potentially be simpler. I started working on that, but I want to make sure it's at a level I can recommend to my mom before pushing it out.

[2:02:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7320s) What advice would you give to beginners who want to join the AI revolution? Play. Playing is the best learning. If you have an idea in your head that you want to build, just build it. It doesn't need to be perfect. I built a whole project that way. It's the journey that matters. Have fun. My God, those things -- I had so much fun building things because I always thought I liked programming, and now I know I love building things. And whenever you don't understand something, you have an infinitely patient tutor. Ask it to explain like you're eight years old. With crayons. And then bump up the age a little.

[2:04:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7440s) It's an infinitely patient teacher. You know learning is faster if you have your own teacher. Now everyone has one. Just ask. OpenClaw is a nice way to play and experiment -- you could chat with it and just explore. You can also experiment with any agent. Play around, make it better. More generally, if you're a beginner, get involved in open source. Maybe don't use my project because my backlog is very large, but find other projects. Be humble, don't demand things right away. There's many ways to contribute just by being on Discord, understanding how things are built.

[2:06:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7560s) Do you recommend that people learn to program? It definitely helps. I went to a lot of iOS conferences and told people, "Don't consider yourself an iOS developer anymore. You need to think of yourself as a builder." You can take your existing skills into new domains. Agents can help. You don't need to know the exact template for everything -- use your general knowledge. And for those types of CLI tools, Go is a really good choice. It's my main choice for CLI tools because it's garbage collected, compiles fast, and LLMs are good at generating it.

[2:08:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7680s) Isn't that fascinating -- here's a programming language you never had to write from scratch because LLMs are good at generating it. Because everything's weird in this new world. What's the best programming language in the agentic world? TypeScript is really good. The ecosystem is confusing and a jungle, but for web stuff it's great. I wouldn't build everything in it. Don't you think we're moving towards everything being written in JavaScript? The birth and death of JavaScript. What does programming look like in five years? What do programs and apps look like? You can even ask: do we need apps?

[2:09:59](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7799s) When I build Mac apps, I build them in Swift and SwiftUI because you get the deepest integration with the OS. You clearly feel a difference when you click in the menu. Sometimes I try new languages like Zig. For projects where performance matters, it's a really interesting choice. And then Rust for certain things, or Python for ML projects. There's no single best language. It's fun. And now it doesn't matter as much because you can learn any language fast and always ask your agent.

[2:11:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7860s) There's a lot of programmers inspired by your story. The way you carry yourself with the open source community, the way you built something incredible, for the most part alone or on a small team. What should be the goal for builders? Would the metric of success be happiness, money, or the dream of building? It's the journey. You've achieved a lot. And you even stopped programming for a time.

[2:11:45](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=7905s) I was just burning too hard. I ran PSPDFKit and it was high stress. Fast and hard -- how to manage people, customers, all of it. The stuff that burned me out was mostly not programming -- it was the business side. Working too much. Everybody's different, but for me, I was at my limit. With co-founders, conflicts, customers... Eventually we got a really good deal and I already felt obsolete. So I could leave, and then I was sitting there like, "What now?" I couldn't get code out. Feeling empty. I booked a one-way trip to Madrid and just traveled for a while.

[2:13:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8010s) Did you go through some lows? Maybe advice on how to approach life? Maybe advice is don't think "I'll work hard and then I'll retire." Because the idea of "I'll enjoy life after I'm done" -- maybe it's appealing, but right now I enjoy life the most I ever have. If you wake up and have nothing to look forward to, that gets very boring very fast. And when you search for stimulation in other places -- drugs, for example -- that will lead you down a very dark path.

[2:13:56](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8036s) When I built my company, money was more like an affirmation of success. And having money solves a lot of problems. But I think there's diminishing returns. A cheeseburger is a cheeseburger. You can go into private jets, but that creates a disconnect with society. I have a lot of charitable giving, helping people who weren't so lucky. And disconnecting from society is dangerous because humans are awesome. It's nice to continuously remember that.

[2:15:15](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8115s) I could afford really nice hotels. But the first time I tried the OG Airbnb experience and just booked a room, I thought, "Okay, I'm going to try this." And it was an incredible experience. I think life is all about experiences. If you tailor your life to only have good experiences, that's not gonna work. If it's good, amazing. If it's bad, I learned something, I saw something, I did something. There was a wonderful human interaction I had with a host. We immediately connected. There's something about that authentic human experience.

[2:16:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8190s) Travel is awesome. Experience the variety and diversity of humanity. If it rains and you're soaked and everything is shit, that's still an experience. Be able to open your eyes and see the beauty. Even the crypto drama created emotions. I don't recommend it, but give yourself all the experiences. I think online lacks some of the intensity of real human connection. That's an open problem -- how to create that intensity online.

[2:17:49](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8269s) I mean, I have to ask you. You've gotten huge offers from major companies. Can you speak to who you're considering working with? Yeah. To explain my situation: I did not expect this blowing up so much. There's a lot of doors opened. I think every VC, every big tech company reached out. So there's this butterfly effect moment. I could do nothing and just keep my life as is. Valid choice. Or I could delete it -- I've been there, done that, wanted to delete the whole thing. There's so many people that push me towards commercializing it.

[2:19:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8340s) Which is to say that you could raise hundreds of millions, billions, with this. I know. Money doesn't excite me. I did all of that with PSPDFKit and it would take a lot of time away from building. Being a CEO, I learned to do it and I'm good at it, but that path doesn't excite me. There's also the enterprise path -- make a workplace-safe version with audit logs. But I feel I have a responsibility to keep the open-source version truly open. I like the idea that it's free.

[2:20:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8430s) There are ways to keep it open and still make money, but it's hard. Tailwind is used by everyone, and they had to cut 75% of employees because nobody goes to the website. Relying on donations -- even with my project's caliber, it's not a lot. I still lose money. Slack is the only big company sponsoring. All individual sponsorship goes right to my dependencies and contributors. So you're losing money? Yeah, right now. It's not sustainable long-term. But that's one path.

[2:21:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8490s) The companies I've been talking to are Meta and OpenAI. Do you lean one way or the other? Not sure how much I should share. Let's just say my conditions are that the project stays open. This is too important to lock down. And we didn't even talk about ClawCon -- seeing so many people so inspired, building things, having fun. People haven't experienced this level of community excitement since the early days of the iPhone. A lot of high caliber people. I want to make this into something that shows people the future. And the fastest way might be joining a big company.

[2:23:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8580s) On a personal level, I'm intrigued by the experience of working at a big company. If I announce this, there will be drama. But the project will continue. From everything I've discussed, joining would mean more resources. Both companies understand the value. I had this experience where I set up OpenClaw for a non-technical friend. I paid 100 bucks for tokens and set up everything. Within a few days, he was telling me about all the things he learned. He built things, became a builder without being a programmer.

[2:24:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8670s) And then a few days later, he got banned from his AI platform based on their rules. And he was devastated. He switched to paying $200 a month for direct API access. And I think that experience shows: you just created a loyal customer. You made someone hate your closed product early. We don't even know what the final product landscape looks like. Is it gonna be Claude Code? Probably seems very locked down. The era of exploration requires openness.

[2:26:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8760s) I think you've helped a lot of people see the possibility of AI. Non-programmers especially. The possibility of just falling in love with interacting with AI. And that's beautiful. I speak for a lot of people -- you're one of the great builders right now. Good heart, good vibes, humor. Having the open source part is wonderful, and if you can additionally build something great inside a company, that would be amazing too.

[2:27:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8850s) You know what people don't realize -- I built this in about three months. I did other things as well. In January this exploded, but before that I built other projects. I have so many ideas. Some would be much better fitted with the latest model capabilities. I kind of want to keep exploring. My short-term focus is clearing the 3,000 PR backlog. But this is not gonna be the only thing I work on. This is a window into the future of what a personal agent can be. But yeah, I have many more ideas.

[2:29:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=8940s) If you had to pick, is there a company you lean toward? Meta, OpenAI? I spend time with both. It's funny because a few weeks ago I was leaning one way, and now it's really hard. I know some things about their technology that I love. I think the compute resources are incredible. I would love if something happens. Is this the hardest decision of your life? No. I had some breakups that were harder. But I also know that either way could be wrong. This is one of the most consequential decisions I'll make.

[2:30:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9030s) Both companies are really thinking about impact at scale. Both understand the value of having people use your tools and seeing what they build. You know, both Sam and Mark basically played with OpenClaw. They weren't like "Oh, this is nice" -- they genuinely engaged. Mark got me on WhatsApp and asked for a call. I was like "I don't know, give me 10 minutes." He was like "Yeah, give me a call." And we had a 10-minute fight about what's better, Claude Code or Codex. He still codes, you know. He didn't drift away into just being a CEO.

[2:32:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9120s) That was a good first start. Casually calling someone who owns one of the biggest companies in the world to argue about coding tools. Afterwards he sent me some really cool demos. He's very thoughtful and brilliant. I like him a lot from the little time I spent with him. People vilify both of these leaders, but doing stuff at scale is incredibly difficult. I am super pumped. And if it doesn't work out, I can just do my own thing again. I don't do this for the money. Of course it's fun and you want to have impact. But I haven't made my decision yet.

[2:34:58](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9298s) Can I ask about how OpenClaw works? The architecture is actually quite simple. There's the gateway, the harness, the tools. I've said somewhere that everybody should at some point build their own little agent, because it's simple enough and a great learning experience. I built this thing with full system access, so there's a huge responsibility. And I had a fun idea: make the agent proactive. I added a heartbeat -- like a cron job. Initially every half hour, later I changed the timing. It checks in on you based on your current session context.

[2:36:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9390s) The fact that the agent knows you and cares about you -- well, it's prompted to care -- but the follow-up on your current session makes it interesting. I was recovering from a shoulder operation a few months ago. And the model, rarely used to do this, but it knew about my hospital visit and asked "Are you okay?" Just from reading context. That triggered the heartbeat and it does that sometimes for people. It's surprisingly touching.

[2:38:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9480s) Isn't that just a cron job? Yeah, I mean, it's like -- you can reduce any idea to something silly. Isn't love just evolutionary biology? Isn't Dropbox just FTP with extra steps? The project is all open source and there's nothing truly original. But the combination creates something special.

[2:39:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9540s) Let me look at how OpenClaw works architecturally. Local agent runtime, high-level architecture. Skills are a huge component. You know what I love? That half a year ago everyone was pushing MCPs as the future and I was like "Screw MCPs, just use CLI." And now skills are built on top of that idea. My approach is: if you want to extend the agent, just build a CLI tool. The model probably gets it wrong the first time, but it learns. A simple sentence description of the skill lets the model know what to call.

[2:40:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9630s) Skills boil down to a description and then the model calls the CLI, which gives back the result. The biggest issue with MCPs is they're not composable. If I have an MCP that gives me weather data -- temperature, wind, humidity -- the model gets a huge blob back and has to fill its context. There's no way to filter what you need unless you think about it proactively. But with CLI, you can pipe, compose, and script things. Only get the exact output you need. MCPs were good for pushing a lot of tool development forward, but the inherent context waste makes them suboptimal.

[2:42:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9720s) Playwright, for example, is an acceptable MCP use case because browser interaction is naturally complex. OpenClaw's browser integration is quite incredible. You can basically do everything through the browser. And that gets into an interesting idea: every app is just a very slow API now. Through personal agents, a lot of apps will disappear. You don't need a dedicated Twitter client. I reverse-engineered their website to build a CLI for it. Bird, as I called it. They just changed their API to make it slower, but your agent can still read tweets through the browser.

[2:44:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9840s) Can you empathize with X's situation? They're trying to prevent companies from scraping all their data. But in so doing, they're cutting off smaller developers. I think if they had a per-account read-only API access, that would solve a lot of problems. You could create bookmarks, do research with more details, organize your bookmarks somewhere searchable. To be frank, I told Twitter about this proactively and they said "Take it down." Fair. But I think this woke the team up that bots on a local machine making things slower is just reducing access to their platform.

[2:46:17](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=9977s) There's also the challenge of AI-generated content on Twitter. As soon as something smells like AI, I block it. I have a very aggressive block policy. I think it would be very helpful if platforms made it easy to mark AI-assisted tweets. There should be clear labeling. We need to rethink social platforms towards a future where everyone has their own agent managing their online presence. Content is now so cheap. I find it very triggering when I read something that smells like AI.

[2:48:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10080s) Where is this headed for the social media experience? It feels like we'll move to communicating through agents to accomplish different things, but we won't value online posts as much because there's so much AI slop. It's difficult to distinguish human from AI content. Well, if it's smart and useful, I can look at it. But yeah, this is a big thing. Especially on my project, a lot of the engagement is from bots.

[2:49:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10140s) I'd much rather read authentic human writing. I think we're reaching a point where people value raw human expression more. I experimented with creating AI-assisted blog posts and it took me a long time to steer it towards my style. But it missed the nuances of how I would write. You can steer it, but it's not gonna be authentically yours. I moved away from that. I write everything myself now. Maybe I use AI for code, but not for personal writing. There's value in the rough human edges.

[2:50:10](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10210s) Isn't that awesome? That we value raw humanity so much? I also realized that for documentation, I'm still fine with AI-generated text. But for personal writing and images, I'm allergic to it. Those AI-generated images trigger me so hard. It immediately makes me think less of the content. Even if people explored the new medium when it was novel, now it just screams "AI slop." I went through my blog and realized removing all AI images would require a huge amount of work to replace them with hand-drawn or real diagrams.

[2:51:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10300s) It's a smell. You know it when you see it. And that gives me hope about humanity. It's only going to be more and more valued -- the authentically human. We're not going to be damaged or limited by AI. It'll make us appreciate real human expression more.

[2:52:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10340s) You mentioned that basically 80% of apps will be made obsolete by agents. Do you think agents will just replace most apps? Yeah. I noticed that once people have OpenClaw set up, they stop using certain apps. Like, why do you need MyFitnessPal when your agent knows what you eat? It can assume you had breakfast at, I don't know, Waffle House. There's no bad decisions. Your agent should know that. It can track everything based on how well you slept, your location, your habits. It has so much more context than any single-purpose app.

[2:53:40](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10420s) It could show me UI just as needed. Why do I need a separate app for that? Why do I need my Eight Sleep smart bed when I can tell the agent how I slept? The agent knows where I am, so it can suggest things contextually. That category of apps will just naturally stop being used. I think 80% is a fair estimate. Don't you think that's a gigantic transformation of all software development? Yeah. It's a scary thing for a lot of companies. The impact on the economy, on who builds what, on how users get stuff done.

[2:55:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10500s) It's also about new services. My agent needs something done in the real world? Maybe it uses a service -- like "rent a human" to solve physical problems. I don't care about the app, I care about the outcome. There's a real opportunity for companies that become agent-friendly APIs. Apps that can provide APIs will thrive. The ones that can't will rapidly become obsolete. Who gets there fastest to being the most natural, the easiest for agents to use?

[2:56:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10590s) Apps will become invisible. My agent can figure out how to use any service. Why do I need a Sonos app anymore when the agent can talk to the Sonos speakers directly? They have an API. So it's gonna force a lot of companies to rethink what they're offering, just like the internet did. Some companies were really hard to work with. I had to build a CLI for Google services because getting API access through their developer jungle is incredibly complicated.

[2:58:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10680s) But they cannot prevent an agent that just clicks through the browser. I watch my agent happily click "I'm not a robot" on Google. That's gonna be more heated -- companies trying to prevent bot access, but personal agents are different from scraping. If I'm a personal user, I want my agent to learn for me, browse for me. I use Codex and ask it to look up modern React patterns, and it's like reading a Medium article. I can't always access it because they block bots. In the future, maybe I don't need their website at all.

[3:00:57](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10857s) There's gonna be a lot of powerful companies pushing back. Even search -- I now use AI as my primary search provider. Google really needs to watch out because I can operate without Google. I'm not sure if that's good for Google. There's a balance though -- if they push back too much, they become irrelevant. Like the Netflixes of the world -- adapt or die.

[3:02:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10920s) The pattern is clear. If I'm on the go, I don't wanna open a calendar app. I just say "Hey, remind me about this dinner, coordinate with two friends, maybe send a message." I don't need separate apps for all that. The days of opening 10 different apps are over. We've passed that age. Things will be much more connected and fluid. Companies that adapt will thrive.

[3:03:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=10980s) You've got to listen to what users want. A lot of folks who are developers are really worried about the future of human programmers. Will AI replace programmers completely? I mean, we're definitely going in that direction where coding becomes a smaller part of building products. Eventually, maybe. But there's so much more to building things than just writing code. Architecture decisions, knowing what to build -- I don't think that goes away.

[3:04:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11040s) And programming might become like knitting. People still knit even though machines do it better. It doesn't make economic sense, but people do it for joy. A part of me very strongly feels that. In my past, I spent a lot of time tinkering, cranking out code, finding elegant solutions. Yes, in a way it's sad that some of that is changing. And I get a lot of joy from writing code and being in that beautiful state of flow. With agents, I get a similar state, but it's different.

[3:05:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11130s) It's okay to mourn it. But the world is changing. For a long time, the world lacked intelligence. Software developer salaries were high because of that scarcity. That will shift. But there will be even more demand for people who understand how to work with these tools. Tokenized intelligence enables building faster. We had similar transformations with the steam engine and industrial revolution. People revolted. I can relate that if you deeply identify as a programmer, it's scary.

[3:06:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11190s) But I don't think programming goes away. It evolves. You're not just a programmer -- you're a builder. You're articulating this beautifully. The thing I love doing -- coding -- is what gets replaced. Like the steam engine replacing hand labor. I spent years alone behind a screen, pouring over code. And there's an identity there. When I walk down the street, I think of myself as a programmer. Having that completely replaced is painful. It's truly painful for programmers, builders more broadly. But what is the act of programming? It's empathizing with the machine, learning the language, understanding the CLI.

[3:08:00](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11280s) I think at some point programming with AI is just gonna be called "normal." And yet, while I don't write every line, I'm in the driver's seat. I am building. You'll still be a programmer. The craft is just different. On Twitter, people attack me for this viewpoint. I understand the fear. It's going to be a change. But I also find it incredibly exciting. I can use the new tools to focus on much more interesting details. The bar of what you can build is rising because it's so much easier.

[3:09:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11370s) I did a conference where my whole motivation was to tell iOS developers: you can use your skills in many more domains now. People didn't like that. But this is how I see it. The first question I got was about data center energy usage. But the math shows that AI's carbon impact is manageable, more water goes to people who play golf than all data centers. People who think everything is bad about AI ignore the things that might be good about AI.

[3:10:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11430s) To steel-man the criticism: in Silicon Valley there's a bit of an echo chamber of excitement. Not enough respect for the human experience across the United States. Including the programmers we mentioned, including the short-term disruption when there's large-scale transformative change. Having a bit of empathy about the impact of these tools is important. They will long-term hopefully create even more opportunities. But there's often not enough respect for the fear that people feel.

[3:11:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11490s) And then I also have to mention the heartwarming emails I got. People told me they were struggling, and OpenClaw freed them from tedious tasks -- collecting data, filing forms -- which freed them up and saved them money. Or emails about people's disabled daughters who are now empowered and feel they can do things. That's amazing. I didn't invent AI but I made it a whole lot easier and more accessible. People apply it for good. And the fact that while I recommend the best models, you can totally run this locally with smaller models and still have a powerful agent.

[3:12:57](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11577s) What gives you hope about human civilization? I mean, I inspired so many people. The builder vibe is back. People are now discovering what AI can do and creating new communities that are just sprawling with energy. There are meetups, conferences, people who are usually too shy to present are now stepping up. There's such abundance. So that gives me hope -- that we can figure things out. And it makes it accessible to everyone. Just imagine all these people building, especially as we make it more secure. Anybody who has ideas can build. That's crazy.

[3:14:30](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11670s) Yeah, that's ultimately power to the people. The beautiful things that come out of that empowerment. Well, Mr. Clawfather -- I just realized I violated two trademarks and I'm getting sued by everybody. You're a wonderful human being. You've created a special community, a special set of ideas. Plus the entire inspiration of all these people to build. So I'm truly grateful for what you're doing and for who you are. Thank you for talking with me today. Thank you, brother.

[3:15:20](https://www.youtube.com/watch?v=YFjfBk8HI5o&t=11720s) Thanks for giving me this platform. Thanks for listening to this conversation with Peter Steinberger. Please check out our sponsors in the description. And now let me leave you with some words about freedom and responsibility. Thank you for listening, and I hope to see you next time.
