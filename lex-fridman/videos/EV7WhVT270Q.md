---
video_id: EV7WhVT270Q
title: "State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI"
channel: Lex Fridman
duration: 15913
duration_formatted: "4:25:13"
view_count: 312452
upload_date: 2026-01-31
url: https://www.youtube.com/watch?v=EV7WhVT270Q
thumbnail: https://i.ytimg.com/vi_webp/EV7WhVT270Q/maxresdefault.webp
tags:
  - AI
  - LLMs
  - Machine Learning
  - DeepSeek
  - Scaling Laws
  - AGI
  - Post-training
  - Nathan Lambert
  - Sebastian Raschka
---

# State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI

## Summary

In this comprehensive discussion, Lex Fridman sits down with two leading AI researchers - Nathan Lambert (post-training lead at Allen Institute for AI) and Sebastian Raschka (author of "Build a Large Language Model from Scratch") - to analyze the state of artificial intelligence in 2026. The conversation covers major developments from the past year, including the DeepSeek moment that shook the AI world, the ongoing competition between Chinese and American AI companies, and deep technical dives into pre-training, post-training, and the future of scaling laws.

The discussion explores who's winning the AI race between different labs (OpenAI, Anthropic, Google DeepMind, Meta, xAI), the best AI models for coding, the open source versus closed source debate, and whether scaling laws are dead or still holding. They also discuss the work culture in AI research (including 72+ hour work weeks), the Silicon Valley bubble, new research directions like text diffusion models and tool use, and predictions for AGI timelines. The conversation is both highly technical and accessible, making complex AI concepts understandable for those outside the field.

This episode serves as an excellent overview of where AI stands at the beginning of 2026, with insights into what the next few years might bring in terms of technological breakthroughs, business models, and the future of human-AI collaboration.

## Key Points

- **DeepSeek Moment** ([1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)) - Discussion of DeepSeek's January 2025 release that achieved state-of-the-art results with much less compute, reigniting the AI competition between China and the US
- **China vs US AI Race** ([1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)) - Analysis of the international competition in AI development and who's currently leading
- **Best AI Models** ([10:38](https://www.youtube.com/watch?v=EV7WhVT270Q&t=638s)) - Comparison of ChatGPT, Claude, Gemini, and Grok to determine which is winning
- **AI for Coding** ([21:38](https://www.youtube.com/watch?v=EV7WhVT270Q&t=1298s)) - Discussion of which AI models are best for programming tasks
- **Open vs Closed Source** ([28:29](https://www.youtube.com/watch?v=EV7WhVT270Q&t=1709s)) - Debate about the future of open source versus closed source LLMs
- **Transformer Evolution** ([40:08](https://www.youtube.com/watch?v=EV7WhVT270Q&t=2408s)) - How transformers and LLMs have evolved since 2019
- **Scaling Laws Status** ([48:05](https://www.youtube.com/watch?v=EV7WhVT270Q&t=2885s)) - Are AI scaling laws dead or still holding?
- **AI Training Pipeline** ([1:04:12](https://www.youtube.com/watch?v=EV7WhVT270Q&t=3852s)) - Deep dive into pre-training, mid-training, and post-training
- **Post-training Research** ([1:37:18](https://www.youtube.com/watch?v=EV7WhVT270Q&t=5838s)) - Exciting new research directions in post-training for LLMs
- **Getting Started in AI** ([1:58:11](https://www.youtube.com/watch?v=EV7WhVT270Q&t=7091s)) - Advice for beginners on how to get into AI development and research
- **AI Work Culture** ([2:21:03](https://www.youtube.com/watch?v=EV7WhVT270Q&t=8463s)) - Discussion of 72+ hour work weeks in AI labs
- **Silicon Valley Bubble** ([2:24:49](https://www.youtube.com/watch?v=EV7WhVT270Q&t=8689s)) - Perspectives on the tech industry bubble
- **New Research Directions** ([2:28:46](https://www.youtube.com/watch?v=EV7WhVT270Q&t=8926s)) - Text diffusion models and other emerging areas
- **Tool Use** ([2:34:28](https://www.youtube.com/watch?v=EV7WhVT270Q&t=9268s)) - How AI systems are learning to use tools
- **Continual Learning** ([2:38:44](https://www.youtube.com/watch?v=EV7WhVT270Q&t=9524s)) - Enabling AI to learn continuously
- **Long Context** ([2:44:06](https://www.youtube.com/watch?v=EV7WhVT270Q&t=9846s)) - Advances in handling longer context windows
- **Robotics** ([2:50:21](https://www.youtube.com/watch?v=EV7WhVT270Q&t=10221s)) - The intersection of LLMs and robotics
- **AGI Timeline** ([2:59:31](https://www.youtube.com/watch?v=EV7WhVT270Q&t=10771s)) - Predictions for when AGI might arrive
- **AI Replacing Programmers** ([3:06:47](https://www.youtube.com/watch?v=EV7WhVT270Q&t=11207s)) - Will AI replace human programmers?
- **Future of AGI Dream** ([3:25:18](https://www.youtube.com/watch?v=EV7WhVT270Q&t=12318s)) - Is the dream of AGI dying?
- **AI Business Models** ([3:32:07](https://www.youtube.com/watch?v=EV7WhVT270Q&t=12727s)) - How will AI companies make money?
- **Big Acquisitions** ([3:36:29](https://www.youtube.com/watch?v=EV7WhVT270Q&t=12989s)) - Predictions for major acquisitions in 2026
- **Future of AI Labs** ([3:41:01](https://www.youtube.com/watch?v=EV7WhVT270Q&t=13261s)) - What's next for OpenAI, Anthropic, Google DeepMind, xAI, and Meta
- **Manhattan Project for AI** ([3:53:35](https://www.youtube.com/watch?v=EV7WhVT270Q&t=14015s)) - Discussion of government-led AI initiatives
- **Future of NVIDIA and GPUs** ([4:00:10](https://www.youtube.com/watch?v=EV7WhVT270Q&t=14410s)) - The future of AI compute infrastructure
- **Future of Humanity** ([4:08:15](https://www.youtube.com/watch?v=EV7WhVT270Q&t=14895s)) - How AI will shape human civilization

## Mentions

### People
- **Nathan Lambert** - Post-training lead at Allen Institute for AI, author of The RLHF Book
- **Sebastian Raschka** - Author of "Build a Large Language Model from Scratch" and "Build a Reasoning Model from Scratch"
- **Sam Altman** - Referenced in discussions of OpenAI's direction
- **Elon Musk** - Mentioned in context of xAI and AI competition

### Companies
- **DeepSeek** ([1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)) - Chinese AI company that released state-of-the-art models with less compute
- **OpenAI** ([10:38](https://www.youtube.com/watch?v=EV7WhVT270Q&t=638s)) - Leading AI lab, creator of ChatGPT
- **Anthropic** ([10:38](https://www.youtube.com/watch?v=EV7WhVT270Q&t=638s)) - AI safety company, creator of Claude
- **Google DeepMind** ([10:38](https://www.youtube.com/watch?v=EV7WhVT270Q&t=638s)) - Google's AI research division, creator of Gemini
- **Meta** ([28:29](https://www.youtube.com/watch?v=EV7WhVT270Q&t=1709s)) - Major player in open source AI with Llama models
- **xAI** ([3:41:01](https://www.youtube.com/watch?v=EV7WhVT270Q&t=13261s)) - Elon Musk's AI company, creator of Grok
- **Allen Institute for AI (Ai2)** - Nathan Lambert's employer
- **NVIDIA** ([4:00:10](https://www.youtube.com/watch?v=EV7WhVT270Q&t=14410s)) - Leading GPU manufacturer for AI compute
- **Helion Energy** ([2:09:52](https://www.youtube.com/watch?v=EV7WhVT270Q&t=7792s)) - Mentioned in context of energy needs for GPU clusters

### Technologies
- **Transformers** ([40:08](https://www.youtube.com/watch?v=EV7WhVT270Q&t=2408s)) - The architecture underlying modern LLMs
- **RLHF** ([1:37:18](https://www.youtube.com/watch?v=EV7WhVT270Q&t=5838s)) - Reinforcement Learning from Human Feedback
- **Diffusion Models** ([2:28:46](https://www.youtube.com/watch?v=EV7WhVT270Q&t=8926s)) - Text diffusion as a new research direction
- **GPUs** ([4:00:10](https://www.youtube.com/watch?v=EV7WhVT270Q&t=14410s)) - Graphics processing units essential for AI training

## Surprising Quotes

> "The DeepSeek moment really won the hearts of the people who work on open models."
> — Sebastian Raschka, [1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)

> "I don't think there will be a take-it-all scenario where one company wins at the moment."
> — Sebastian Raschka, [1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)

> "The differentiating factor is the resources and constraints companies operate under."
> — Sebastian Raschka, [1:57](https://www.youtube.com/watch?v=EV7WhVT270Q&t=117s)

## Additional Resources

- [Nathan Lambert's X](https://x.com/natolambert)
- [Nathan Lambert's Blog](https://interconnects.ai)
- [Nathan's Book: The RLHF Book](https://rlhfbook.com)
- [Sebastian Raschka's X](https://x.com/rasbt)
- [Sebastian Raschka's Blog](https://magazine.sebastianraschka.com)
- [Build a Large Language Model (From Scratch)](https://manning.com/books/build-a-large-language-model-from-scratch)
- [Build a Reasoning Model (From Scratch)](https://manning.com/books/build-a-reasoning-model-from-scratch)
- [Full Transcript](https://lexfridman.com/ai-sota-2026-transcript)
